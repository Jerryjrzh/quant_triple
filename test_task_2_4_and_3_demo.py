"""
Task 2.4 å’Œ Task 3 æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºç¼“å­˜ç®¡ç†ç³»ç»Ÿå’Œæ•°æ®åº“æ¨¡å‹æ‰©å±•çš„é›†æˆåŠŸèƒ½ï¼š
1. ç¼“å­˜ç®¡ç†ç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½
2. æ–°å¢æ•°æ®åº“æ¨¡å‹çš„ä½¿ç”¨
3. å¢å¼ºæ•°æ®æºç®¡ç†å™¨ä¸ç¼“å­˜çš„é›†æˆ
4. æ•°æ®è´¨é‡ç›‘æ§å’Œå¥åº·æ£€æŸ¥
"""

import asyncio
import logging
import pandas as pd
from datetime import datetime, timedelta, date
from decimal import Decimal
from typing import List, Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def demo_cache_manager():
    """æ¼”ç¤ºç¼“å­˜ç®¡ç†å™¨åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ”§ Task 2.4: ç¼“å­˜ç®¡ç†ç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    
    try:
        from stock_analysis_system.data.cache_manager import get_cache_manager
        
        # è·å–ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
        cache_manager = await get_cache_manager()
        print("âœ… ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'symbol': ['000001', '000002', '000003'],
            'price': [10.5, 20.3, 15.8],
            'volume': [1000000, 2000000, 1500000],
            'timestamp': [datetime.now() - timedelta(minutes=i) for i in range(3)]
        })
        
        # æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ
        print("\nğŸ“ æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ:")
        cache_key = "demo:stock:000001"
        cache_type = "realtime_data"
        
        # è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(cache_key, test_data, cache_type)
        print(f"   âœ“ ç¼“å­˜å·²è®¾ç½®: {cache_key}")
        
        # è·å–ç¼“å­˜
        cached_data = await cache_manager.get_cached_data(cache_key, cache_type)
        if cached_data is not None:
            print(f"   âœ“ ç¼“å­˜å‘½ä¸­: è·å–åˆ° {len(cached_data)} è¡Œæ•°æ®")
        else:
            print("   âŒ ç¼“å­˜æœªå‘½ä¸­")
        
        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        stats = cache_manager.get_cache_stats()
        print(f"\nğŸ“Š ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   å‘½ä¸­æ¬¡æ•°: {stats['hits']}")
        print(f"   æœªå‘½ä¸­æ¬¡æ•°: {stats['misses']}")
        print(f"   å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
        print(f"   è®¾ç½®æ¬¡æ•°: {stats['sets']}")
        print(f"   å†…å­˜ç¼“å­˜å¤§å°: {stats['memory_cache_size']}")
        
        # æµ‹è¯•ç¼“å­˜å¤±æ•ˆ
        print(f"\nğŸ—‘ï¸ æµ‹è¯•ç¼“å­˜å¤±æ•ˆ:")
        await cache_manager.invalidate_cache("demo:*")
        print("   âœ“ ç¼“å­˜å·²å¤±æ•ˆ")
        
        # éªŒè¯ç¼“å­˜å¤±æ•ˆ
        cached_data_after = await cache_manager.get_cached_data(cache_key, cache_type)
        if cached_data_after is None:
            print("   âœ“ ç¼“å­˜å¤±æ•ˆéªŒè¯æˆåŠŸ")
        else:
            print("   âŒ ç¼“å­˜å¤±æ•ˆéªŒè¯å¤±è´¥")
        
        await cache_manager.close()
        print("âœ… ç¼“å­˜ç®¡ç†å™¨æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ç¼“å­˜ç®¡ç†å™¨æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def demo_database_models():
    """æ¼”ç¤ºæ•°æ®åº“æ¨¡å‹æ‰©å±•"""
    print("\n" + "="*60)
    print("ğŸ—„ï¸ Task 3: æ•°æ®åº“æ¨¡å‹æ‰©å±•æ¼”ç¤º")
    print("="*60)
    
    try:
        from stock_analysis_system.data.models import (
            DragonTigerBoard, DragonTigerDetail, FundFlow, 
            LimitUpReason, ETFData, ETFConstituent,
            DataQualityLog, DataSourceHealth
        )
        
        print("âœ… æ–°å¢æ•°æ®åº“æ¨¡å‹å¯¼å…¥æˆåŠŸ")
        
        # æ¼”ç¤ºæ¨¡å‹ç»“æ„
        models_info = {
            "DragonTigerBoard": "é¾™è™æ¦œæ•°æ®è¡¨ - å­˜å‚¨é¾™è™æ¦œåŸºæœ¬ä¿¡æ¯",
            "DragonTigerDetail": "é¾™è™æ¦œè¯¦ç»†æ•°æ®è¡¨ - å­˜å‚¨æœºæ„å’Œè¥ä¸šéƒ¨æ˜ç»†",
            "FundFlow": "èµ„é‡‘æµå‘æ•°æ®è¡¨ - å­˜å‚¨ä¸»åŠ›èµ„é‡‘æµå‘ä¿¡æ¯",
            "LimitUpReason": "æ¶¨åœåŸå› æ•°æ®è¡¨ - å­˜å‚¨æ¶¨åœè‚¡ç¥¨åŸå› åˆ†æ",
            "ETFData": "ETFæ•°æ®è¡¨ - å­˜å‚¨ETFè¡Œæƒ…å’Œç‰¹æœ‰æŒ‡æ ‡",
            "ETFConstituent": "ETFæˆåˆ†è‚¡æ•°æ®è¡¨ - å­˜å‚¨ETFæŒä»“æ˜ç»†",
            "DataQualityLog": "æ•°æ®è´¨é‡æ—¥å¿—è¡¨ - è®°å½•æ•°æ®è´¨é‡æ£€æŸ¥ç»“æœ",
            "DataSourceHealth": "æ•°æ®æºå¥åº·çŠ¶æ€è¡¨ - ç›‘æ§æ•°æ®æºå¯ç”¨æ€§"
        }
        
        print("\nğŸ“‹ æ–°å¢æ•°æ®åº“æ¨¡å‹åˆ—è¡¨:")
        for model_name, description in models_info.items():
            print(f"   â€¢ {model_name}: {description}")
        
        # æ¼”ç¤ºæ¨¡å‹å®ä¾‹åˆ›å»ºï¼ˆä¸å®é™…ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
        print(f"\nğŸ—ï¸ æ¼”ç¤ºæ¨¡å‹å®ä¾‹åˆ›å»º:")
        
        # é¾™è™æ¦œæ•°æ®ç¤ºä¾‹
        dragon_tiger = DragonTigerBoard(
            trade_date=date.today(),
            stock_code="000001",
            stock_name="å¹³å®‰é“¶è¡Œ",
            close_price=Decimal("12.50"),
            change_rate=Decimal("5.00"),
            net_buy_amount=50000000,
            buy_amount=80000000,
            sell_amount=30000000,
            reason="æœºæ„å¤§å¹…ä¹°å…¥"
        )
        print(f"   âœ“ é¾™è™æ¦œæ•°æ®: {dragon_tiger.stock_name} ({dragon_tiger.stock_code})")
        
        # èµ„é‡‘æµå‘æ•°æ®ç¤ºä¾‹
        fund_flow = FundFlow(
            stock_code="000001",
            stock_name="å¹³å®‰é“¶è¡Œ",
            trade_date=date.today(),
            period_type="ä»Šæ—¥",
            main_net_inflow=25000000,
            main_net_inflow_rate=Decimal("3.50"),
            super_large_net_inflow=15000000,
            super_large_net_inflow_rate=Decimal("2.10")
        )
        print(f"   âœ“ èµ„é‡‘æµå‘æ•°æ®: {fund_flow.stock_name} ä¸»åŠ›å‡€æµå…¥ {fund_flow.main_net_inflow}")
        
        # æ¶¨åœåŸå› æ•°æ®ç¤ºä¾‹
        limitup_reason = LimitUpReason(
            trade_date=date.today(),
            stock_code="000002",
            stock_name="ä¸‡ç§‘A",
            reason="åœ°äº§æ”¿ç­–åˆ©å¥½",
            detail_reason="å›½å®¶å‡ºå°æˆ¿åœ°äº§æ”¯æŒæ”¿ç­–ï¼Œåœ°äº§è‚¡é›†ä½“ä¸Šæ¶¨",
            latest_price=Decimal("8.88"),
            change_rate=Decimal("10.00"),
            reason_category="æ”¿ç­–åˆ©å¥½",
            reason_tags=["æˆ¿åœ°äº§", "æ”¿ç­–", "åˆ©å¥½"]
        )
        print(f"   âœ“ æ¶¨åœåŸå› æ•°æ®: {limitup_reason.stock_name} - {limitup_reason.reason}")
        
        # ETFæ•°æ®ç¤ºä¾‹
        etf_data = ETFData(
            etf_code="510300",
            etf_name="æ²ªæ·±300ETF",
            trade_date=date.today(),
            close_price=Decimal("4.125"),
            volume=50000000,
            unit_nav=Decimal("4.123"),
            premium_rate=Decimal("0.05"),
            fund_size=Decimal("15000000000.00")
        )
        print(f"   âœ“ ETFæ•°æ®: {etf_data.etf_name} ({etf_data.etf_code})")
        
        # æ•°æ®è´¨é‡æ—¥å¿—ç¤ºä¾‹
        quality_log = DataQualityLog(
            data_source="eastmoney",
            data_type="stock_realtime",
            check_date=date.today(),
            total_records=1000,
            valid_records=995,
            invalid_records=5,
            completeness_score=Decimal("99.50"),
            accuracy_score=Decimal("98.80"),
            overall_score=Decimal("99.15")
        )
        print(f"   âœ“ æ•°æ®è´¨é‡æ—¥å¿—: {quality_log.data_source} æ€»ä½“è¯„åˆ† {quality_log.overall_score}")
        
        # æ•°æ®æºå¥åº·çŠ¶æ€ç¤ºä¾‹
        health_status = DataSourceHealth(
            source_name="eastmoney_adapter",
            status="healthy",
            response_time=Decimal("0.250"),
            success_rate=Decimal("99.80"),
            total_requests=10000,
            successful_requests=9980,
            failed_requests=20
        )
        print(f"   âœ“ æ•°æ®æºå¥åº·çŠ¶æ€: {health_status.source_name} - {health_status.status}")
        
        print("âœ… æ•°æ®åº“æ¨¡å‹æ‰©å±•æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ¨¡å‹æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def demo_enhanced_data_source_with_cache():
    """æ¼”ç¤ºå¢å¼ºæ•°æ®æºç®¡ç†å™¨ä¸ç¼“å­˜çš„é›†æˆ"""
    print("\n" + "="*60)
    print("ğŸ”„ å¢å¼ºæ•°æ®æºç®¡ç†å™¨ä¸ç¼“å­˜é›†æˆæ¼”ç¤º")
    print("="*60)
    
    try:
        from stock_analysis_system.data.enhanced_data_sources import EnhancedDataSourceManager
        from stock_analysis_system.data.market_data_request import MarketDataRequest
        
        # åˆ›å»ºå¢å¼ºæ•°æ®æºç®¡ç†å™¨
        manager = EnhancedDataSourceManager()
        print("âœ… å¢å¼ºæ•°æ®æºç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # ç­‰å¾…ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–
        await asyncio.sleep(1)
        
        # åˆ›å»ºæ•°æ®è¯·æ±‚
        request = MarketDataRequest(
            symbol="000001",
            start_date="20240101",
            end_date="20241231",
            period="daily",
            data_type="stock_history"
        )
        
        print(f"\nğŸ“Š æµ‹è¯•å¸¦ç¼“å­˜çš„æ•°æ®è·å–:")
        print(f"   è¯·æ±‚è‚¡ç¥¨: {request.symbol}")
        print(f"   æ•°æ®ç±»å‹: {request.data_type}")
        print(f"   æ—¶é—´èŒƒå›´: {request.start_date} - {request.end_date}")
        
        # ç¬¬ä¸€æ¬¡è·å–æ•°æ®ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        print(f"\nğŸ” ç¬¬ä¸€æ¬¡æ•°æ®è·å–ï¼ˆé¢„æœŸç¼“å­˜æœªå‘½ä¸­ï¼‰:")
        start_time = asyncio.get_event_loop().time()
        
        if hasattr(manager, 'get_cached_market_data'):
            data1 = await manager.get_cached_market_data(request)
        else:
            print("   âš ï¸ ç¼“å­˜åŠŸèƒ½æœªå®Œå…¨é›†æˆï¼Œä½¿ç”¨æ™®é€šæ•°æ®è·å–")
            data1 = await manager.get_enhanced_market_data(request)
        
        first_time = asyncio.get_event_loop().time() - start_time
        print(f"   è€—æ—¶: {first_time:.3f} ç§’")
        print(f"   æ•°æ®è¡Œæ•°: {len(data1) if not data1.empty else 0}")
        
        # ç¬¬äºŒæ¬¡è·å–ç›¸åŒæ•°æ®ï¼ˆé¢„æœŸç¼“å­˜å‘½ä¸­ï¼‰
        print(f"\nâš¡ ç¬¬äºŒæ¬¡æ•°æ®è·å–ï¼ˆé¢„æœŸç¼“å­˜å‘½ä¸­ï¼‰:")
        start_time = asyncio.get_event_loop().time()
        
        if hasattr(manager, 'get_cached_market_data'):
            data2 = await manager.get_cached_market_data(request)
        else:
            data2 = await manager.get_enhanced_market_data(request)
        
        second_time = asyncio.get_event_loop().time() - start_time
        print(f"   è€—æ—¶: {second_time:.3f} ç§’")
        print(f"   æ•°æ®è¡Œæ•°: {len(data2) if not data2.empty else 0}")
        
        # æ€§èƒ½å¯¹æ¯”
        if first_time > 0 and second_time > 0:
            speedup = first_time / second_time
            print(f"   æ€§èƒ½æå‡: {speedup:.1f}x")
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        if hasattr(manager, 'get_cache_stats'):
            cache_stats = manager.get_cache_stats()
            print(f"\nğŸ“ˆ ç¼“å­˜ç»Ÿè®¡:")
            if isinstance(cache_stats, dict) and 'error' not in cache_stats:
                print(f"   å‘½ä¸­ç‡: {cache_stats.get('hit_rate', 0):.2%}")
                print(f"   æ€»å‘½ä¸­: {cache_stats.get('hits', 0)}")
                print(f"   æ€»æœªå‘½ä¸­: {cache_stats.get('misses', 0)}")
            else:
                print(f"   {cache_stats}")
        
        print("âœ… å¢å¼ºæ•°æ®æºç®¡ç†å™¨ä¸ç¼“å­˜é›†æˆæ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å¢å¼ºæ•°æ®æºç®¡ç†å™¨æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def demo_migration_script():
    """æ¼”ç¤ºæ•°æ®åº“è¿ç§»è„šæœ¬"""
    print("\n" + "="*60)
    print("ğŸ”„ æ•°æ®åº“è¿ç§»è„šæœ¬æ¼”ç¤º")
    print("="*60)
    
    try:
        # è¯»å–è¿ç§»è„šæœ¬å†…å®¹
        migration_file = "alembic/versions/b12345678901_add_crawling_integration_models.py"
        
        print(f"ğŸ“„ è¿ç§»è„šæœ¬æ–‡ä»¶: {migration_file}")
        print(f"ğŸ“ è¿ç§»å†…å®¹åŒ…æ‹¬:")
        
        tables_created = [
            "dragon_tiger_board - é¾™è™æ¦œæ•°æ®è¡¨",
            "dragon_tiger_detail - é¾™è™æ¦œè¯¦ç»†æ•°æ®è¡¨", 
            "fund_flow - èµ„é‡‘æµå‘æ•°æ®è¡¨",
            "limitup_reason - æ¶¨åœåŸå› æ•°æ®è¡¨",
            "etf_data - ETFæ•°æ®è¡¨",
            "etf_constituent - ETFæˆåˆ†è‚¡æ•°æ®è¡¨",
            "data_quality_log - æ•°æ®è´¨é‡æ—¥å¿—è¡¨",
            "data_source_health - æ•°æ®æºå¥åº·çŠ¶æ€è¡¨"
        ]
        
        for table in tables_created:
            print(f"   âœ“ {table}")
        
        print(f"\nğŸ”§ ä¼˜åŒ–ç‰¹æ€§:")
        optimizations = [
            "ä¸ºé¾™è™æ¦œæ•°æ®è¡¨åˆ›å»ºæŒ‰æœˆåˆ†åŒº",
            "åˆ›å»ºå¤åˆç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½",
            "ä¸ºæ¶¨åœåŸå› åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•",
            "æ·»åŠ å”¯ä¸€çº¦æŸé˜²æ­¢æ•°æ®é‡å¤",
            "è®¾ç½®è‡ªåŠ¨æ—¶é—´æˆ³å­—æ®µ"
        ]
        
        for opt in optimizations:
            print(f"   â€¢ {opt}")
        
        print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print(f"   1. ç¡®ä¿æ•°æ®åº“è¿æ¥æ­£å¸¸")
        print(f"   2. è¿è¡Œå‘½ä»¤: alembic upgrade head")
        print(f"   3. éªŒè¯è¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
        print(f"   4. å¦‚éœ€å›æ»š: alembic downgrade -1")
        
        print("âœ… æ•°æ®åº“è¿ç§»è„šæœ¬æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è¿ç§»è„šæœ¬æ¼”ç¤ºå¤±è´¥: {e}")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ Task 2.4 å’Œ Task 3 é›†æˆæ¼”ç¤º")
    print("=" * 80)
    print("æœ¬æ¼”ç¤ºå±•ç¤ºç¼“å­˜ç®¡ç†ç³»ç»Ÿå’Œæ•°æ®åº“æ¨¡å‹æ‰©å±•çš„å®Œæ•´åŠŸèƒ½")
    
    try:
        # Task 2.4: ç¼“å­˜ç®¡ç†ç³»ç»Ÿæ¼”ç¤º
        await demo_cache_manager()
        
        # Task 3: æ•°æ®åº“æ¨¡å‹æ‰©å±•æ¼”ç¤º
        demo_database_models()
        
        # é›†æˆæ¼”ç¤ºï¼šå¢å¼ºæ•°æ®æºç®¡ç†å™¨ä¸ç¼“å­˜
        await demo_enhanced_data_source_with_cache()
        
        # æ•°æ®åº“è¿ç§»è„šæœ¬æ¼”ç¤º
        demo_migration_script()
        
        print("\n" + "="*80)
        print("ğŸ‰ Task 2.4 å’Œ Task 3 æ¼”ç¤ºå®Œæˆ!")
        print("="*80)
        
        print(f"\nğŸ“‹ å®Œæˆçš„åŠŸèƒ½:")
        completed_features = [
            "âœ… Task 2.4: ç¼“å­˜ç®¡ç†ç³»ç»Ÿ",
            "  â€¢ å¤šçº§ç¼“å­˜ç­–ç•¥ï¼ˆå†…å­˜ + Redisï¼‰",
            "  â€¢ ç¼“å­˜é¢„çƒ­å’Œæ™ºèƒ½é¢„åŠ è½½",
            "  â€¢ ç¼“å­˜æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡",
            "  â€¢ ç¼“å­˜å¤±æ•ˆå’Œç®¡ç†æœºåˆ¶",
            "",
            "âœ… Task 3: æ•°æ®åº“æ¨¡å‹æ‰©å±•å’Œè¿ç§»",
            "  â€¢ 8ä¸ªæ–°å¢æ•°æ®è¡¨æ¨¡å‹",
            "  â€¢ æ•°æ®åº“åˆ†åŒºå’Œç´¢å¼•ä¼˜åŒ–",
            "  â€¢ æ•°æ®è´¨é‡ç›‘æ§æ¨¡å‹",
            "  â€¢ å®Œæ•´çš„è¿ç§»è„šæœ¬",
            "",
            "âœ… ç³»ç»Ÿé›†æˆ:",
            "  â€¢ å¢å¼ºæ•°æ®æºç®¡ç†å™¨é›†æˆç¼“å­˜",
            "  â€¢ ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£",
            "  â€¢ æ€§èƒ½ç›‘æ§å’Œå¥åº·æ£€æŸ¥",
            "  â€¢ é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶"
        ]
        
        for feature in completed_features:
            print(f"   {feature}")
        
        print(f"\nğŸ”§ æŠ€æœ¯ç‰¹ç‚¹:")
        tech_features = [
            "â€¢ å¼‚æ­¥ç¼–ç¨‹æ”¯æŒé«˜å¹¶å‘",
            "â€¢ å¤šçº§ç¼“å­˜æå‡æ€§èƒ½",
            "â€¢ æ•°æ®åº“åˆ†åŒºä¼˜åŒ–æŸ¥è¯¢",
            "â€¢ å…¨æ–‡æœç´¢æ”¯æŒå¤æ‚æŸ¥è¯¢",
            "â€¢ å¥åº·ç›‘æ§ä¿è¯å¯ç”¨æ€§",
            "â€¢ æ¨¡å—åŒ–è®¾è®¡æ˜“äºæ‰©å±•"
        ]
        
        for feature in tech_features:
            print(f"   {feature}")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
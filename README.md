# æ™ºèƒ½è‚¡ç¥¨åˆ†æç³»ç»Ÿ (Stock Analysis System)

[![Docker Setup](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](DOCKER_SETUP_SUMMARY.md)
[![API Status](https://img.shields.io/badge/API-Working-green?logo=fastapi)](http://localhost:8000/docs)
[![Database](https://img.shields.io/badge/Database-PostgreSQL-blue?logo=postgresql)](docker-compose.yml)
[![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)](requirements.txt)
[![AI Powered](https://img.shields.io/badge/AI-Powered-orange?logo=tensorflow)](stock_analysis_system/analysis/)

åŸºäºæ˜¥èŠ‚æ—¶é—´é”šç‚¹çš„åˆ›æ–°æ€§è‚¡ç¥¨åˆ†æç³»ç»Ÿï¼Œé›†æˆå¤šç»´åº¦æ•°æ®æºã€æœºå™¨å­¦ä¹ æ¨¡å¼è¯†åˆ«ã€é£é™©ç®¡ç†å¼•æ“å’Œæ™ºèƒ½äº¤æ˜“ç­–ç•¥ã€‚é€šè¿‡ç‹¬ç‰¹çš„å†œå†æ—¶é—´å¯¹é½æŠ€æœ¯ï¼Œæ­ç¤ºä¼ ç»Ÿåˆ†ææ–¹æ³•æ— æ³•å‘ç°çš„å­£èŠ‚æ€§æŠ•èµ„æœºä¼šã€‚

> **ğŸš€ ä¸€é”®å¯åŠ¨**: `sudo docker-compose up -d postgres redis && python start_server.py`  
> **ğŸ“Š Webç•Œé¢**: http://localhost:3000 | **ğŸ“– APIæ–‡æ¡£**: http://localhost:8000/docs

## ğŸ¯ ç³»ç»Ÿå®ŒæˆçŠ¶æ€

**ç”Ÿäº§å°±ç»ª**: ğŸŸ¢ **95% å®Œæˆ** - æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·²å®ç°å¹¶ç»è¿‡æµ‹è¯•

### âœ… å·²å®Œæˆçš„æ ¸å¿ƒæ¨¡å—

#### ğŸ¤– AIåˆ†æå¼•æ“
- **æ˜¥èŠ‚å¯¹é½åˆ†æå¼•æ“**: åŸºäºå†œå†æ—¶é—´é”šç‚¹çš„å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«
- **æœºå™¨å­¦ä¹ æ¨¡å‹ç®¡ç†**: MLflowé›†æˆçš„æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **é£é™©ç®¡ç†å¼•æ“**: VaRã€CVaRå¤šç§é£é™©åº¦é‡æ–¹æ³•
- **æ¨¡å‹æ¼‚ç§»ç›‘æ§**: è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ€§èƒ½é€€åŒ–å¹¶è§¦å‘é‡è®­ç»ƒ
- **A/Bæµ‹è¯•æ¡†æ¶**: å¤šæ¨¡å‹å¯¹æ¯”å’Œç­–ç•¥ä¼˜åŒ–

#### ğŸ“Š æ•°æ®æºé›†æˆ
- **å¤šæºæ•°æ®ç®¡ç†å™¨**: Tushareã€AkShareã€æœ¬åœ°TDXæ•°æ®æ— ç¼é›†æˆ
- **æ™ºèƒ½æ•…éšœè½¬ç§»**: ç†”æ–­å™¨æ¨¡å¼ç¡®ä¿æ•°æ®è·å–çš„é«˜å¯ç”¨æ€§
- **æ•°æ®è´¨é‡å¼•æ“**: åŸºäºIsolation Forestçš„å¼‚å¸¸æ£€æµ‹å’Œæ•°æ®æ¸…æ´—
- **å®æ—¶æ•°æ®æµ**: WebSocketå®æ—¶è¡Œæƒ…æ¨é€
- **ç¼“å­˜ä¼˜åŒ–**: Rediså¤šå±‚ç¼“å­˜ç­–ç•¥

#### ğŸ—ï¸ åŸºç¡€è®¾æ–½
- **FastAPIåç«¯**: å¼‚æ­¥é«˜æ€§èƒ½APIï¼Œæ”¯æŒJWTè®¤è¯å’Œé™æµ
- **Reactå‰ç«¯**: TypeScript + Ant Designç°ä»£åŒ–äº¤äº’ç•Œé¢
- **PostgreSQLæ•°æ®åº“**: å®Œæ•´çš„æ•°æ®æ¨¡å‹å’ŒAlembicè¿ç§»
- **Celeryä»»åŠ¡é˜Ÿåˆ—**: åå°æ•°æ®å¤„ç†å’Œå®šæ—¶ä»»åŠ¡
- **Dockerå®¹å™¨åŒ–**: å®Œæ•´çš„ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆ

#### ğŸ“ˆ é«˜çº§åŠŸèƒ½
- **è‚¡ç¥¨æ± ç®¡ç†**: åŠ¨æ€è‚¡ç¥¨ç»„åˆç®¡ç†å’Œå›æµ‹
- **æœºæ„èµ„é‡‘è¿½è¸ª**: é¾™è™æ¦œåˆ†æå’Œæœºæ„å…³æ³¨åº¦è¯„åˆ†
- **äº¤äº’å¼å¯è§†åŒ–**: Plotly.jsåŠ¨æ€å›¾è¡¨å’ŒWebGLåŠ é€Ÿæ¸²æŸ“
- **å‘Šè­¦é€šçŸ¥ç³»ç»Ÿ**: å¤šæ¸ é“æ™ºèƒ½å‘Šè­¦å’Œé£é™©æç¤º
- **æˆæœ¬ä¼˜åŒ–ç®¡ç†**: äº‘èµ„æºæ™ºèƒ½è°ƒåº¦å’Œæˆæœ¬æ§åˆ¶

### ğŸ”„ æŒç»­ä¼˜åŒ–ä¸­
- **æ·±åº¦å­¦ä¹ æ¨¡å‹**: LSTMæ—¶åºé¢„æµ‹å’ŒTransformeræ¶æ„é›†æˆ
- **é‡åŒ–ç­–ç•¥å›æµ‹**: æ›´å¤šæŠ€æœ¯æŒ‡æ ‡å’Œç­–ç•¥æ¨¡æ¿
- **å¤šå¸‚åœºæ”¯æŒ**: æ¸¯è‚¡ã€ç¾è‚¡æ•°æ®æºæ‰©å±•

## ğŸŒŸ æ ¸å¿ƒåŠŸèƒ½ç‰¹è‰²

### ğŸ¤– AIé©±åŠ¨çš„æ™ºèƒ½åˆ†æ

#### æ˜¥èŠ‚å¯¹é½åˆ†æå¼•æ“
```python
# æ ¸å¿ƒAIç®—æ³•ï¼šåŸºäºå†œå†æ—¶é—´é”šç‚¹çš„æ¨¡å¼è¯†åˆ«
from stock_analysis_system.analysis.spring_festival_engine import SpringFestivalAlignmentEngine

engine = SpringFestivalAlignmentEngine(window_days=60)
# è‡ªåŠ¨è¯†åˆ«å­£èŠ‚æ€§æ¨¡å¼ï¼Œç½®ä¿¡åº¦è¯„åˆ†ï¼Œä¸€è‡´æ€§åˆ†æ
seasonal_pattern = engine.identify_seasonal_patterns(aligned_data)
# AIç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼šä¹°å…¥/å–å‡º/æŒæœ‰ï¼Œé™„å¸¦å¼ºåº¦è¯„åˆ†
signals = engine.generate_trading_signals(seasonal_pattern, current_position)
```

#### æœºå™¨å­¦ä¹ æ¨¡å‹ç®¡ç†
```python
# MLflowé›†æˆçš„å®Œæ•´MLç”Ÿå‘½å‘¨æœŸç®¡ç†
from stock_analysis_system.analysis.ml_model_manager import MLModelManager

model_manager = MLModelManager()
# è‡ªåŠ¨æ¨¡å‹è®­ç»ƒã€ç‰ˆæœ¬æ§åˆ¶ã€A/Bæµ‹è¯•
model_manager.train_model(data, model_type="spring_festival_predictor")
# æ¨¡å‹æ¼‚ç§»æ£€æµ‹å’Œè‡ªåŠ¨é‡è®­ç»ƒ
drift_score = model_manager.detect_model_drift(new_data)
```

#### é£é™©ç®¡ç†å¼•æ“
```python
# å¤šç»´åº¦é£é™©è¯„ä¼°ï¼šVaRã€CVaRã€æœ€å¤§å›æ’¤
from stock_analysis_system.analysis.risk_management_engine import RiskManagementEngine

risk_engine = RiskManagementEngine()
# å†å²æ³•ã€å‚æ•°æ³•ã€è’™ç‰¹å¡æ´›ä¸‰ç§VaRè®¡ç®—æ–¹æ³•
var_results = risk_engine.calculate_var(portfolio_data, methods=['historical', 'parametric', 'monte_carlo'])
# å­£èŠ‚æ€§é£é™©è¯„åˆ†å’ŒæµåŠ¨æ€§é£é™©åˆ†æ
seasonal_risk = risk_engine.calculate_seasonal_risk_score(stock_data, spring_festival_dates)
```

### ğŸ“Š å¤šæºæ•°æ®æ™ºèƒ½é›†æˆ

#### æ•°æ®æºé…ç½®ä¸ç®¡ç†
```python
# æ”¯æŒçš„æ•°æ®æºï¼šTushareã€AkShareã€æœ¬åœ°TDXã€Wind
DATA_SOURCES = {
    "tushare": {
        "token": "your_tushare_token",
        "priority": 1,
        "timeout": 30,
        "retry_attempts": 3
    },
    "akshare": {
        "priority": 2,
        "timeout": 30,
        "rate_limit": 200  # requests per minute
    },
    "local_tdx": {
        "path": "/data/tdx",
        "priority": 3,
        "enabled": True
    }
}
```

#### æ™ºèƒ½æ•…éšœè½¬ç§»
```python
# ç†”æ–­å™¨æ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®æºå¥åº·çŠ¶æ€å¹¶åˆ‡æ¢
from stock_analysis_system.data.data_source_manager import DataSourceManager

data_manager = DataSourceManager()
# è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ•°æ®æºï¼Œæ•…éšœæ—¶æ— ç¼åˆ‡æ¢
stock_data = await data_manager.get_stock_data("000001.SZ", start_date, end_date)
# å®æ—¶ç›‘æ§æ•°æ®æºå¥åº·çŠ¶æ€
health_status = data_manager.get_health_status()
```

#### æ•°æ®è´¨é‡ä¿è¯
```python
# åŸºäºæœºå™¨å­¦ä¹ çš„æ•°æ®è´¨é‡æ£€æµ‹
from stock_analysis_system.data.data_quality_engine import EnhancedDataQualityEngine

quality_engine = EnhancedDataQualityEngine()
# Isolation Forestå¼‚å¸¸æ£€æµ‹
quality_engine.train_ml_detector(stock_data, feature_columns=['open', 'high', 'low', 'close', 'volume'])
# è‡ªåŠ¨æ•°æ®æ¸…æ´—å’Œè´¨é‡è¯„åˆ†
quality_report = quality_engine.validate_data(stock_data)
cleaned_data = quality_engine.clean_data(stock_data, quality_report)
```

### ğŸ¯ ç­–ç•¥é…ç½®ä¸ä¼˜åŒ–

#### äº¤æ˜“ç­–ç•¥é…ç½®
```python
# å¯é…ç½®çš„äº¤æ˜“ç­–ç•¥å‚æ•°
STRATEGY_CONFIG = {
    "spring_festival_strategy": {
        "window_days": 60,           # åˆ†æçª—å£ï¼šæ˜¥èŠ‚å‰åå¤©æ•°
        "confidence_threshold": 0.7,  # ä¿¡å·ç½®ä¿¡åº¦é˜ˆå€¼
        "pattern_strength_min": 0.6,  # æœ€å°æ¨¡å¼å¼ºåº¦
        "consistency_score_min": 0.5, # æœ€å°ä¸€è‡´æ€§è¯„åˆ†
        "position_sizing": {
            "method": "kelly",        # ä»“ä½ç®¡ç†ï¼škelly/fixed/volatility
            "max_position": 0.1,      # æœ€å¤§å•è‚¡ä»“ä½
            "risk_per_trade": 0.02    # å•ç¬”äº¤æ˜“é£é™©
        }
    }
}
```

#### é£é™©æ§åˆ¶å‚æ•°
```python
# å¤šå±‚æ¬¡é£é™©æ§åˆ¶é…ç½®
RISK_CONFIG = {
    "var_calculation": {
        "confidence_levels": [0.95, 0.99],  # VaRç½®ä¿¡æ°´å¹³
        "holding_period": 1,                # æŒæœ‰æœŸï¼ˆå¤©ï¼‰
        "methods": ["historical", "parametric", "monte_carlo"]
    },
    "position_limits": {
        "max_portfolio_var": 0.05,          # ç»„åˆæœ€å¤§VaR
        "max_sector_exposure": 0.3,         # æœ€å¤§è¡Œä¸šæš´éœ²
        "max_single_stock": 0.1             # æœ€å¤§å•è‚¡æƒé‡
    }
}
```

### ğŸ“ˆ å®æ—¶ç›‘æ§ä¸å‘Šè­¦

#### æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ
```python
# å¤šç»´åº¦å‘Šè­¦é…ç½®
ALERT_CONFIG = {
    "price_alerts": {
        "price_change_threshold": 0.05,     # ä»·æ ¼å˜åŠ¨é˜ˆå€¼
        "volume_spike_threshold": 2.0,      # æˆäº¤é‡å¼‚å¸¸å€æ•°
        "technical_signals": ["ma_cross", "rsi_oversold"]
    },
    "risk_alerts": {
        "var_breach_threshold": 1.2,        # VaRçªç ´å€æ•°
        "drawdown_threshold": 0.1,          # æœ€å¤§å›æ’¤é˜ˆå€¼
        "correlation_spike": 0.8            # ç›¸å…³æ€§å¼‚å¸¸é˜ˆå€¼
    },
    "notification_channels": ["email", "webhook", "sms"]
}
```

### ğŸ”§ ç³»ç»Ÿé…ç½®ä¸éƒ¨ç½²

#### ç¯å¢ƒé…ç½®
```bash
# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_PORT=5432
DB_NAME=stock_analysis
DB_USER=postgres
DB_PASSWORD=your_secure_password

# Redisç¼“å­˜é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_MAX_CONNECTIONS=50

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
CORS_ORIGINS=http://localhost:3000

# æ•°æ®æºé…ç½®
TUSHARE_TOKEN=your_tushare_token
AKSHARE_TIMEOUT=30
DATA_REQUESTS_PER_MINUTE=200
```

#### Dockeréƒ¨ç½²é…ç½®
```yaml
# docker-compose.yml æ ¸å¿ƒæœåŠ¡
services:
  app:          # FastAPIåº”ç”¨
  postgres:     # PostgreSQLæ•°æ®åº“
  redis:        # Redisç¼“å­˜
  celery-worker: # åå°ä»»åŠ¡å¤„ç†
  celery-beat:  # å®šæ—¶ä»»åŠ¡è°ƒåº¦
  frontend:     # Reactå‰ç«¯ç•Œé¢
```

## ğŸ—ï¸ Architecture

The system follows a four-layer architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Presentation Layer                          â”‚
â”‚  React 18 + TypeScript â€¢ Ant Design â€¢ Plotly.js Charts    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Application Layer                           â”‚
â”‚  FastAPI â€¢ Stock Pool Manager â€¢ Alert Engine â€¢ API Gateway â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Analysis Layer                              â”‚
â”‚  Spring Festival Engine â€¢ Risk Engine â€¢ ML Models â€¢ Pluginsâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Data Layer                                  â”‚
â”‚  PostgreSQL â€¢ Redis Cache â€¢ ETL Pipeline â€¢ Data Sources    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.9+ (æ¨è3.11)
- **Docker**: 20.10+ & Docker Compose 2.0+
- **å†…å­˜**: æœ€å°‘4GBï¼Œæ¨è8GB+
- **å­˜å‚¨**: æœ€å°‘10GBå¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥ï¼ˆç”¨äºæ•°æ®è·å–ï¼‰

### âš¡ ä¸€é”®éƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/your-org/stock-analysis-system.git
cd stock-analysis-system

# 2. ä¸€é”®å¯åŠ¨ï¼ˆè‡ªåŠ¨å¤„ç†æ‰€æœ‰ä¾èµ–ï¼‰
make setup-dev && make docker-up && python start_server.py

# 3. è®¿é—®ç³»ç»Ÿ
# Webç•Œé¢: http://localhost:3000
# APIæ–‡æ¡£: http://localhost:8000/docs
```

### ğŸ”§ è¯¦ç»†å®‰è£…æ­¥éª¤

#### æ­¥éª¤1: ç¯å¢ƒå‡†å¤‡
```bash
# åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### æ­¥éª¤2: æ•°æ®æºé…ç½®
```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œæ·»åŠ æ•°æ®æºtoken
nano .env
```

**é‡è¦é…ç½®é¡¹**:
```bash
# Tushareé…ç½®ï¼ˆæ¨èï¼‰
TUSHARE_TOKEN=your_tushare_token_here  # ä» https://tushare.pro è·å–

# æ•°æ®åº“é…ç½®
DB_PASSWORD=your_secure_password       # ä¿®æ”¹é»˜è®¤å¯†ç 

# APIé…ç½®
SECRET_KEY=your-super-secret-key       # ç”Ÿäº§ç¯å¢ƒå¿…é¡»ä¿®æ”¹
```

#### æ­¥éª¤3: å¯åŠ¨åŸºç¡€æœåŠ¡
```bash
# å¯åŠ¨PostgreSQLå’ŒRedis
sudo docker-compose up -d postgres redis

# éªŒè¯æœåŠ¡çŠ¶æ€
sudo docker-compose ps
# åº”è¯¥æ˜¾ç¤º: postgres (healthy), redis (healthy)
```

#### æ­¥éª¤4: åˆå§‹åŒ–æ•°æ®åº“
```bash
# è¿è¡Œæ•°æ®åº“è¿ç§»
make db-upgrade

# éªŒè¯æ•°æ®åº“è¡¨åˆ›å»º
sudo docker-compose exec postgres psql -U postgres -d stock_analysis -c "\dt"
```

#### æ­¥éª¤5: å¯åŠ¨åº”ç”¨æœåŠ¡
```bash
# å¯åŠ¨åç«¯API
python start_server.py

# æ–°ç»ˆç«¯å¯åŠ¨å‰ç«¯ï¼ˆå¯é€‰ï¼‰
cd frontend && npm install && npm start

# å¯åŠ¨åå°ä»»åŠ¡å¤„ç†ï¼ˆå¯é€‰ï¼‰
celery -A stock_analysis_system.etl.celery_app worker --loglevel=info
```

### ğŸ¯ å¿«é€ŸéªŒè¯

#### 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
```bash
# APIå¥åº·æ£€æŸ¥
curl http://localhost:8000/health
# é¢„æœŸè¾“å‡º: {"status":"ok","database":"healthy","version":"0.1.0"}

# æ•°æ®æºè¿æ¥æµ‹è¯•
python -c "
from stock_analysis_system.data.data_source_manager import DataSourceManager
import asyncio
async def test():
    dm = DataSourceManager()
    health = dm.get_health_status()
    print(health)
asyncio.run(test())
"
```

#### 2. æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
```bash
# è¿è¡Œæ˜¥èŠ‚åˆ†ææ¼”ç¤º
python test_spring_festival_demo.py

# è¿è¡Œæ•°æ®è´¨é‡æ£€æµ‹æ¼”ç¤º
python test_data_quality_demo.py

# è¿è¡Œå®Œæ•´APIæµ‹è¯•
python test_api.py
```

#### 3. Webç•Œé¢éªŒè¯
- è®¿é—® http://localhost:3000
- æœç´¢è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001ï¼‰
- æŸ¥çœ‹æ˜¥èŠ‚åˆ†æå›¾è¡¨
- éªŒè¯æ•°æ®åŠ è½½å’Œå›¾è¡¨äº¤äº’

### ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

```bash
# æœåŠ¡ç®¡ç†
make docker-up          # å¯åŠ¨DockeræœåŠ¡
make docker-down        # åœæ­¢DockeræœåŠ¡
make start-server       # å¯åŠ¨APIæœåŠ¡å™¨
make test-api          # æµ‹è¯•APIè¿æ¥

# å¼€å‘å·¥å…·
make setup-dev         # è®¾ç½®å¼€å‘ç¯å¢ƒ
make test             # è¿è¡Œæµ‹è¯•å¥—ä»¶
make lint             # ä»£ç è´¨é‡æ£€æŸ¥
make format           # ä»£ç æ ¼å¼åŒ–

# æ•°æ®åº“ç®¡ç†
make db-upgrade       # å‡çº§æ•°æ®åº“
make db-downgrade     # å›æ»šæ•°æ®åº“

# å‰ç«¯ç®¡ç†
make frontend-install # å®‰è£…å‰ç«¯ä¾èµ–
make frontend-start   # å¯åŠ¨å‰ç«¯æœåŠ¡
make frontend-build   # æ„å»ºç”Ÿäº§ç‰ˆæœ¬
```

### ğŸ” æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜è§£å†³

**1. Dockeræƒé™é—®é¢˜**
```bash
# ä¸´æ—¶è§£å†³
sudo docker-compose up -d postgres redis

# æ°¸ä¹…è§£å†³
sudo usermod -aG docker $USER
newgrp docker  # æˆ–é‡æ–°ç™»å½•
```

**2. ç«¯å£å ç”¨é—®é¢˜**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tlnp | grep :5432
sudo netstat -tlnp | grep :6379

# ä¿®æ”¹docker-compose.ymlç«¯å£æ˜ å°„
# "15432:5432" å’Œ "16379:6379"
```

**3. æ•°æ®æºè¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping tushare.pro

# éªŒè¯tokenæœ‰æ•ˆæ€§
python -c "
import tushare as ts
ts.set_token('your_token')
pro = ts.pro_api()
print(pro.stock_basic().head())
"
```

**4. å‰ç«¯å¯åŠ¨å¤±è´¥**
```bash
# æ¸…ç†å¹¶é‡æ–°å®‰è£…
cd frontend
rm -rf node_modules package-lock.json
npm install

# æ£€æŸ¥Node.jsç‰ˆæœ¬
node --version  # éœ€è¦16+
```

### ğŸ“Š ç³»ç»Ÿç›‘æ§

#### å®æ—¶ç›‘æ§é¢æ¿
```bash
# ç³»ç»ŸçŠ¶æ€ç›‘æ§
curl http://localhost:8000/api/v1/system/status

# æ•°æ®æºå¥åº·ç›‘æ§
curl http://localhost:8000/api/v1/data/health

# æ€§èƒ½æŒ‡æ ‡ç›‘æ§
curl http://localhost:8000/api/v1/metrics
```

#### æ—¥å¿—æŸ¥çœ‹
```bash
# APIæœåŠ¡æ—¥å¿—
tail -f logs/api.log

# æ•°æ®å¤„ç†æ—¥å¿—
tail -f logs/data_processing.log

# DockeræœåŠ¡æ—¥å¿—
sudo docker-compose logs -f postgres
sudo docker-compose logs -f redis
```

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„ä¸æ¨¡å—ä»‹ç»

### ğŸ“ æ•´ä½“æ¶æ„

ç³»ç»Ÿé‡‡ç”¨å››å±‚æ¶æ„è®¾è®¡ï¼Œç¡®ä¿é«˜æ€§èƒ½ã€é«˜å¯ç”¨å’Œæ˜“ç»´æŠ¤ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Presentation Layer                          â”‚
â”‚  React 18 + TypeScript â€¢ Ant Design â€¢ Plotly.js Charts    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Application Layer                           â”‚
â”‚  FastAPI â€¢ Stock Pool Manager â€¢ Alert Engine â€¢ API Gateway â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Analysis Layer                              â”‚
â”‚  Spring Festival Engine â€¢ Risk Engine â€¢ ML Models â€¢ Pluginsâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 Data Layer                                  â”‚
â”‚  PostgreSQL â€¢ Redis Cache â€¢ ETL Pipeline â€¢ Data Sources    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§© æ ¸å¿ƒæ¨¡å—è¯¦è§£

#### ğŸ“Š æ•°æ®å±‚ (Data Layer)

**1. æ•°æ®æºç®¡ç†å™¨ (DataSourceManager)**
```python
# ä½ç½®: stock_analysis_system/data/data_source_manager.py
# åŠŸèƒ½: å¤šæ•°æ®æºé›†æˆã€æ™ºèƒ½æ•…éšœè½¬ç§»ã€å¥åº·ç›‘æ§
# æ”¯æŒ: Tushareã€AkShareã€æœ¬åœ°TDXã€Windæ•°æ®æº
```

**2. æ•°æ®è´¨é‡å¼•æ“ (DataQualityEngine)**
```python
# ä½ç½®: stock_analysis_system/data/data_quality_engine.py
# åŠŸèƒ½: MLå¼‚å¸¸æ£€æµ‹ã€æ•°æ®æ¸…æ´—ã€è´¨é‡è¯„åˆ†
# ç®—æ³•: Isolation Forestã€ç»Ÿè®¡æ£€éªŒã€è§„åˆ™å¼•æ“
```

**3. ç¼“å­˜ç®¡ç†å™¨ (CacheManager)**
```python
# ä½ç½®: stock_analysis_system/data/cache_manager.py
# åŠŸèƒ½: Rediså¤šå±‚ç¼“å­˜ã€ç¼“å­˜é¢„çƒ­ã€å¤±æ•ˆç­–ç•¥
# ç‰¹æ€§: åˆ†å¸ƒå¼ç¼“å­˜ã€å‹ç¼©å­˜å‚¨ã€æ™ºèƒ½è¿‡æœŸ
```

**4. ETLç®¡é“ (ETL Pipeline)**
```python
# ä½ç½®: stock_analysis_system/etl/
# åŠŸèƒ½: æ•°æ®æŠ½å–ã€è½¬æ¢ã€åŠ è½½ã€ä»»åŠ¡è°ƒåº¦
# æŠ€æœ¯: Celeryã€å¼‚æ­¥å¤„ç†ã€é”™è¯¯é‡è¯•
```

#### ğŸ¤– åˆ†æå±‚ (Analysis Layer)

**1. æ˜¥èŠ‚å¯¹é½å¼•æ“ (SpringFestivalEngine)**
```python
# ä½ç½®: stock_analysis_system/analysis/spring_festival_engine.py
# æ ¸å¿ƒåŠŸèƒ½:
# - å†œå†æ—¶é—´é”šç‚¹å¯¹é½
# - å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«
# - äº¤æ˜“ä¿¡å·ç”Ÿæˆ
# - ç½®ä¿¡åº¦è¯„ä¼°

# ä½¿ç”¨ç¤ºä¾‹:
engine = SpringFestivalAlignmentEngine(window_days=60)
pattern = engine.identify_seasonal_patterns(aligned_data)
signals = engine.generate_trading_signals(pattern, current_position)
```

**2. æœºå™¨å­¦ä¹ æ¨¡å‹ç®¡ç† (MLModelManager)**
```python
# ä½ç½®: stock_analysis_system/analysis/ml_model_manager.py
# æ ¸å¿ƒåŠŸèƒ½:
# - MLflowé›†æˆçš„æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
# - æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶å’ŒA/Bæµ‹è¯•
# - æ¨¡å‹æ¼‚ç§»æ£€æµ‹å’Œè‡ªåŠ¨é‡è®­ç»ƒ
# - æ¨¡å‹æ€§èƒ½ç›‘æ§

# ä½¿ç”¨ç¤ºä¾‹:
model_manager = MLModelManager()
model_info = await model_manager.register_model(model, metrics, tags)
drift_score = await model_manager.detect_model_drift(new_data, reference_data)
```

**3. é£é™©ç®¡ç†å¼•æ“ (RiskManagementEngine)**
```python
# ä½ç½®: stock_analysis_system/analysis/risk_management_engine.py
# æ ¸å¿ƒåŠŸèƒ½:
# - å¤šç§VaRè®¡ç®—æ–¹æ³• (å†å²æ³•ã€å‚æ•°æ³•ã€è’™ç‰¹å¡æ´›)
# - é£é™©æŒ‡æ ‡è®¡ç®— (å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ã€CVaR)
# - æµåŠ¨æ€§é£é™©è¯„ä¼°
# - å­£èŠ‚æ€§é£é™©åˆ†æ

# ä½¿ç”¨ç¤ºä¾‹:
risk_engine = EnhancedRiskManagementEngine()
risk_metrics = await risk_engine.calculate_comprehensive_risk_metrics(price_data)
```

**4. æœºæ„æ•°æ®æ”¶é›†å™¨ (InstitutionalDataCollector)**
```python
# ä½ç½®: stock_analysis_system/analysis/institutional_data_collector.py
# åŠŸèƒ½: é¾™è™æ¦œæ•°æ®ã€æœºæ„æŒä»“ã€èµ„é‡‘æµå‘åˆ†æ
```

**5. ä»“ä½ç®¡ç†å¼•æ“ (PositionSizingEngine)**
```python
# ä½ç½®: stock_analysis_system/analysis/position_sizing_engine.py
# åŠŸèƒ½: Kellyå…¬å¼ã€é£é™©å¹³ä»·ã€æ³¢åŠ¨ç‡ç›®æ ‡ä»“ä½ç®¡ç†
```

#### ğŸŒ åº”ç”¨å±‚ (Application Layer)

**1. FastAPIåç«¯ (API Layer)**
```python
# ä½ç½®: stock_analysis_system/api/
# åŠŸèƒ½: RESTful APIã€WebSocketå®æ—¶æ•°æ®ã€JWTè®¤è¯
# ç‰¹æ€§: å¼‚æ­¥å¤„ç†ã€è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆã€è¯·æ±‚é™æµ
```

**2. å¯è§†åŒ–å¼•æ“ (Visualization)**
```python
# ä½ç½®: stock_analysis_system/visualization/
# åŠŸèƒ½: æ˜¥èŠ‚åˆ†æå›¾è¡¨ã€äº¤äº’å¼å¯è§†åŒ–ã€å›¾è¡¨å¯¼å‡º
# æŠ€æœ¯: Plotly.jsã€WebGLåŠ é€Ÿã€å“åº”å¼è®¾è®¡
```

**3. ç›‘æ§ç³»ç»Ÿ (Monitoring)**
```python
# ä½ç½®: stock_analysis_system/monitoring/
# åŠŸèƒ½: ç³»ç»Ÿå¥åº·ç›‘æ§ã€æ€§èƒ½æŒ‡æ ‡ã€å‘Šè­¦é€šçŸ¥
# æŠ€æœ¯: Prometheusã€Grafanaã€ELK Stack
```

#### ğŸ–¥ï¸ è¡¨ç°å±‚ (Presentation Layer)

**Reactå‰ç«¯åº”ç”¨**
```typescript
// ä½ç½®: frontend/src/
// æŠ€æœ¯æ ˆ: React 18 + TypeScript + Ant Design
// åŠŸèƒ½: è‚¡ç¥¨æœç´¢ã€å›¾è¡¨å±•ç¤ºã€å‚æ•°é…ç½®ã€ç»“æœå¯¼å‡º
```

### ğŸ”§ é«˜çº§é…ç½®ä¸è°ƒä¼˜

#### 1. æ•°æ®æºä¼˜å…ˆçº§é…ç½®
```python
# config/data_sources.py
DATA_SOURCE_PRIORITY = {
    "realtime": ["tushare", "akshare"],      # å®æ—¶æ•°æ®ä¼˜å…ˆçº§
    "historical": ["local_tdx", "tushare"],  # å†å²æ•°æ®ä¼˜å…ˆçº§
    "fundamental": ["tushare", "wind"],      # åŸºæœ¬é¢æ•°æ®ä¼˜å…ˆçº§
}

# æ•…éšœè½¬ç§»é…ç½®
FAILOVER_CONFIG = {
    "circuit_breaker": {
        "failure_threshold": 5,    # å¤±è´¥é˜ˆå€¼
        "recovery_timeout": 60,    # æ¢å¤è¶…æ—¶(ç§’)
    },
    "retry_policy": {
        "max_attempts": 3,         # æœ€å¤§é‡è¯•æ¬¡æ•°
        "backoff_factor": 2,       # é€€é¿å› å­
        "jitter": True,            # æ·»åŠ éšæœºæŠ–åŠ¨
    }
}
```

#### 2. AIæ¨¡å‹é…ç½®ä¼˜åŒ–
```python
# config/ml_config.py
ML_MODEL_CONFIG = {
    "spring_festival_predictor": {
        "algorithm": "random_forest",
        "hyperparameters": {
            "n_estimators": 100,
            "max_depth": 10,
            "min_samples_split": 5,
            "random_state": 42
        },
        "feature_engineering": {
            "technical_indicators": ["ma", "rsi", "macd", "bollinger"],
            "seasonal_features": ["days_to_sf", "sf_year", "sf_weekday"],
            "market_features": ["volume_ratio", "price_change", "volatility"]
        },
        "training_schedule": {
            "frequency": "monthly",
            "retrain_threshold": 0.1,  # æ¨¡å‹æ¼‚ç§»é˜ˆå€¼
            "validation_split": 0.2
        }
    }
}
```

#### 3. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
```python
# config/cache_config.py
CACHE_STRATEGIES = {
    "stock_data": {
        "ttl": 3600,                    # 1å°æ—¶ç¼“å­˜
        "compression": "gzip",          # æ•°æ®å‹ç¼©
        "serialization": "pickle",      # åºåˆ—åŒ–æ–¹å¼
        "key_pattern": "stock:{symbol}:{date}",
        "preload_patterns": [           # é¢„åŠ è½½æ¨¡å¼
            "popular_stocks",           # çƒ­é—¨è‚¡ç¥¨
            "index_components",         # æŒ‡æ•°æˆåˆ†è‚¡
            "recent_analysis"           # æœ€è¿‘åˆ†æç»“æœ
        ]
    },
    "analysis_results": {
        "ttl": 86400,                   # 24å°æ—¶ç¼“å­˜
        "invalidation_triggers": [      # å¤±æ•ˆè§¦å‘å™¨
            "new_trading_day",
            "model_update",
            "parameter_change"
        ]
    }
}
```

#### 4. æ€§èƒ½ç›‘æ§é…ç½®
```python
# config/monitoring_config.py
MONITORING_CONFIG = {
    "metrics": {
        "api_response_time": {
            "buckets": [0.1, 0.5, 1.0, 2.0, 5.0],  # å“åº”æ—¶é—´åˆ†æ¡¶
            "labels": ["endpoint", "method", "status"]
        },
        "data_source_health": {
            "check_interval": 30,        # å¥åº·æ£€æŸ¥é—´éš”(ç§’)
            "timeout": 10,               # æ£€æŸ¥è¶…æ—¶
            "failure_threshold": 3       # å¤±è´¥é˜ˆå€¼
        },
        "model_performance": {
            "track_metrics": ["accuracy", "precision", "recall", "f1"],
            "alert_thresholds": {
                "accuracy": 0.7,         # å‡†ç¡®ç‡å‘Šè­¦é˜ˆå€¼
                "drift_score": 0.1       # æ¼‚ç§»å‘Šè­¦é˜ˆå€¼
            }
        }
    },
    "alerts": {
        "channels": ["email", "webhook", "slack"],
        "severity_levels": ["critical", "warning", "info"],
        "rate_limiting": {
            "max_alerts_per_hour": 10,
            "cooldown_period": 300       # å†·å´æœŸ(ç§’)
        }
    }
}
```

### ğŸ“ˆ ä½¿ç”¨æœ€ä½³å®è·µ

#### 1. æ•°æ®è·å–æœ€ä½³å®è·µ
```python
# æ¨èçš„æ•°æ®è·å–æ¨¡å¼
async def get_stock_data_optimized(symbol: str, start_date: date, end_date: date):
    """ä¼˜åŒ–çš„è‚¡ç¥¨æ•°æ®è·å–"""
    
    # 1. æ£€æŸ¥ç¼“å­˜
    cached_data = await cache_manager.get(f"stock:{symbol}:{start_date}:{end_date}")
    if cached_data:
        return cached_data
    
    # 2. æ‰¹é‡è·å–ï¼Œå‡å°‘APIè°ƒç”¨
    if (end_date - start_date).days > 30:
        # å¤§èŒƒå›´æ•°æ®ä½¿ç”¨æœ¬åœ°TDX
        data = await data_manager.get_stock_data(symbol, start_date, end_date, source="local_tdx")
    else:
        # å°èŒƒå›´æ•°æ®ä½¿ç”¨åœ¨çº¿API
        data = await data_manager.get_stock_data(symbol, start_date, end_date, source="tushare")
    
    # 3. æ•°æ®è´¨é‡æ£€æŸ¥
    quality_report = quality_engine.validate_data(data)
    if quality_report.overall_score < 0.8:
        # è´¨é‡ä¸ä½³æ—¶å°è¯•å…¶ä»–æ•°æ®æº
        data = await data_manager.get_stock_data(symbol, start_date, end_date, source="akshare")
    
    # 4. ç¼“å­˜ç»“æœ
    await cache_manager.set(f"stock:{symbol}:{start_date}:{end_date}", data, ttl=3600)
    
    return data
```

#### 2. AIåˆ†ææœ€ä½³å®è·µ
```python
# æ¨èçš„AIåˆ†ææµç¨‹
async def analyze_stock_comprehensive(symbol: str, years: List[int]):
    """ç»¼åˆè‚¡ç¥¨åˆ†æ"""
    
    # 1. æ•°æ®å‡†å¤‡
    stock_data = await get_stock_data_optimized(symbol, 
                                               date(min(years), 1, 1), 
                                               date(max(years), 12, 31))
    
    # 2. æ•°æ®è´¨é‡æ£€æŸ¥å’Œæ¸…æ´—
    quality_report = quality_engine.validate_data(stock_data)
    cleaned_data = quality_engine.clean_data(stock_data, quality_report)
    
    # 3. æ˜¥èŠ‚å¯¹é½åˆ†æ
    sf_engine = SpringFestivalAlignmentEngine(window_days=60)
    aligned_data = sf_engine.align_to_spring_festival(cleaned_data, years)
    seasonal_pattern = sf_engine.identify_seasonal_patterns(aligned_data)
    
    # 4. é£é™©è¯„ä¼°
    risk_engine = EnhancedRiskManagementEngine()
    risk_metrics = await risk_engine.calculate_comprehensive_risk_metrics(cleaned_data)
    
    # 5. äº¤æ˜“ä¿¡å·ç”Ÿæˆ
    current_position = sf_engine.get_current_position(symbol)
    signals = sf_engine.generate_trading_signals(seasonal_pattern, current_position)
    
    # 6. ç»“æœæ•´åˆ
    analysis_result = {
        "symbol": symbol,
        "data_quality": quality_report.overall_score,
        "seasonal_pattern": seasonal_pattern,
        "risk_metrics": risk_metrics,
        "trading_signals": signals,
        "analysis_timestamp": datetime.now()
    }
    
    return analysis_result
```

#### 3. ç³»ç»Ÿç›‘æ§æœ€ä½³å®è·µ
```python
# æ¨èçš„ç›‘æ§è®¾ç½®
async def setup_monitoring():
    """è®¾ç½®ç³»ç»Ÿç›‘æ§"""
    
    # 1. æ•°æ®æºå¥åº·ç›‘æ§
    health_monitor = HealthMonitor()
    await health_monitor.start_monitoring([
        "tushare", "akshare", "local_tdx"
    ], check_interval=30)
    
    # 2. æ¨¡å‹æ€§èƒ½ç›‘æ§
    model_monitor = ModelPerformanceMonitor()
    await model_monitor.track_models([
        "spring_festival_predictor",
        "risk_assessment_model"
    ])
    
    # 3. ç³»ç»Ÿèµ„æºç›‘æ§
    resource_monitor = ResourceMonitor()
    await resource_monitor.track_resources([
        "cpu_usage", "memory_usage", "disk_usage",
        "database_connections", "cache_hit_rate"
    ])
    
    # 4. å‘Šè­¦è§„åˆ™è®¾ç½®
    alert_manager = AlertManager()
    await alert_manager.setup_alerts([
        {
            "name": "data_source_failure",
            "condition": "data_source_health < 0.5",
            "severity": "critical",
            "channels": ["email", "slack"]
        },
        {
            "name": "model_drift_detected",
            "condition": "model_drift_score > 0.1",
            "severity": "warning",
            "channels": ["email"]
        }
    ])
```

### ğŸš€ éƒ¨ç½²ä¸è¿ç»´

#### Dockerç”Ÿäº§éƒ¨ç½²
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: stock-analysis-system:latest
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    environment:
      - ENVIRONMENT=production
      - DB_POOL_SIZE=20
      - REDIS_MAX_CONNECTIONS=100
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```

#### Kuberneteséƒ¨ç½²
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stock-analysis-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: stock-analysis-api
  template:
    metadata:
      labels:
        app: stock-analysis-api
    spec:
      containers:
      - name: api
        image: stock-analysis-system:latest
        ports:
        - containerPort: 8000
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: host
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

## ğŸ“Š ä½¿ç”¨æŒ‡å—ä¸é…ç½®

### ğŸ”§ æ•°æ®æºé…ç½®

#### 1. Tushareé…ç½®ï¼ˆæ¨èä¸»æ•°æ®æºï¼‰
```bash
# åœ¨.envæ–‡ä»¶ä¸­é…ç½®
TUSHARE_TOKEN=your_tushare_token_here
TUSHARE_TIMEOUT=30
TUSHARE_RETRY_ATTEMPTS=3

# è·å–Tushare Tokenï¼š
# 1. æ³¨å†Œ https://tushare.pro/register
# 2. å®åè®¤è¯åè·å–token
# 3. æ ¹æ®ç§¯åˆ†ç­‰çº§äº«å—ä¸åŒAPIæƒé™
```

```python
# ä»£ç ä¸­ä½¿ç”¨
from stock_analysis_system.data.data_source_manager import DataSourceManager

data_manager = DataSourceManager()
# è‡ªåŠ¨ä½¿ç”¨Tushareä½œä¸ºä¸»æ•°æ®æº
stock_data = await data_manager.get_stock_data("000001.SZ", start_date, end_date)
```

#### 2. AkShareé…ç½®ï¼ˆå…è´¹å¤‡ç”¨æ•°æ®æºï¼‰
```bash
# AkShareæ— éœ€tokenï¼Œä½†æœ‰é¢‘ç‡é™åˆ¶
AKSHARE_TIMEOUT=30
DATA_REQUESTS_PER_MINUTE=200  # å»ºè®®ä¸è¶…è¿‡200æ¬¡/åˆ†é’Ÿ
```

```python
# å½“Tushareä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°AkShare
# æ”¯æŒçš„æ•°æ®ç±»å‹ï¼š
# - æ—¥çº¿æ•°æ®ï¼šå¼€é«˜ä½æ”¶ã€æˆäº¤é‡ã€æˆäº¤é¢
# - é¾™è™æ¦œæ•°æ®ï¼šæœºæ„ä¹°å–æ˜ç»†
# - èµ„é‡‘æµå‘ï¼šä¸»åŠ›èµ„é‡‘å‡€æµå…¥
# - ETFæ•°æ®ï¼šETFå‡€å€¼ã€æŒä»“æ˜ç»†
```

#### 3. æœ¬åœ°TDXæ•°æ®é…ç½®
```bash
# é…ç½®æœ¬åœ°é€šè¾¾ä¿¡æ•°æ®è·¯å¾„
LOCAL_TDX_PATH=/data/tdx
LOCAL_TDX_ENABLED=true
```

```python
# æœ¬åœ°æ•°æ®ä¼˜åŠ¿ï¼š
# - æ— ç½‘ç»œä¾èµ–ï¼Œå“åº”é€Ÿåº¦å¿«
# - å†å²æ•°æ®å®Œæ•´ï¼Œæ”¯æŒå¤æƒå¤„ç†
# - é€‚åˆå¤§æ‰¹é‡å†å²æ•°æ®åˆ†æ
```

#### 4. æ•°æ®æºå¥åº·ç›‘æ§
```python
# å®æ—¶ç›‘æ§æ•°æ®æºçŠ¶æ€
health_status = data_manager.get_health_status()
for source, health in health_status.items():
    print(f"{source}: {health.status.value}")
    print(f"  å¯é æ€§è¯„åˆ†: {health.reliability_score:.2f}")
    print(f"  å“åº”æ—¶é—´: {health.response_time:.2f}ms")
    print(f"  é”™è¯¯ç‡: {health.error_rate:.2%}")
```

### ğŸ¤– AIåŠŸèƒ½ä½¿ç”¨æŒ‡å—

#### 1. æ˜¥èŠ‚å¯¹é½åˆ†æï¼ˆæ ¸å¿ƒAIåŠŸèƒ½ï¼‰
```python
from stock_analysis_system.analysis.spring_festival_engine import SpringFestivalAlignmentEngine

# åˆå§‹åŒ–åˆ†æå¼•æ“
engine = SpringFestivalAlignmentEngine(
    window_days=60,              # åˆ†æçª—å£ï¼šæ˜¥èŠ‚å‰åå„60å¤©
    min_years=3,                 # æœ€å°‘éœ€è¦3å¹´æ•°æ®
    confidence_threshold=0.7     # ä¿¡å·ç½®ä¿¡åº¦é˜ˆå€¼
)

# æ‰§è¡Œæ˜¥èŠ‚å¯¹é½åˆ†æ
stock_data = await data_manager.get_stock_data("000001.SZ", date(2020,1,1), date(2024,12,31))
aligned_data = engine.align_to_spring_festival(stock_data, years=[2020,2021,2022,2023,2024])

# AIæ¨¡å¼è¯†åˆ«
seasonal_pattern = engine.identify_seasonal_patterns(aligned_data)
print(f"æ¨¡å¼å¼ºåº¦: {seasonal_pattern.pattern_strength:.2f}")      # 0.8+ å¼ºæ¨¡å¼
print(f"ç½®ä¿¡æ°´å¹³: {seasonal_pattern.confidence_level:.2f}")      # 0.7+ å¯ä¿¡
print(f"ä¸€è‡´æ€§è¯„åˆ†: {seasonal_pattern.consistency_score:.2f}")   # 0.6+ ç¨³å®š

# ç”Ÿæˆäº¤æ˜“ä¿¡å·
signals = engine.generate_trading_signals(seasonal_pattern)
print(f"äº¤æ˜“ä¿¡å·: {signals['signal']}")           # BUY/SELL/HOLD
print(f"ä¿¡å·å¼ºåº¦: {signals['strength']:.2f}")     # 0-1è¯„åˆ†
print(f"å»ºè®®ä»“ä½: {signals['position_size']:.2%}") # å»ºè®®ä»“ä½æ¯”ä¾‹
```

#### 2. æœºå™¨å­¦ä¹ æ¨¡å‹ç®¡ç†
```python
from stock_analysis_system.analysis.ml_model_manager import MLModelManager

model_manager = MLModelManager()

# è®­ç»ƒæ˜¥èŠ‚é¢„æµ‹æ¨¡å‹
model_info = await model_manager.train_model(
    data=training_data,
    model_type="spring_festival_predictor",
    model_name="sf_predictor_v1",
    hyperparameters={
        "n_estimators": 100,
        "max_depth": 10,
        "learning_rate": 0.1
    }
)

# æ¨¡å‹éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
await model_manager.promote_model(model_info.model_id, stage="production")

# æ¨¡å‹æ¼‚ç§»æ£€æµ‹
drift_score = await model_manager.detect_model_drift(new_data)
if drift_score > 0.3:
    print("âš ï¸ æ£€æµ‹åˆ°æ¨¡å‹æ¼‚ç§»ï¼Œå»ºè®®é‡æ–°è®­ç»ƒ")
    # è‡ªåŠ¨è§¦å‘é‡è®­ç»ƒ
    await model_manager.schedule_retraining(model_info.model_id)
```

#### 3. é£é™©ç®¡ç†å¼•æ“
```python
from stock_analysis_system.analysis.risk_management_engine import RiskManagementEngine

risk_engine = RiskManagementEngine()

# è®¡ç®—å¤šç§VaRæŒ‡æ ‡
var_results = await risk_engine.calculate_var(
    portfolio_data,
    confidence_levels=[0.95, 0.99],
    methods=['historical', 'parametric', 'monte_carlo']
)

print(f"95% VaR (å†å²æ³•): {var_results['historical'].var_95:.2%}")
print(f"99% VaR (å‚æ•°æ³•): {var_results['parametric'].var_99:.2%}")
print(f"CVaR (è’™ç‰¹å¡æ´›): {var_results['monte_carlo'].cvar_95:.2%}")

# å­£èŠ‚æ€§é£é™©è¯„ä¼°
seasonal_risk = await risk_engine.calculate_seasonal_risk_score(
    stock_data, 
    spring_festival_dates
)
print(f"æ˜¥èŠ‚æœŸé—´é£é™©è¯„åˆ†: {seasonal_risk:.2f}")  # 0-1è¯„åˆ†ï¼Œè¶Šé«˜é£é™©è¶Šå¤§
```

### ğŸ¯ ç­–ç•¥é…ç½®ä¸è°ƒä¼˜

#### 1. æ˜¥èŠ‚ç­–ç•¥å‚æ•°é…ç½®
```python
# config/strategy_config.py
SPRING_FESTIVAL_STRATEGY = {
    # æ•°æ®åˆ†æå‚æ•°
    "analysis": {
        "window_days": 60,              # æ˜¥èŠ‚å‰ååˆ†æå¤©æ•°
        "min_years": 3,                 # æœ€å°‘å†å²å¹´ä»½
        "max_years": 10,                # æœ€å¤šå†å²å¹´ä»½
        "exclude_years": [2020],        # æ’é™¤å¼‚å¸¸å¹´ä»½ï¼ˆå¦‚ç–«æƒ…å¹´ï¼‰
    },
    
    # ä¿¡å·ç”Ÿæˆå‚æ•°
    "signals": {
        "confidence_threshold": 0.7,     # æœ€ä½ç½®ä¿¡åº¦
        "pattern_strength_min": 0.6,     # æœ€å°æ¨¡å¼å¼ºåº¦
        "consistency_score_min": 0.5,    # æœ€å°ä¸€è‡´æ€§è¦æ±‚
        "signal_decay_days": 5,          # ä¿¡å·è¡°å‡å¤©æ•°
    },
    
    # ä»“ä½ç®¡ç†å‚æ•°
    "position_sizing": {
        "method": "kelly",               # kelly/fixed/volatility_target
        "max_position": 0.1,             # æœ€å¤§å•è‚¡ä»“ä½10%
        "risk_per_trade": 0.02,          # å•ç¬”é£é™©2%
        "leverage": 1.0,                 # æ æ†å€æ•°
    },
    
    # é£é™©æ§åˆ¶å‚æ•°
    "risk_management": {
        "stop_loss": 0.05,               # æ­¢æŸ5%
        "take_profit": 0.15,             # æ­¢ç›ˆ15%
        "max_drawdown": 0.1,             # æœ€å¤§å›æ’¤10%
        "var_limit": 0.03,               # VaRé™åˆ¶3%
    }
}
```

#### 2. åŠ¨æ€å‚æ•°è°ƒä¼˜
```python
from stock_analysis_system.analysis.strategy_optimizer import StrategyOptimizer

optimizer = StrategyOptimizer()

# å‚æ•°ä¼˜åŒ–ç©ºé—´
param_space = {
    'window_days': [30, 45, 60, 90],
    'confidence_threshold': [0.6, 0.7, 0.8],
    'pattern_strength_min': [0.5, 0.6, 0.7],
    'max_position': [0.05, 0.1, 0.15]
}

# æ‰§è¡Œå‚æ•°ä¼˜åŒ–
best_params = await optimizer.optimize_parameters(
    strategy_name="spring_festival",
    param_space=param_space,
    optimization_metric="sharpe_ratio",
    cv_folds=5
)

print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {best_params}")
print(f"é¢„æœŸå¤æ™®æ¯”ç‡: {best_params['expected_sharpe']:.2f}")
```

#### 3. å®æ—¶ç­–ç•¥ç›‘æ§
```python
from stock_analysis_system.monitoring.strategy_monitor import StrategyMonitor

monitor = StrategyMonitor()

# ç­–ç•¥æ€§èƒ½ç›‘æ§
performance = await monitor.get_strategy_performance("spring_festival")
print(f"å½“å‰æ”¶ç›Šç‡: {performance.total_return:.2%}")
print(f"å¤æ™®æ¯”ç‡: {performance.sharpe_ratio:.2f}")
print(f"æœ€å¤§å›æ’¤: {performance.max_drawdown:.2%}")
print(f"èƒœç‡: {performance.win_rate:.2%}")

# å®æ—¶é£é™©ç›‘æ§
risk_metrics = await monitor.get_real_time_risk()
if risk_metrics.current_var > risk_metrics.var_limit:
    print("âš ï¸ VaRè¶…é™ï¼Œå»ºè®®å‡ä»“")
    
if risk_metrics.drawdown > 0.08:
    print("âš ï¸ å›æ’¤è¿‡å¤§ï¼Œè§¦å‘é£æ§")
```

### ğŸ“ˆ ç³»ç»Ÿä½¿ç”¨æŠ€å·§

#### 1. æ•°æ®æºé€‰æ‹©ç­–ç•¥
```python
# æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©æœ€ä½³æ•°æ®æº
scenarios = {
    "å®æ—¶äº¤æ˜“": "tushare",          # å»¶è¿Ÿä½ï¼Œæ•°æ®å‡†ç¡®
    "å†å²å›æµ‹": "local_tdx",        # æ•°æ®å®Œæ•´ï¼Œé€Ÿåº¦å¿«
    "ç ”ç©¶åˆ†æ": "akshare",          # å…è´¹ï¼Œæ•°æ®ä¸°å¯Œ
    "ç”Ÿäº§ç¯å¢ƒ": "multi_source"      # å¤šæºå†—ä½™ï¼Œé«˜å¯ç”¨
}
```

#### 2. ç¼“å­˜ä¼˜åŒ–é…ç½®
```python
# Redisç¼“å­˜ç­–ç•¥é…ç½®
CACHE_CONFIG = {
    "stock_data": {
        "ttl": 3600,                # 1å°æ—¶ç¼“å­˜
        "key_pattern": "stock:{symbol}:{date}"
    },
    "analysis_results": {
        "ttl": 86400,               # 24å°æ—¶ç¼“å­˜
        "key_pattern": "analysis:{symbol}:{strategy}"
    },
    "real_time_data": {
        "ttl": 60,                  # 1åˆ†é’Ÿç¼“å­˜
        "key_pattern": "realtime:{symbol}"
    }
}
```

#### 3. æ€§èƒ½ä¼˜åŒ–å»ºè®®
```python
# æ‰¹é‡æ•°æ®å¤„ç†
async def batch_analysis(symbols: List[str]):
    # ä½¿ç”¨å¼‚æ­¥å¹¶å‘å¤„ç†
    tasks = [analyze_stock(symbol) for symbol in symbols]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results

# æ•°æ®é¢„åŠ è½½
async def preload_data():
    # é¢„åŠ è½½çƒ­é—¨è‚¡ç¥¨æ•°æ®åˆ°ç¼“å­˜
    hot_stocks = ["000001.SZ", "000002.SZ", "600000.SH"]
    await data_manager.preload_stocks(hot_stocks)
```

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### æ•°æ®åº“è¿ç§»æµ‹è¯•

æ— éœ€PostgreSQLå³å¯æµ‹è¯•æ•°æ®åº“è®¾ç½®ï¼š

```bash
# ä½¿ç”¨SQLiteæµ‹è¯•è¿ç§»ï¼ˆæ— éœ€æ•°æ®åº“æœåŠ¡å™¨ï¼‰
python test_migration.py

# ä½¿ç”¨ç‰¹å®šæ•°æ®åº“URLæµ‹è¯•
DATABASE_URL="sqlite:///./test.db" alembic upgrade head
DATABASE_URL="sqlite:///./test.db" alembic current
```

### åº”ç”¨ç¨‹åºæµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
pytest --cov=stock_analysis_system --cov-report=html

# åªè¿è¡Œå•å…ƒæµ‹è¯•
pytest -m unit

# åªè¿è¡Œé›†æˆæµ‹è¯•
pytest -m integration

# ä½¿ç”¨SQLiteæ•°æ®åº“æµ‹è¯•
DATABASE_URL="sqlite:///./test.db" pytest
```

### åŠŸèƒ½éªŒè¯æµ‹è¯•

```bash
# æ˜¥èŠ‚åˆ†æåŠŸèƒ½æµ‹è¯•
python test_spring_festival_demo.py

# æ•°æ®è´¨é‡å¼•æ“æµ‹è¯•
python test_data_quality_demo.py

# é£é™©ç®¡ç†å¼•æ“æµ‹è¯•
python test_risk_management_demo.py

# æœºå™¨å­¦ä¹ æ¨¡å‹ç®¡ç†æµ‹è¯•
python demo_task_7_2_model_drift_and_ab_testing.py

# å®Œæ•´APIæµ‹è¯•
python test_api.py
```

## ğŸ”§ å¼€å‘æŒ‡å—

### ä»£ç è´¨é‡å·¥å…·

é¡¹ç›®ä½¿ç”¨å¤šç§å·¥å…·ç»´æŠ¤ä»£ç è´¨é‡ï¼š

- **Black**: ä»£ç æ ¼å¼åŒ–
- **isort**: å¯¼å…¥æ’åº
- **flake8**: ä»£ç æ£€æŸ¥
- **mypy**: ç±»å‹æ£€æŸ¥
- **pre-commit**: Gité’©å­è´¨é‡æ£€æŸ¥

æ‰‹åŠ¨è¿è¡Œè´¨é‡æ£€æŸ¥ï¼š

```bash
# æ ¼å¼åŒ–ä»£ç 
black stock_analysis_system tests

# æ’åºå¯¼å…¥
isort stock_analysis_system tests

# æ£€æŸ¥ä»£ç 
flake8 stock_analysis_system tests

# ç±»å‹æ£€æŸ¥
mypy stock_analysis_system

# ä¸€æ¬¡è¿è¡Œæ‰€æœ‰è´¨é‡æ£€æŸ¥
make lint
```

### å¼€å‘ç¯å¢ƒè®¾ç½®

ä½¿ç”¨è‡ªåŠ¨åŒ–è®¾ç½®è„šæœ¬ï¼š

```bash
# è‡ªåŠ¨åŒ–å¼€å‘ç¯å¢ƒè®¾ç½®
python scripts/setup_dev.py

# æˆ–ä½¿ç”¨makeå‘½ä»¤
make setup-dev    # å®Œæ•´å¼€å‘è®¾ç½®
make install-dev  # å®‰è£…å¼€å‘ä¾èµ–
make test         # è¿è¡Œæµ‹è¯•
make run-dev      # å¯åŠ¨å¼€å‘æœåŠ¡å™¨
```

### é¡¹ç›®ç»“æ„

```
stock_analysis_system/
â”œâ”€â”€ analysis/           # åˆ†æå¼•æ“ï¼ˆæ˜¥èŠ‚ã€é£é™©ç­‰ï¼‰
â”‚   â”œâ”€â”€ spring_festival_engine.py      # æ˜¥èŠ‚å¯¹é½åˆ†æå¼•æ“
â”‚   â”œâ”€â”€ ml_model_manager.py            # MLæ¨¡å‹ç®¡ç†
â”‚   â”œâ”€â”€ risk_management_engine.py      # é£é™©ç®¡ç†å¼•æ“
â”‚   â”œâ”€â”€ institutional_data_collector.py # æœºæ„æ•°æ®æ”¶é›†
â”‚   â””â”€â”€ position_sizing_engine.py      # ä»“ä½ç®¡ç†å¼•æ“
â”œâ”€â”€ api/               # FastAPIåº”ç”¨å’Œè·¯ç”±
â”‚   â”œâ”€â”€ main.py                        # ä¸»APIåº”ç”¨
â”‚   â”œâ”€â”€ routes/                        # APIè·¯ç”±
â”‚   â””â”€â”€ middleware/                    # ä¸­é—´ä»¶
â”œâ”€â”€ core/              # æ ¸å¿ƒå·¥å…·å’ŒåŸºç¡€ç±»
â”‚   â”œâ”€â”€ database_manager.py            # æ•°æ®åº“ç®¡ç†
â”‚   â”œâ”€â”€ error_handler.py               # é”™è¯¯å¤„ç†
â”‚   â””â”€â”€ failover_mechanism.py          # æ•…éšœè½¬ç§»æœºåˆ¶
â”œâ”€â”€ data/              # æ•°æ®è®¿é—®å±‚å’ŒETL
â”‚   â”œâ”€â”€ data_source_manager.py         # æ•°æ®æºç®¡ç†
â”‚   â”œâ”€â”€ data_quality_engine.py         # æ•°æ®è´¨é‡å¼•æ“
â”‚   â”œâ”€â”€ cache_manager.py               # ç¼“å­˜ç®¡ç†
â”‚   â””â”€â”€ enhanced_data_sources.py       # å¢å¼ºæ•°æ®æº
â”œâ”€â”€ etl/               # ETLç®¡é“
â”‚   â”œâ”€â”€ pipeline.py                    # ETLç®¡é“
â”‚   â”œâ”€â”€ tasks.py                       # Celeryä»»åŠ¡
â”‚   â””â”€â”€ celery_app.py                  # Celeryåº”ç”¨
â”œâ”€â”€ ml/                # æœºå™¨å­¦ä¹ æ¨¡å—
â”‚   â”œâ”€â”€ automated_training_pipeline.py # è‡ªåŠ¨è®­ç»ƒç®¡é“
â”‚   â”œâ”€â”€ model_drift_detector.py        # æ¨¡å‹æ¼‚ç§»æ£€æµ‹
â”‚   â””â”€â”€ ab_testing_framework.py        # A/Bæµ‹è¯•æ¡†æ¶
â”œâ”€â”€ monitoring/        # ç›‘æ§ç³»ç»Ÿ
â”‚   â”œâ”€â”€ health_monitor.py              # å¥åº·ç›‘æ§
â”‚   â”œâ”€â”€ performance_monitoring.py      # æ€§èƒ½ç›‘æ§
â”‚   â””â”€â”€ prometheus_metrics.py          # PrometheusæŒ‡æ ‡
â”œâ”€â”€ security/          # å®‰å…¨æ¨¡å—
â”‚   â”œâ”€â”€ authentication.py              # è®¤è¯
â”‚   â””â”€â”€ gdpr_compliance.py             # GDPRåˆè§„
â””â”€â”€ visualization/     # å›¾è¡¨ç”Ÿæˆå’Œå¯è§†åŒ–
    â””â”€â”€ spring_festival_charts.py      # æ˜¥èŠ‚åˆ†æå›¾è¡¨

tests/
â”œâ”€â”€ unit/              # å•å…ƒæµ‹è¯•
â”œâ”€â”€ integration/       # é›†æˆæµ‹è¯•
â””â”€â”€ fixtures/          # æµ‹è¯•æ•°æ®å’Œå›ºä»¶

config/                # é…ç½®æ–‡ä»¶
docs/                  # æ–‡æ¡£
scripts/               # å·¥å…·è„šæœ¬
frontend/              # Reactå‰ç«¯
k8s/                   # Kubernetesé…ç½®
monitoring/            # ç›‘æ§é…ç½®
```

## ğŸ“ˆ æ€§èƒ½ç‰¹æ€§

ç³»ç»Ÿé€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›é«˜æ€§èƒ½ï¼š

- **å¼‚æ­¥æ¶æ„**: FastAPIå’Œasyncioçš„å®Œæ•´async/awaitå®ç°
- **æ™ºèƒ½ç¼“å­˜**: Redisé©±åŠ¨çš„ç¼“å­˜ï¼Œæ”¯æŒå¯é…ç½®TTLå’Œç¼“å­˜é¢„çƒ­
- **ç†”æ–­å™¨æ¨¡å¼**: è‡ªåŠ¨æ•…éšœè½¬ç§»é˜²æ­¢çº§è”æ•…éšœ
- **è¿æ¥æ± **: PostgreSQLè¿æ¥æ± ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½
- **æ‰¹å¤„ç†**: Celeryé©±åŠ¨çš„åå°ä»»åŠ¡å¤„ç†å¤§æ•°æ®é›†
- **é€Ÿç‡é™åˆ¶**: æ™ºèƒ½é€Ÿç‡é™åˆ¶é˜²æ­¢APIèŠ‚æµ
- **å“åº”æ—¶é—´**: 
  - APIå¥åº·æ£€æŸ¥: <100ms
  - è‚¡ç¥¨æ•°æ®æŸ¥è¯¢: <500ms (ç¼“å­˜), <2s (æ–°æ•°æ®)
  - æ˜¥èŠ‚åˆ†æ: 5å¹´æ•°æ®é›†<5s
  - æ•°æ®è´¨é‡éªŒè¯: 1000æ¡è®°å½•<3s

## ğŸ”’ å®‰å…¨ç‰¹æ€§

å®‰å…¨åŠŸèƒ½åŒ…æ‹¬ï¼š

- **JWTè®¤è¯**: å®‰å…¨çš„APIè®¿é—®
- **è¾“å…¥éªŒè¯**: Pydanticæ¨¡å‹æ•°æ®éªŒè¯
- **SQLæ³¨å…¥é˜²æŠ¤**: SQLAlchemy ORM
- **é€Ÿç‡é™åˆ¶**: APIé€Ÿç‡é™åˆ¶
- **æ•°æ®åŠ å¯†**: æ•æ„Ÿæ•°æ®åŠ å¯†
- **GDPRåˆè§„**: æ•°æ®éšç§ä¿æŠ¤
- **å®¡è®¡æ—¥å¿—**: å®Œæ•´çš„æ“ä½œå®¡è®¡

## ğŸ“š æ–‡æ¡£èµ„æº

- **[APIæ–‡æ¡£](http://localhost:8000/docs)**: Swagger UIäº¤äº’å¼APIæ–‡æ¡£
- **[ç”¨æˆ·æŒ‡å—](docs/USER_GUIDE.md)**: è¯¦ç»†çš„ç”¨æˆ·ä½¿ç”¨æŒ‡å—
- **[å¼€å‘è€…æŒ‡å—](docs/DEVELOPER_GUIDE.md)**: å¼€å‘è€…æŠ€æœ¯æ–‡æ¡£
- **[æ•…éšœæ’é™¤æŒ‡å—](docs/TROUBLESHOOTING_GUIDE.md)**: å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ
- **[è¿ç»´æ‰‹å†Œ](docs/OPERATIONS_MANUAL.md)**: ç”Ÿäº§ç¯å¢ƒè¿ç»´æŒ‡å—
- **[APIç«¯ç‚¹æ–‡æ¡£](API_ENDPOINTS.md)**: å®Œæ•´çš„APIç«¯ç‚¹è¯´æ˜

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. **Forkä»“åº“**
2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯** (`git checkout -b feature/amazing-feature`)
3. **è¿›è¡Œæ›´æ”¹**
4. **è¿è¡Œæµ‹è¯•å’Œè´¨é‡æ£€æŸ¥** (`make test && make lint`)
5. **æäº¤æ›´æ”¹** (`git commit -m 'Add amazing feature'`)
6. **æ¨é€åˆ°åˆ†æ”¯** (`git push origin feature/amazing-feature`)
7. **å¼€å¯Pull Request**

### ä»£ç è´¡çŒ®è§„èŒƒ

- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ é€‚å½“çš„ç±»å‹æ³¨è§£
- ç¼–å†™å•å…ƒæµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£
- ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- ä¸­å›½å†œå†è®¡ç®—åŸºäºå¤©æ–‡æ•°æ®
- é‡‘èæ•°æ®ç”±AkShareå’ŒTushareæä¾›
- å¯è§†åŒ–ç”±Plotlyå’ŒD3.jsé©±åŠ¨
- æœºå™¨å­¦ä¹ åŠŸèƒ½åŸºäºscikit-learnå’ŒMLflow
- æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œå¼€æºç¤¾åŒºçš„æ”¯æŒ

## ğŸ“ æŠ€æœ¯æ”¯æŒ

è·å–æ”¯æŒå’Œå¸®åŠ©ï¼š

- **ğŸ“§ é‚®ç®±**: support@stockanalysis.com
- **ğŸ’¬ ç¤¾åŒº**: [åŠ å…¥æˆ‘ä»¬çš„è®¨è®ºç¤¾åŒº](https://github.com/your-org/stock-analysis-system/discussions)
- **ğŸ“– æ–‡æ¡£**: [åœ¨çº¿æ–‡æ¡£](https://stock-analysis-system.readthedocs.io/)
- **ğŸ› é—®é¢˜æŠ¥å‘Š**: [GitHub Issues](https://github.com/your-org/stock-analysis-system/issues)
- **ğŸ’¡ åŠŸèƒ½å»ºè®®**: [åŠŸèƒ½è¯·æ±‚](https://github.com/your-org/stock-analysis-system/issues/new?template=feature_request.md)

### å¸¸è§é—®é¢˜å¿«é€Ÿé“¾æ¥

- [å®‰è£…é—®é¢˜](docs/TROUBLESHOOTING_GUIDE.md#å®‰è£…é—®é¢˜)
- [æ•°æ®æºé…ç½®](docs/USER_GUIDE.md#æ•°æ®æºé…ç½®)
- [APIä½¿ç”¨](docs/API_DOCUMENTATION.md)
- [æ€§èƒ½ä¼˜åŒ–](docs/DEVELOPER_GUIDE.md#æ€§èƒ½ä¼˜åŒ–)
- [éƒ¨ç½²æŒ‡å—](docs/OPERATIONS_MANUAL.md#éƒ¨ç½²æŒ‡å—)

---

**ğŸš€ å¼€å§‹ä½¿ç”¨**: `make setup-dev && make docker-up && python start_server.py`  
**ğŸ“Š ç«‹å³ä½“éªŒ**: è®¿é—® http://localhost:3000 å¼€å§‹åˆ†æè‚¡ç¥¨ï¼
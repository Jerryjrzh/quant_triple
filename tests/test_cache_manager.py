"""
ç¼“å­˜ç®¡ç†å™¨å•å…ƒæµ‹è¯•

æµ‹è¯•ç¼“å­˜çš„è¯»å†™ã€å¤±æ•ˆå’Œæ›´æ–°æœºåˆ¶ï¼Œå®ç°å¹¶å‘è®¿é—®å’Œç«æ€æ¡ä»¶çš„æµ‹è¯•ï¼Œ
æ·»åŠ ç¼“å­˜æ€§èƒ½å’Œå†…å­˜ä½¿ç”¨çš„æµ‹è¯•ï¼Œåˆ›å»ºç¼“å­˜ä¸€è‡´æ€§å’Œæ•°æ®åŒæ­¥çš„éªŒè¯ã€‚

Author: Stock Analysis System Team
Date: 2024-01-20
"""

import asyncio
import json
import pickle
import pytest
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, AsyncMock, MagicMock
from typing import Dict, List, Any
import threading
import concurrent.futures

from stock_analysis_system.data.cache_manager import (
    CacheManager,
    CacheConfig,
    CacheStats,
    CacheLevel,
    get_cache_manager
)


class TestDataGenerator:
    """ç¼“å­˜æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_sample_dataframe(rows: int = 100) -> pd.DataFrame:
        """ç”Ÿæˆç¤ºä¾‹DataFrame"""
        np.random.seed(42)
        
        data = {
            'stock_code': [f'{i:06d}' for i in range(rows)],
            'trade_date': [datetime.now() - timedelta(days=i) for i in range(rows)],
            'close_price': np.random.uniform(10, 100, rows),
            'volume': np.random.randint(1000000, 10000000, rows),
            'amount': np.random.uniform(10000000, 100000000, rows)
        }
        
        return pd.DataFrame(data)
    
    @staticmethod
    def generate_large_dataframe(rows: int = 10000) -> pd.DataFrame:
        """ç”Ÿæˆå¤§å‹DataFrameç”¨äºæ€§èƒ½æµ‹è¯•"""
        np.random.seed(42)
        
        data = {
            'id': range(rows),
            'timestamp': [datetime.now() - timedelta(seconds=i) for i in range(rows)],
            'value1': np.random.normal(0, 1, rows),
            'value2': np.random.uniform(0, 100, rows),
            'value3': np.random.exponential(2, rows),
            'category': np.random.choice(['A', 'B', 'C', 'D'], rows),
            'flag': np.random.choice([True, False], rows)
        }
        
        return pd.DataFrame(data)


class MockRedis:
    """æ¨¡æ‹ŸRediså®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.data = {}
        self.expire_times = {}
        self.connected = True
    
    async def ping(self):
        """æ¨¡æ‹Ÿpingå‘½ä»¤"""
        if not self.connected:
            raise Exception("Redis connection failed")
        return True
    
    async def get(self, key: str):
        """æ¨¡æ‹Ÿgetå‘½ä»¤"""
        if not self.connected:
            raise Exception("Redis connection failed")
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if key in self.expire_times:
            if time.time() > self.expire_times[key]:
                del self.data[key]
                del self.expire_times[key]
                return None
        
        return self.data.get(key)
    
    async def setex(self, key: str, ttl: int, value: Any):
        """æ¨¡æ‹Ÿsetexå‘½ä»¤"""
        if not self.connected:
            raise Exception("Redis connection failed")
        
        self.data[key] = value
        self.expire_times[key] = time.time() + ttl
    
    async def delete(self, *keys):
        """æ¨¡æ‹Ÿdeleteå‘½ä»¤"""
        if not self.connected:
            raise Exception("Redis connection failed")
        
        deleted_count = 0
        for key in keys:
            if key in self.data:
                del self.data[key]
                deleted_count += 1
            if key in self.expire_times:
                del self.expire_times[key]
        
        return deleted_count
    
    async def keys(self, pattern: str):
        """æ¨¡æ‹Ÿkeyså‘½ä»¤"""
        if not self.connected:
            raise Exception("Redis connection failed")
        
        import fnmatch
        matching_keys = []
        for key in self.data.keys():
            if fnmatch.fnmatch(key, pattern):
                matching_keys.append(key)
        
        return matching_keys
    
    async def close(self):
        """æ¨¡æ‹Ÿcloseå‘½ä»¤"""
        pass
    
    def disconnect(self):
        """æ¨¡æ‹Ÿè¿æ¥æ–­å¼€"""
        self.connected = False
    
    def reconnect(self):
        """æ¨¡æ‹Ÿé‡æ–°è¿æ¥"""
        self.connected = True


class TestCacheConfig:
    """ç¼“å­˜é…ç½®æµ‹è¯•ç±»"""
    
    def test_cache_config_creation(self):
        """æµ‹è¯•ç¼“å­˜é…ç½®åˆ›å»º"""
        config = CacheConfig(
            ttl=300,
            key_pattern='test:{id}',
            level=CacheLevel.REDIS,
            preload=True,
            compress=True
        )
        
        assert config.ttl == 300
        assert config.key_pattern == 'test:{id}'
        assert config.level == CacheLevel.REDIS
        assert config.preload is True
        assert config.compress is True
    
    def test_cache_config_defaults(self):
        """æµ‹è¯•ç¼“å­˜é…ç½®é»˜è®¤å€¼"""
        config = CacheConfig(ttl=300, key_pattern='test:{id}')
        
        assert config.level == CacheLevel.REDIS
        assert config.preload is False
        assert config.compress is False


class TestCacheStats:
    """ç¼“å­˜ç»Ÿè®¡æµ‹è¯•ç±»"""
    
    def test_cache_stats_initialization(self):
        """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡åˆå§‹åŒ–"""
        stats = CacheStats()
        
        assert stats.hits == 0
        assert stats.misses == 0
        assert stats.sets == 0
        assert stats.deletes == 0
        assert stats.errors == 0
        assert stats.total_size == 0
        assert stats.hit_rate == 0.0
    
    def test_hit_rate_calculation(self):
        """æµ‹è¯•å‘½ä¸­ç‡è®¡ç®—"""
        stats = CacheStats()
        
        # æ— è®¿é—®æ—¶å‘½ä¸­ç‡ä¸º0
        assert stats.hit_rate == 0.0
        
        # æœ‰å‘½ä¸­å’Œæœªå‘½ä¸­æ—¶
        stats.hits = 8
        stats.misses = 2
        assert stats.hit_rate == 0.8
        
        # åªæœ‰å‘½ä¸­æ—¶
        stats.misses = 0
        assert stats.hit_rate == 1.0
        
        # åªæœ‰æœªå‘½ä¸­æ—¶
        stats.hits = 0
        stats.misses = 5
        assert stats.hit_rate == 0.0


class TestCacheManager:
    """ç¼“å­˜ç®¡ç†å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def cache_manager(self):
        """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
        manager = CacheManager("redis://localhost:6379/0")
        
        # ä½¿ç”¨æ¨¡æ‹ŸRediså®¢æˆ·ç«¯
        mock_redis = MockRedis()
        manager.redis_client = mock_redis
        
        return manager
    
    @pytest.fixture
    def sample_data(self):
        """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
        return TestDataGenerator.generate_sample_dataframe(50)
    
    @pytest.mark.asyncio
    async def test_initialization_success(self):
        """æµ‹è¯•æˆåŠŸåˆå§‹åŒ–"""
        manager = CacheManager()
        
        with patch('redis.asyncio.from_url') as mock_redis:
            mock_client = AsyncMock()
            mock_client.ping.return_value = True
            mock_redis.return_value = mock_client
            
            await manager.initialize()
            
            assert manager.redis_client is not None
            mock_client.ping.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_initialization_failure(self):
        """æµ‹è¯•åˆå§‹åŒ–å¤±è´¥"""
        manager = CacheManager()
        
        with patch('redis.asyncio.from_url') as mock_redis:
            mock_client = AsyncMock()
            mock_client.ping.side_effect = Exception("Connection failed")
            mock_redis.return_value = mock_client
            
            await manager.initialize()
            
            assert manager.redis_client is None
    
    @pytest.mark.asyncio
    async def test_memory_cache_operations(self, cache_manager, sample_data):
        """æµ‹è¯•å†…å­˜ç¼“å­˜æ“ä½œ"""
        key = "test_memory_key"
        cache_type = "realtime_data"
        
        # æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is None
        assert cache_manager.stats.misses == 1
        
        # è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(key, sample_data, cache_type)
        assert cache_manager.stats.sets == 1
        
        # æµ‹è¯•ç¼“å­˜å‘½ä¸­
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        assert len(result) == len(sample_data)
        assert cache_manager.stats.hits == 1
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        pd.testing.assert_frame_equal(result, sample_data)
    
    @pytest.mark.asyncio
    async def test_redis_cache_operations(self, cache_manager, sample_data):
        """æµ‹è¯•Redisç¼“å­˜æ“ä½œ"""
        key = "test_redis_key"
        cache_type = "daily_data"
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜ä»¥ç¡®ä¿ä»Redisè¯»å–
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        # è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(key, sample_data, cache_type)
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        # ä»Redisè·å–ç¼“å­˜
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        assert len(result) == len(sample_data)
    
    @pytest.mark.asyncio
    async def test_cache_expiration(self, cache_manager, sample_data):
        """æµ‹è¯•ç¼“å­˜è¿‡æœŸ"""
        key = "test_expiration_key"
        cache_type = "realtime_data"
        short_ttl = 1  # 1ç§’TTL
        
        # è®¾ç½®çŸ­TTLçš„ç¼“å­˜
        await cache_manager.set_cached_data(key, sample_data, cache_type, ttl=short_ttl)
        
        # ç«‹å³è·å–åº”è¯¥æˆåŠŸ
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        
        # ç­‰å¾…è¿‡æœŸ
        await asyncio.sleep(1.5)
        
        # å†æ¬¡è·å–åº”è¯¥å¤±è´¥
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is None
    
    @pytest.mark.asyncio
    async def test_cache_invalidation(self, cache_manager, sample_data):
        """æµ‹è¯•ç¼“å­˜å¤±æ•ˆ"""
        # è®¾ç½®å¤šä¸ªç¼“å­˜é¡¹
        keys = ["test_inv_1", "test_inv_2", "other_key"]
        cache_type = "realtime_data"
        
        for key in keys:
            await cache_manager.set_cached_data(key, sample_data, cache_type)
        
        # éªŒè¯ç¼“å­˜å­˜åœ¨
        for key in keys:
            result = await cache_manager.get_cached_data(key, cache_type)
            assert result is not None
        
        # ä½¿ç”¨æ¨¡å¼å¤±æ•ˆç¼“å­˜
        await cache_manager.invalidate_cache("test_inv_*")
        
        # éªŒè¯åŒ¹é…çš„ç¼“å­˜è¢«åˆ é™¤
        result1 = await cache_manager.get_cached_data("test_inv_1", cache_type)
        result2 = await cache_manager.get_cached_data("test_inv_2", cache_type)
        assert result1 is None
        assert result2 is None
        
        # éªŒè¯ä¸åŒ¹é…çš„ç¼“å­˜ä»ç„¶å­˜åœ¨
        result3 = await cache_manager.get_cached_data("other_key", cache_type)
        assert result3 is not None
    
    @pytest.mark.asyncio
    async def test_cache_stats(self, cache_manager, sample_data):
        """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡"""
        key = "test_stats_key"
        cache_type = "realtime_data"
        
        # åˆå§‹ç»Ÿè®¡
        stats = cache_manager.get_cache_stats()
        assert stats['hits'] == 0
        assert stats['misses'] == 0
        assert stats['sets'] == 0
        
        # ç¼“å­˜æœªå‘½ä¸­
        await cache_manager.get_cached_data(key, cache_type)
        stats = cache_manager.get_cache_stats()
        assert stats['misses'] == 1
        
        # è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(key, sample_data, cache_type)
        stats = cache_manager.get_cache_stats()
        assert stats['sets'] == 1
        
        # ç¼“å­˜å‘½ä¸­
        await cache_manager.get_cached_data(key, cache_type)
        stats = cache_manager.get_cache_stats()
        assert stats['hits'] == 1
        assert stats['hit_rate'] == 0.5  # 1 hit / (1 hit + 1 miss)
    
    @pytest.mark.asyncio
    async def test_memory_cache_size_limit(self, cache_manager):
        """æµ‹è¯•å†…å­˜ç¼“å­˜å¤§å°é™åˆ¶"""
        cache_type = "realtime_data"
        
        # åˆ›å»ºè¶…è¿‡é™åˆ¶çš„ç¼“å­˜é¡¹ï¼ˆé™åˆ¶æ˜¯1000ï¼‰
        for i in range(1005):
            key = f"test_limit_{i}"
            data = TestDataGenerator.generate_sample_dataframe(10)
            await cache_manager.set_cached_data(key, data, cache_type)
        
        # éªŒè¯å†…å­˜ç¼“å­˜å¤§å°ä¸è¶…è¿‡é™åˆ¶
        assert len(cache_manager.memory_cache) <= 1000
        
        # éªŒè¯æœ€æ–°çš„ç¼“å­˜é¡¹ä»ç„¶å­˜åœ¨
        result = await cache_manager.get_cached_data("test_limit_1004", cache_type)
        assert result is not None
    
    @pytest.mark.asyncio
    async def test_compressed_cache(self, cache_manager, sample_data):
        """æµ‹è¯•å‹ç¼©ç¼“å­˜"""
        key = "test_compressed_key"
        cache_type = "daily_data"  # é…ç½®ä¸ºå‹ç¼©
        
        # è®¾ç½®å‹ç¼©ç¼“å­˜
        await cache_manager.set_cached_data(key, sample_data, cache_type)
        
        # éªŒè¯Redisä¸­å­˜å‚¨çš„æ˜¯pickleæ ¼å¼
        redis_data = await cache_manager.redis_client.get(key)
        assert redis_data is not None
        
        # å°è¯•ç”¨pickleååºåˆ—åŒ–
        try:
            unpickled_data = pickle.loads(redis_data)
            assert isinstance(unpickled_data, pd.DataFrame)
        except:
            pytest.fail("å‹ç¼©ç¼“å­˜æ•°æ®ä¸æ˜¯pickleæ ¼å¼")
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜åä»Redisè·å–
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        pd.testing.assert_frame_equal(result, sample_data)
    
    @pytest.mark.asyncio
    async def test_error_handling(self, cache_manager, sample_data):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        key = "test_error_key"
        cache_type = "realtime_data"
        
        # è®°å½•åˆå§‹é”™è¯¯æ•°
        initial_errors = cache_manager.stats.errors
        
        # æ¨¡æ‹ŸRedisè¿æ¥å¤±è´¥
        cache_manager.redis_client.disconnect()
        
        # è®¾ç½®ç¼“å­˜åº”è¯¥ä»ç„¶å·¥ä½œï¼ˆåªä½¿ç”¨å†…å­˜ç¼“å­˜ï¼‰
        await cache_manager.set_cached_data(key, sample_data, cache_type)
        
        # è·å–ç¼“å­˜åº”è¯¥ä»ç„¶å·¥ä½œ
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        
        # é”™è¯¯ç»Ÿè®¡åº”è¯¥å¢åŠ ï¼ˆRedisæ“ä½œå¤±è´¥ä¼šå¢åŠ é”™è¯¯è®¡æ•°ï¼‰
        assert cache_manager.stats.errors > initial_errors
    
    @pytest.mark.asyncio
    async def test_preload_cache(self, cache_manager, sample_data):
        """æµ‹è¯•é¢„åŠ è½½ç¼“å­˜"""
        cache_type = "realtime_data"
        
        # æ¨¡æ‹Ÿæ•°æ®åŠ è½½å‡½æ•°
        async def mock_data_loader(symbol):
            return sample_data
        
        # é¢„åŠ è½½ç¼“å­˜
        await cache_manager.preload_cache(cache_type, mock_data_loader, symbol="000001")
        
        # éªŒè¯ç¼“å­˜å·²è®¾ç½®
        # ç”±äºé”®ç”Ÿæˆå¯èƒ½å¤æ‚ï¼Œæˆ‘ä»¬æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯
        assert cache_manager.stats.sets > 0
    
    @pytest.mark.asyncio
    async def test_warm_up_cache(self, cache_manager, sample_data):
        """æµ‹è¯•ç¼“å­˜é¢„çƒ­"""
        async def mock_loader1():
            return sample_data
        
        async def mock_loader2():
            return sample_data
        
        warm_up_configs = [
            {
                'cache_type': 'realtime_data',
                'data_loader': mock_loader1,
                'params': {}
            },
            {
                'cache_type': 'dragon_tiger',
                'data_loader': mock_loader2,
                'params': {}
            }
        ]
        
        await cache_manager.warm_up_cache(warm_up_configs)
        
        # éªŒè¯é¢„çƒ­å®Œæˆ
        assert cache_manager.stats.sets >= 2


class TestConcurrencyAndRaceConditions:
    """å¹¶å‘å’Œç«æ€æ¡ä»¶æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def cache_manager(self):
        """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
        manager = CacheManager("redis://localhost:6379/0")
        manager.redis_client = MockRedis()
        return manager
    
    @pytest.mark.asyncio
    async def test_concurrent_read_write(self, cache_manager):
        """æµ‹è¯•å¹¶å‘è¯»å†™"""
        key = "concurrent_test_key"
        cache_type = "realtime_data"
        
        async def writer(data_id):
            data = TestDataGenerator.generate_sample_dataframe(10)
            data['id'] = data_id
            await cache_manager.set_cached_data(f"{key}_{data_id}", data, cache_type)
        
        async def reader(data_id):
            result = await cache_manager.get_cached_data(f"{key}_{data_id}", cache_type)
            return result
        
        # å¹¶å‘å†™å…¥
        write_tasks = [writer(i) for i in range(10)]
        await asyncio.gather(*write_tasks)
        
        # å¹¶å‘è¯»å–
        read_tasks = [reader(i) for i in range(10)]
        results = await asyncio.gather(*read_tasks)
        
        # éªŒè¯æ‰€æœ‰è¯»å–éƒ½æˆåŠŸ
        assert all(result is not None for result in results)
        assert len(results) == 10
    
    @pytest.mark.asyncio
    async def test_concurrent_cache_invalidation(self, cache_manager):
        """æµ‹è¯•å¹¶å‘ç¼“å­˜å¤±æ•ˆ"""
        cache_type = "realtime_data"
        
        # è®¾ç½®å¤šä¸ªç¼“å­˜é¡¹
        async def setup_cache():
            for i in range(20):
                key = f"concurrent_inv_{i}"
                data = TestDataGenerator.generate_sample_dataframe(5)
                await cache_manager.set_cached_data(key, data, cache_type)
        
        await setup_cache()
        
        # å¹¶å‘å¤±æ•ˆä¸åŒçš„æ¨¡å¼
        async def invalidate_pattern(pattern):
            await cache_manager.invalidate_cache(pattern)
        
        patterns = ["concurrent_inv_1*", "concurrent_inv_*5", "concurrent_inv_*0"]
        invalidate_tasks = [invalidate_pattern(pattern) for pattern in patterns]
        
        await asyncio.gather(*invalidate_tasks)
        
        # éªŒè¯å¤±æ•ˆæ“ä½œå®Œæˆ
        assert cache_manager.stats.deletes > 0
    
    @pytest.mark.asyncio
    async def test_race_condition_same_key(self, cache_manager):
        """æµ‹è¯•åŒä¸€é”®çš„ç«æ€æ¡ä»¶"""
        key = "race_condition_key"
        cache_type = "realtime_data"
        
        async def concurrent_operation(operation_id):
            # åŒæ—¶è¯»å–å’Œå†™å…¥åŒä¸€ä¸ªé”®
            data = TestDataGenerator.generate_sample_dataframe(5)
            data['operation_id'] = operation_id
            
            # å…ˆå°è¯•è¯»å–
            existing = await cache_manager.get_cached_data(key, cache_type)
            
            # ç„¶åå†™å…¥
            await cache_manager.set_cached_data(key, data, cache_type)
            
            # å†æ¬¡è¯»å–éªŒè¯
            final = await cache_manager.get_cached_data(key, cache_type)
            
            return existing, final
        
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªæ“ä½œ
        tasks = [concurrent_operation(i) for i in range(5)]
        results = await asyncio.gather(*tasks)
        
        # éªŒè¯æ“ä½œå®Œæˆä¸”æ²¡æœ‰å¼‚å¸¸
        assert len(results) == 5
        
        # æœ€ç»ˆåº”è¯¥æœ‰ä¸€ä¸ªå€¼å­˜åœ¨
        final_result = await cache_manager.get_cached_data(key, cache_type)
        assert final_result is not None
    
    def test_thread_safety(self, cache_manager):
        """æµ‹è¯•çº¿ç¨‹å®‰å…¨æ€§"""
        key_base = "thread_safety_test"
        cache_type = "realtime_data"
        
        def sync_cache_operation(thread_id):
            """åŒæ­¥ç¼“å­˜æ“ä½œï¼ˆåœ¨çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                async def async_operation():
                    key = f"{key_base}_{thread_id}"
                    data = TestDataGenerator.generate_sample_dataframe(10)
                    
                    # å†™å…¥ç¼“å­˜
                    await cache_manager.set_cached_data(key, data, cache_type)
                    
                    # è¯»å–ç¼“å­˜
                    result = await cache_manager.get_cached_data(key, cache_type)
                    return result is not None
                
                return loop.run_until_complete(async_operation())
            finally:
                loop.close()
        
        # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘æ‰§è¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(sync_cache_operation, i) for i in range(10)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        # éªŒè¯æ‰€æœ‰æ“ä½œéƒ½æˆåŠŸ
        assert all(results)
        assert len(results) == 10


class TestPerformanceAndMemoryUsage:
    """æ€§èƒ½å’Œå†…å­˜ä½¿ç”¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def cache_manager(self):
        """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
        manager = CacheManager("redis://localhost:6379/0")
        manager.redis_client = MockRedis()
        return manager
    
    @pytest.mark.asyncio
    async def test_large_data_caching_performance(self, cache_manager):
        """æµ‹è¯•å¤§æ•°æ®ç¼“å­˜æ€§èƒ½"""
        import time
        
        large_data = TestDataGenerator.generate_large_dataframe(10000)
        key = "large_data_test"
        cache_type = "daily_data"
        
        # æµ‹è¯•å†™å…¥æ€§èƒ½
        start_time = time.time()
        await cache_manager.set_cached_data(key, large_data, cache_type)
        write_time = time.time() - start_time
        
        # å†™å…¥åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼ˆä¾‹å¦‚5ç§’ï¼‰
        assert write_time < 5.0
        
        # æµ‹è¯•è¯»å–æ€§èƒ½
        start_time = time.time()
        result = await cache_manager.get_cached_data(key, cache_type)
        read_time = time.time() - start_time
        
        # è¯»å–åº”è¯¥æ›´å¿«ï¼ˆä¾‹å¦‚1ç§’ï¼‰
        assert read_time < 1.0
        assert result is not None
        assert len(result) == len(large_data)
    
    @pytest.mark.asyncio
    async def test_batch_operations_performance(self, cache_manager):
        """æµ‹è¯•æ‰¹é‡æ“ä½œæ€§èƒ½"""
        import time
        
        cache_type = "realtime_data"
        batch_size = 100
        
        # å‡†å¤‡æ‰¹é‡æ•°æ®
        batch_data = []
        for i in range(batch_size):
            data = TestDataGenerator.generate_sample_dataframe(50)
            batch_data.append((f"batch_key_{i}", data))
        
        # æµ‹è¯•æ‰¹é‡å†™å…¥æ€§èƒ½
        start_time = time.time()
        write_tasks = [
            cache_manager.set_cached_data(key, data, cache_type)
            for key, data in batch_data
        ]
        await asyncio.gather(*write_tasks)
        batch_write_time = time.time() - start_time
        
        # æ‰¹é‡å†™å…¥åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        assert batch_write_time < 10.0
        
        # æµ‹è¯•æ‰¹é‡è¯»å–æ€§èƒ½
        start_time = time.time()
        read_tasks = [
            cache_manager.get_cached_data(key, cache_type)
            for key, _ in batch_data
        ]
        results = await asyncio.gather(*read_tasks)
        batch_read_time = time.time() - start_time
        
        # æ‰¹é‡è¯»å–åº”è¯¥æ›´å¿«
        assert batch_read_time < 5.0
        assert all(result is not None for result in results)
    
    @pytest.mark.asyncio
    async def test_memory_usage_monitoring(self, cache_manager):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # ç¼“å­˜å¤§é‡æ•°æ®
        cache_type = "realtime_data"
        for i in range(100):
            key = f"memory_test_{i}"
            data = TestDataGenerator.generate_sample_dataframe(1000)
            await cache_manager.set_cached_data(key, data, cache_type)
        
        current_memory = process.memory_info().rss
        memory_increase = current_memory - initial_memory
        
        # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆä¾‹å¦‚å°äº100MBï¼‰
        assert memory_increase < 100 * 1024 * 1024  # 100MB
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        stats = cache_manager.get_cache_stats()
        assert stats['memory_cache_size'] > 0
    
    @pytest.mark.asyncio
    async def test_cache_hit_rate_optimization(self, cache_manager):
        """æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡ä¼˜åŒ–"""
        cache_type = "realtime_data"
        
        # è®¾ç½®ä¸€äº›ç¼“å­˜æ•°æ®
        for i in range(20):
            key = f"hit_rate_test_{i}"
            data = TestDataGenerator.generate_sample_dataframe(10)
            await cache_manager.set_cached_data(key, data, cache_type)
        
        # æ¨¡æ‹ŸçœŸå®è®¿é—®æ¨¡å¼ï¼ˆ80/20è§„åˆ™ï¼‰
        # 80%çš„è®¿é—®é›†ä¸­åœ¨20%çš„æ•°æ®ä¸Š
        hot_keys = [f"hit_rate_test_{i}" for i in range(4)]  # 20%çš„é”®
        cold_keys = [f"hit_rate_test_{i}" for i in range(4, 20)]  # 80%çš„é”®
        
        # æ‰§è¡Œè®¿é—®æ¨¡å¼
        access_count = 100
        for _ in range(access_count):
            # 80%çš„è®¿é—®è®¿é—®çƒ­ç‚¹æ•°æ®
            if np.random.random() < 0.8:
                key = np.random.choice(hot_keys)
            else:
                key = np.random.choice(cold_keys)
            
            await cache_manager.get_cached_data(key, cache_type)
        
        # æ£€æŸ¥å‘½ä¸­ç‡
        stats = cache_manager.get_cache_stats()
        assert stats['hit_rate'] > 0.8  # åº”è¯¥æœ‰è¾ƒé«˜çš„å‘½ä¸­ç‡
    
    @pytest.mark.asyncio
    async def test_ttl_performance_impact(self, cache_manager):
        """æµ‹è¯•TTLå¯¹æ€§èƒ½çš„å½±å“"""
        import time
        
        cache_type = "realtime_data"
        data = TestDataGenerator.generate_sample_dataframe(100)
        
        # æµ‹è¯•ä¸åŒTTLå€¼çš„æ€§èƒ½
        ttl_values = [60, 300, 1800, 3600]  # 1åˆ†é’Ÿåˆ°1å°æ—¶
        performance_results = {}
        
        for ttl in ttl_values:
            key = f"ttl_test_{ttl}"
            
            # æµ‹è¯•è®¾ç½®æ€§èƒ½
            start_time = time.time()
            await cache_manager.set_cached_data(key, data, cache_type, ttl=ttl)
            set_time = time.time() - start_time
            
            # æµ‹è¯•è·å–æ€§èƒ½
            start_time = time.time()
            result = await cache_manager.get_cached_data(key, cache_type)
            get_time = time.time() - start_time
            
            performance_results[ttl] = {
                'set_time': set_time,
                'get_time': get_time,
                'success': result is not None
            }
        
        # éªŒè¯æ‰€æœ‰TTLå€¼éƒ½èƒ½æ­£å¸¸å·¥ä½œ
        assert all(result['success'] for result in performance_results.values())
        
        # éªŒè¯æ€§èƒ½åœ¨åˆç†èŒƒå›´å†…
        for ttl, result in performance_results.items():
            assert result['set_time'] < 1.0  # è®¾ç½®æ—¶é—´å°äº1ç§’
            assert result['get_time'] < 0.1  # è·å–æ—¶é—´å°äº0.1ç§’


class TestCacheConsistencyAndSynchronization:
    """ç¼“å­˜ä¸€è‡´æ€§å’Œæ•°æ®åŒæ­¥æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def cache_manager(self):
        """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
        manager = CacheManager("redis://localhost:6379/0")
        manager.redis_client = MockRedis()
        return manager
    
    @pytest.mark.asyncio
    async def test_memory_redis_consistency(self, cache_manager):
        """æµ‹è¯•å†…å­˜ç¼“å­˜å’ŒRedisç¼“å­˜çš„ä¸€è‡´æ€§"""
        key = "consistency_test_key"
        cache_type = "daily_data"
        data = TestDataGenerator.generate_sample_dataframe(50)
        
        # è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(key, data, cache_type)
        
        # ä»å†…å­˜è·å–
        memory_result = cache_manager._get_memory_cache(key)
        assert memory_result is not None
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜ï¼Œå¼ºåˆ¶ä»Redisè·å–
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        redis_result = await cache_manager.get_cached_data(key, cache_type)
        assert redis_result is not None
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        pd.testing.assert_frame_equal(memory_result, redis_result)
    
    @pytest.mark.asyncio
    async def test_cache_update_consistency(self, cache_manager):
        """æµ‹è¯•ç¼“å­˜æ›´æ–°ä¸€è‡´æ€§"""
        key = "update_consistency_key"
        cache_type = "realtime_data"
        
        # è®¾ç½®åˆå§‹æ•°æ®
        initial_data = TestDataGenerator.generate_sample_dataframe(30)
        initial_data['version'] = 1
        await cache_manager.set_cached_data(key, initial_data, cache_type)
        
        # æ›´æ–°æ•°æ®
        updated_data = TestDataGenerator.generate_sample_dataframe(30)
        updated_data['version'] = 2
        await cache_manager.set_cached_data(key, updated_data, cache_type)
        
        # ä»å†…å­˜è·å–
        memory_result = await cache_manager.get_cached_data(key, cache_type)
        assert memory_result['version'].iloc[0] == 2
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜ï¼Œä»Redisè·å–
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        redis_result = await cache_manager.get_cached_data(key, cache_type)
        assert redis_result['version'].iloc[0] == 2
        
        # éªŒè¯æ›´æ–°åçš„æ•°æ®ä¸€è‡´æ€§
        pd.testing.assert_frame_equal(memory_result, redis_result)
    
    @pytest.mark.asyncio
    async def test_partial_cache_failure_handling(self, cache_manager):
        """æµ‹è¯•éƒ¨åˆ†ç¼“å­˜å¤±è´¥å¤„ç†"""
        key = "partial_failure_key"
        cache_type = "realtime_data"
        data = TestDataGenerator.generate_sample_dataframe(20)
        
        # æ­£å¸¸è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(key, data, cache_type)
        
        # æ¨¡æ‹ŸRediså¤±è´¥
        cache_manager.redis_client.disconnect()
        
        # åº”è¯¥ä»èƒ½ä»å†…å­˜ç¼“å­˜è·å–æ•°æ®
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        pd.testing.assert_frame_equal(result, data)
        
        # è®¾ç½®æ–°æ•°æ®åº”è¯¥ä»ç„¶å·¥ä½œï¼ˆåªæ›´æ–°å†…å­˜ç¼“å­˜ï¼‰
        new_data = TestDataGenerator.generate_sample_dataframe(25)
        await cache_manager.set_cached_data(key, new_data, cache_type)
        
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        assert len(result) == 25
    
    @pytest.mark.asyncio
    async def test_cache_recovery_after_failure(self, cache_manager):
        """æµ‹è¯•æ•…éšœåç¼“å­˜æ¢å¤"""
        key = "recovery_test_key"
        cache_type = "daily_data"
        data = TestDataGenerator.generate_sample_dataframe(40)
        
        # æ­£å¸¸è®¾ç½®ç¼“å­˜
        await cache_manager.set_cached_data(key, data, cache_type)
        
        # æ¨¡æ‹ŸRedisæ•…éšœ
        cache_manager.redis_client.disconnect()
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        # æ­¤æ—¶åº”è¯¥æ— æ³•è·å–æ•°æ®
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is None
        
        # æ¢å¤Redisè¿æ¥
        cache_manager.redis_client.reconnect()
        
        # é‡æ–°è®¾ç½®æ•°æ®
        await cache_manager.set_cached_data(key, data, cache_type)
        
        # åº”è¯¥èƒ½å¤Ÿæ­£å¸¸è·å–æ•°æ®
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        pd.testing.assert_frame_equal(result, data)
    
    @pytest.mark.asyncio
    async def test_concurrent_update_consistency(self, cache_manager):
        """æµ‹è¯•å¹¶å‘æ›´æ–°ä¸€è‡´æ€§"""
        key = "concurrent_update_key"
        cache_type = "realtime_data"
        
        async def update_cache(update_id):
            data = TestDataGenerator.generate_sample_dataframe(10)
            data['update_id'] = update_id
            data['timestamp'] = datetime.now()
            await cache_manager.set_cached_data(key, data, cache_type)
            return update_id
        
        # å¹¶å‘æ›´æ–°åŒä¸€ä¸ªé”®
        update_tasks = [update_cache(i) for i in range(10)]
        update_results = await asyncio.gather(*update_tasks)
        
        # éªŒè¯æœ€ç»ˆçŠ¶æ€ä¸€è‡´
        final_memory = cache_manager._get_memory_cache(key)
        
        # æ¸…ç©ºå†…å­˜ç¼“å­˜ï¼Œä»Redisè·å–
        cache_manager.memory_cache.clear()
        cache_manager.memory_expire.clear()
        
        final_redis = await cache_manager.get_cached_data(key, cache_type)
        
        # ä¸¤è€…åº”è¯¥ä¸€è‡´ï¼ˆè™½ç„¶ä¸çŸ¥é“æœ€ç»ˆæ˜¯å“ªä¸ªæ›´æ–°çš„ç»“æœï¼‰
        if final_memory is not None and final_redis is not None:
            assert final_memory['update_id'].iloc[0] == final_redis['update_id'].iloc[0]


class TestEdgeCasesAndErrorScenarios:
    """è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯åœºæ™¯æµ‹è¯•ç±»"""
    
    @pytest.fixture
    async def cache_manager(self):
        """åˆ›å»ºç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
        manager = CacheManager("redis://localhost:6379/0")
        manager.redis_client = MockRedis()
        yield manager
        await manager.close()
    
    @pytest.mark.asyncio
    async def test_empty_dataframe_caching(self, cache_manager):
        """æµ‹è¯•ç©ºDataFrameç¼“å­˜"""
        key = "empty_df_key"
        cache_type = "realtime_data"
        empty_df = pd.DataFrame()
        
        # è®¾ç½®ç©ºDataFrame
        await cache_manager.set_cached_data(key, empty_df, cache_type)
        
        # è·å–ç©ºDataFrame
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        assert len(result) == 0
        assert isinstance(result, pd.DataFrame)
    
    @pytest.mark.asyncio
    async def test_very_large_dataframe(self, cache_manager):
        """æµ‹è¯•éå¸¸å¤§çš„DataFrame"""
        key = "large_df_key"
        cache_type = "daily_data"
        
        # åˆ›å»ºå¤§å‹DataFrameï¼ˆå¯èƒ½æ¥è¿‘å†…å­˜é™åˆ¶ï¼‰
        large_df = TestDataGenerator.generate_large_dataframe(100000)
        
        # åº”è¯¥èƒ½å¤Ÿå¤„ç†å¤§å‹DataFrame
        await cache_manager.set_cached_data(key, large_df, cache_type)
        
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        assert len(result) == len(large_df)
    
    @pytest.mark.asyncio
    async def test_special_characters_in_keys(self, cache_manager):
        """æµ‹è¯•é”®ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        special_keys = [
            "key:with:colons",
            "key with spaces",
            "key-with-dashes",
            "key_with_underscores",
            "key.with.dots",
            "key/with/slashes",
            "key@with@symbols",
            "ä¸­æ–‡é”®å",
            "keyğŸš€withğŸ¯emojis"
        ]
        
        cache_type = "realtime_data"
        data = TestDataGenerator.generate_sample_dataframe(5)
        
        for key in special_keys:
            # è®¾ç½®ç¼“å­˜
            await cache_manager.set_cached_data(key, data, cache_type)
            
            # è·å–ç¼“å­˜
            result = await cache_manager.get_cached_data(key, cache_type)
            assert result is not None, f"Failed for key: {key}"
            assert len(result) == len(data)
    
    @pytest.mark.asyncio
    async def test_dataframe_with_special_values(self, cache_manager):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå€¼çš„DataFrame"""
        key = "special_values_key"
        cache_type = "realtime_data"
        
        # åˆ›å»ºåŒ…å«ç‰¹æ®Šå€¼çš„DataFrame
        special_df = pd.DataFrame({
            'normal_values': [1.0, 2.0, 3.0],
            'nan_values': [np.nan, 1.0, np.nan],
            'inf_values': [np.inf, -np.inf, 1.0],
            'string_values': ['normal', '', None],
            'datetime_values': [datetime.now(), pd.NaT, datetime.now() - timedelta(days=1)]
        })
        
        # è®¾ç½®å’Œè·å–åŒ…å«ç‰¹æ®Šå€¼çš„DataFrame
        await cache_manager.set_cached_data(key, special_df, cache_type)
        
        result = await cache_manager.get_cached_data(key, cache_type)
        assert result is not None
        assert len(result) == len(special_df)
        
        # éªŒè¯ç‰¹æ®Šå€¼ä¿æŒä¸å˜
        assert pd.isna(result['nan_values'].iloc[0])
        assert np.isinf(result['inf_values'].iloc[0])
    
    @pytest.mark.asyncio
    async def test_zero_ttl_handling(self, cache_manager):
        """æµ‹è¯•é›¶TTLå¤„ç†"""
        key = "zero_ttl_key"
        cache_type = "realtime_data"
        data = TestDataGenerator.generate_sample_dataframe(10)
        
        # è®¾ç½®TTLä¸º0
        await cache_manager.set_cached_data(key, data, cache_type, ttl=0)
        
        # åº”è¯¥ç«‹å³è¿‡æœŸ
        result = await cache_manager.get_cached_data(key, cache_type)
        # æ ¹æ®å®ç°ï¼Œå¯èƒ½è¿”å›Noneæˆ–è€…æ•°æ®ï¼ˆå–å†³äºæ˜¯å¦ç«‹å³è¿‡æœŸï¼‰
        # è¿™é‡Œæˆ‘ä»¬åªéªŒè¯ä¸ä¼šå´©æºƒ
        assert result is None or isinstance(result, pd.DataFrame)
    
    @pytest.mark.asyncio
    async def test_negative_ttl_handling(self, cache_manager):
        """æµ‹è¯•è´ŸTTLå¤„ç†"""
        key = "negative_ttl_key"
        cache_type = "realtime_data"
        data = TestDataGenerator.generate_sample_dataframe(10)
        
        # è®¾ç½®è´ŸTTL
        await cache_manager.set_cached_data(key, data, cache_type, ttl=-100)
        
        # åº”è¯¥èƒ½å¤Ÿå¤„ç†è´ŸTTLè€Œä¸å´©æºƒ
        result = await cache_manager.get_cached_data(key, cache_type)
        # æ ¹æ®å®ç°ï¼Œå¯èƒ½è¿”å›Noneæˆ–è€…æ•°æ®
        assert result is None or isinstance(result, pd.DataFrame)
    
    @pytest.mark.asyncio
    async def test_invalid_cache_type(self, cache_manager):
        """æµ‹è¯•æ— æ•ˆç¼“å­˜ç±»å‹"""
        key = "invalid_type_key"
        invalid_cache_type = "nonexistent_cache_type"
        data = TestDataGenerator.generate_sample_dataframe(10)
        
        # ä½¿ç”¨ä¸å­˜åœ¨çš„ç¼“å­˜ç±»å‹
        await cache_manager.set_cached_data(key, data, invalid_cache_type)
        
        # åº”è¯¥ä½¿ç”¨é»˜è®¤é…ç½®
        result = await cache_manager.get_cached_data(key, invalid_cache_type)
        assert result is not None
        pd.testing.assert_frame_equal(result, data)
    
    @pytest.mark.asyncio
    async def test_corrupted_cache_data_handling(self, cache_manager):
        """æµ‹è¯•æŸåç¼“å­˜æ•°æ®å¤„ç†"""
        key = "corrupted_data_key"
        
        # ç›´æ¥åœ¨Redisä¸­è®¾ç½®æŸåçš„æ•°æ®
        await cache_manager.redis_client.setex(key, 300, "corrupted_json_data")
        
        # å°è¯•è·å–æŸåçš„æ•°æ®
        result = await cache_manager.get_cached_data(key, "daily_data")
        
        # åº”è¯¥è¿”å›Noneè€Œä¸æ˜¯å´©æºƒ
        assert result is None
        
        # é”™è¯¯ç»Ÿè®¡åº”è¯¥å¢åŠ 
        assert cache_manager.stats.errors > 0


class TestGlobalCacheManager:
    """å…¨å±€ç¼“å­˜ç®¡ç†å™¨æµ‹è¯•ç±»"""
    
    @pytest.mark.asyncio
    async def test_get_cache_manager_singleton(self):
        """æµ‹è¯•è·å–ç¼“å­˜ç®¡ç†å™¨å•ä¾‹"""
        with patch('stock_analysis_system.data.cache_manager.cache_manager') as mock_manager:
            mock_manager.redis_client = None
            mock_manager.initialize = AsyncMock()
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨åº”è¯¥åˆå§‹åŒ–
            manager1 = await get_cache_manager()
            mock_manager.initialize.assert_called_once()
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ä¸åº”è¯¥å†æ¬¡åˆå§‹åŒ–
            mock_manager.redis_client = MockRedis()  # æ¨¡æ‹Ÿå·²åˆå§‹åŒ–
            manager2 = await get_cache_manager()
            
            # åº”è¯¥è¿”å›åŒä¸€ä¸ªå®ä¾‹
            assert manager1 is manager2
    
    @pytest.mark.asyncio
    async def test_get_cache_manager_initialization_failure(self):
        """æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥"""
        with patch('stock_analysis_system.data.cache_manager.cache_manager') as mock_manager:
            mock_manager.redis_client = None
            mock_manager.initialize = AsyncMock(side_effect=Exception("Init failed"))
            
            # å³ä½¿åˆå§‹åŒ–å¤±è´¥ï¼Œä¹Ÿåº”è¯¥è¿”å›ç®¡ç†å™¨å®ä¾‹
            manager = await get_cache_manager()
            assert manager is not None


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "--tb=short"])
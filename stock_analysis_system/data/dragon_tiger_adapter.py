"""
é¾™è™æ¦œæ•°æ®é€‚é…å™¨

åŸºäº tmp/core/crawling/stock_lhb_em.py åˆ›å»ºçš„é¾™è™æ¦œæ•°æ®é€‚é…å™¨ï¼Œ
æä¾›é¾™è™æ¦œè¯¦æƒ…ã€æœºæ„ç»Ÿè®¡ã€è¥ä¸šéƒ¨æ’è¡Œç­‰æ•°æ®çš„ç»Ÿä¸€æ¥å£ã€‚

Author: Stock Analysis System Team
Date: 2024-01-20
"""

import asyncio
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
import pandas as pd
import requests
from dataclasses import dataclass
from tqdm import tqdm

logger = logging.getLogger(__name__)


@dataclass
class DragonTigerRequest:
    """é¾™è™æ¦œè¯·æ±‚ç»“æ„"""
    data_type: str = "detail"  # detail, stock_statistic, institution_daily, institution_statistic, department_active, department_ranking, department_statistic, stock_detail
    start_date: str = ""
    end_date: str = ""
    symbol: str = ""  # è‚¡ç¥¨ä»£ç 
    period: str = "è¿‘ä¸€æœˆ"  # è¿‘ä¸€æœˆ, è¿‘ä¸‰æœˆ, è¿‘å…­æœˆ, è¿‘ä¸€å¹´
    flag: str = "ä¹°å…¥"  # ä¹°å…¥, å–å‡º (ä»…ç”¨äºstock_detail)


@dataclass
class DragonTigerResponse:
    """é¾™è™æ¦œå“åº”ç»“æ„"""
    success: bool
    data: pd.DataFrame
    error_message: str = ""
    response_time: float = 0.0
    data_source: str = "eastmoney_dragon_tiger"
    timestamp: datetime = None
    data_type: str = ""
    total_pages: int = 1


class DragonTigerAdapter:
    """é¾™è™æ¦œæ•°æ®é€‚é…å™¨"""
    
    def __init__(self, timeout: int = 30, max_retries: int = 3):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        
        # APIç«¯ç‚¹
        self.base_url = "https://datacenter-web.eastmoney.com/api/data/v1/get"
        
        # æ—¶é—´å‘¨æœŸæ˜ å°„
        self.period_map = {
            "è¿‘ä¸€æœˆ": "01",
            "è¿‘ä¸‰æœˆ": "02", 
            "è¿‘å…­æœˆ": "03",
            "è¿‘ä¸€å¹´": "04"
        }
        
        # é”™è¯¯ç»Ÿè®¡
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def get_dragon_tiger_detail(self, request: DragonTigerRequest) -> DragonTigerResponse:
        """
        è·å–é¾™è™æ¦œè¯¦æƒ…æ•°æ®
        
        Args:
            request: é¾™è™æ¦œè¯·æ±‚å¯¹è±¡
            
        Returns:
            é¾™è™æ¦œå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            # æ ¼å¼åŒ–æ—¥æœŸ
            start_date = self._format_date(request.start_date)
            end_date = self._format_date(request.end_date)
            
            params = {
                "sortColumns": "SECURITY_CODE,TRADE_DATE",
                "sortTypes": "1,-1",
                "pageSize": "5000",
                "pageNumber": "1",
                "reportName": "RPT_DAILYBILLBOARD_DETAILSNEW",
                "columns": "SECURITY_CODE,SECUCODE,SECURITY_NAME_ABBR,TRADE_DATE,EXPLAIN,CLOSE_PRICE,CHANGE_RATE,BILLBOARD_NET_AMT,BILLBOARD_BUY_AMT,BILLBOARD_SELL_AMT,BILLBOARD_DEAL_AMT,ACCUM_AMOUNT,DEAL_NET_RATIO,DEAL_AMOUNT_RATIO,TURNOVERRATE,FREE_MARKET_CAP,EXPLANATION,D1_CLOSE_ADJCHRATE,D2_CLOSE_ADJCHRATE,D5_CLOSE_ADJCHRATE,D10_CLOSE_ADJCHRATE,SECURITY_TYPE_CODE",
                "source": "WEB",
                "client": "WEB",
                "filter": f"(TRADE_DATE<='{end_date}')(TRADE_DATE>='{start_date}')",
            }
            
            # è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®
            all_data = await self._fetch_all_pages(params)
            if not all_data:
                return DragonTigerResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°é¾™è™æ¦œæ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="detail"
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_dragon_tiger_detail_data(all_data)
            
            # æ•°æ®å…³è”æ€§éªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥
            df = self._validate_and_clean_data(df)
            
            self.error_stats['successful_requests'] += 1
            
            return DragonTigerResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="detail"
            )
            
        except Exception as e:
            logger.error(f"è·å–é¾™è™æ¦œè¯¦æƒ…å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return DragonTigerResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="detail"
            )
    
    async def get_stock_statistic(self, request: DragonTigerRequest) -> DragonTigerResponse:
        """
        è·å–ä¸ªè‚¡ä¸Šæ¦œç»Ÿè®¡æ•°æ®
        
        Args:
            request: é¾™è™æ¦œè¯·æ±‚å¯¹è±¡
            
        Returns:
            é¾™è™æ¦œå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            params = {
                "sortColumns": "BILLBOARD_TIMES,LATEST_TDATE,SECURITY_CODE",
                "sortTypes": "-1,-1,1",
                "pageSize": "500",
                "pageNumber": "1",
                "reportName": "RPT_BILLBOARD_TRADEALL",
                "columns": "ALL",
                "source": "WEB",
                "client": "WEB",
                "filter": f'(STATISTICS_CYCLE="{self.period_map[request.period]}")',
            }
            
            response_data = await self._make_request(params)
            if not response_data:
                return DragonTigerResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°ä¸ªè‚¡ç»Ÿè®¡æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="stock_statistic"
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_stock_statistic_data(response_data["result"]["data"])
            
            self.error_stats['successful_requests'] += 1
            
            return DragonTigerResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="stock_statistic"
            )
            
        except Exception as e:
            logger.error(f"è·å–ä¸ªè‚¡ç»Ÿè®¡å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return DragonTigerResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="stock_statistic"
            )
    
    async def get_institution_daily_statistic(self, request: DragonTigerRequest) -> DragonTigerResponse:
        """
        è·å–æœºæ„ä¹°å–æ¯æ—¥ç»Ÿè®¡æ•°æ®
        
        Args:
            request: é¾™è™æ¦œè¯·æ±‚å¯¹è±¡
            
        Returns:
            é¾™è™æ¦œå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            start_date = self._format_date(request.start_date)
            end_date = self._format_date(request.end_date)
            
            params = {
                "sortColumns": "NET_BUY_AMT,TRADE_DATE,SECURITY_CODE",
                "sortTypes": "-1,-1,1",
                "pageSize": "5000",
                "pageNumber": "1",
                "reportName": "RPT_ORGANIZATION_TRADE_DETAILS",
                "columns": "ALL",
                "source": "WEB",
                "client": "WEB",
                "filter": f"(TRADE_DATE>='{start_date}')(TRADE_DATE<='{end_date}')",
            }
            
            response_data = await self._make_request(params)
            if not response_data:
                return DragonTigerResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°æœºæ„æ¯æ—¥ç»Ÿè®¡æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="institution_daily"
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_institution_daily_data(response_data["result"]["data"])
            
            self.error_stats['successful_requests'] += 1
            
            return DragonTigerResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="institution_daily"
            )
            
        except Exception as e:
            logger.error(f"è·å–æœºæ„æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return DragonTigerResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="institution_daily"
            )
    
    async def get_department_ranking(self, request: DragonTigerRequest) -> DragonTigerResponse:
        """
        è·å–è¥ä¸šéƒ¨æ’è¡Œæ•°æ®
        
        Args:
            request: é¾™è™æ¦œè¯·æ±‚å¯¹è±¡
            
        Returns:
            é¾™è™æ¦œå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            params = {
                "sortColumns": "TOTAL_BUYER_SALESTIMES_1DAY,OPERATEDEPT_CODE",
                "sortTypes": "-1,1",
                "pageSize": "5000",
                "pageNumber": "1",
                "reportName": "RPT_RATEDEPT_RETURNT_RANKING",
                "columns": "ALL",
                "source": "WEB",
                "client": "WEB",
                "filter": f'(STATISTICSCYCLE="{self.period_map[request.period]}")',
            }
            
            # è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®
            all_data = await self._fetch_all_pages(params)
            if not all_data:
                return DragonTigerResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°è¥ä¸šéƒ¨æ’è¡Œæ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="department_ranking"
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_department_ranking_data(all_data)
            
            self.error_stats['successful_requests'] += 1
            
            return DragonTigerResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="department_ranking"
            )
            
        except Exception as e:
            logger.error(f"è·å–è¥ä¸šéƒ¨æ’è¡Œå¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return DragonTigerResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="department_ranking"
            )
    
    async def get_stock_detail(self, request: DragonTigerRequest) -> DragonTigerResponse:
        """
        è·å–ä¸ªè‚¡é¾™è™æ¦œè¯¦æƒ…
        
        Args:
            request: é¾™è™æ¦œè¯·æ±‚å¯¹è±¡ï¼Œéœ€è¦åŒ…å«symbolå’Œstart_date
            
        Returns:
            é¾™è™æ¦œå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            flag_map = {"ä¹°å…¥": "BUY", "å–å‡º": "SELL"}
            report_map = {
                "ä¹°å…¥": "RPT_BILLBOARD_DAILYDETAILSBUY",
                "å–å‡º": "RPT_BILLBOARD_DAILYDETAILSSELL",
            }
            
            date_formatted = self._format_date(request.start_date)
            
            params = {
                "reportName": report_map[request.flag],
                "columns": "ALL",
                "filter": f"""(TRADE_DATE='{date_formatted}')(SECURITY_CODE="{request.symbol}")""",
                "pageNumber": "1",
                "pageSize": "500",
                "sortTypes": "-1",
                "sortColumns": flag_map[request.flag],
                "source": "WEB",
                "client": "WEB",
                "_": str(int(time.time() * 1000)),
            }
            
            response_data = await self._make_request(params)
            if not response_data:
                return DragonTigerResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°ä¸ªè‚¡è¯¦æƒ…æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="stock_detail"
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_stock_detail_data(response_data["result"]["data"], request.flag)
            
            self.error_stats['successful_requests'] += 1
            
            return DragonTigerResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="stock_detail"
            )
            
        except Exception as e:
            logger.error(f"è·å–ä¸ªè‚¡è¯¦æƒ…å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return DragonTigerResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="stock_detail"
            )
    
    async def _make_request(self, params: Dict) -> Optional[Dict]:
        """å‘é€HTTPè¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        for attempt in range(self.max_retries):
            try:
                response = self.session.get(
                    self.base_url, 
                    params=params, 
                    timeout=self.timeout
                )
                response.raise_for_status()
                return response.json()
                
            except requests.exceptions.Timeout:
                self.error_stats['network_errors'] += 1
                logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{self.max_retries}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                    
            except requests.exceptions.RequestException as e:
                self.error_stats['network_errors'] += 1
                logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                    
            except ValueError as e:
                self.error_stats['data_format_errors'] += 1
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                break
                
        return None
    
    async def _fetch_all_pages(self, base_params: Dict) -> List[Dict]:
        """è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®"""
        all_data = []
        
        # è·å–ç¬¬ä¸€é¡µæ•°æ®
        response_data = await self._make_request(base_params)
        if not response_data or not response_data.get("result"):
            return all_data
        
        first_page_data = response_data["result"].get("data", [])
        all_data.extend(first_page_data)
        
        # è·å–æ€»é¡µæ•°
        total_pages = response_data["result"].get("pages", 1)
        
        # è·å–å…¶ä»–é¡µé¢æ•°æ®
        for page in range(2, total_pages + 1):
            params = base_params.copy()
            params["pageNumber"] = str(page)
            
            response_data = await self._make_request(params)
            if response_data and response_data.get("result", {}).get("data"):
                all_data.extend(response_data["result"]["data"])
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.1)
        
        return all_data
    
    def _format_date(self, date_str: str) -> str:
        """æ ¼å¼åŒ–æ—¥æœŸå­—ç¬¦ä¸²"""
        if not date_str:
            return datetime.now().strftime("%Y-%m-%d")
        
        if len(date_str) == 8:  # YYYYMMDD
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
        
        return date_str
    
    def _process_dragon_tiger_detail_data(self, data: List[Dict]) -> pd.DataFrame:
        """å¤„ç†é¾™è™æ¦œè¯¦æƒ…æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        df.reset_index(inplace=True)
        df["index"] = df.index + 1
        
        # é‡å‘½ååˆ—
        df.rename(columns={
            "index": "åºå·",
            "SECURITY_CODE": "ä»£ç ",
            "SECUCODE": "-",
            "SECURITY_NAME_ABBR": "åç§°",
            "TRADE_DATE": "ä¸Šæ¦œæ—¥",
            "EXPLAIN": "è§£è¯»",
            "CLOSE_PRICE": "æ”¶ç›˜ä»·",
            "CHANGE_RATE": "æ¶¨è·Œå¹…",
            "BILLBOARD_NET_AMT": "é¾™è™æ¦œå‡€ä¹°é¢",
            "BILLBOARD_BUY_AMT": "é¾™è™æ¦œä¹°å…¥é¢",
            "BILLBOARD_SELL_AMT": "é¾™è™æ¦œå–å‡ºé¢",
            "BILLBOARD_DEAL_AMT": "é¾™è™æ¦œæˆäº¤é¢",
            "ACCUM_AMOUNT": "å¸‚åœºæ€»æˆäº¤é¢",
            "DEAL_NET_RATIO": "å‡€ä¹°é¢å æ€»æˆäº¤æ¯”",
            "DEAL_AMOUNT_RATIO": "æˆäº¤é¢å æ€»æˆäº¤æ¯”",
            "TURNOVERRATE": "æ¢æ‰‹ç‡",
            "FREE_MARKET_CAP": "æµé€šå¸‚å€¼",
            "EXPLANATION": "ä¸Šæ¦œåŸå› ",
            "D1_CLOSE_ADJCHRATE": "ä¸Šæ¦œå1æ—¥",
            "D2_CLOSE_ADJCHRATE": "ä¸Šæ¦œå2æ—¥",
            "D5_CLOSE_ADJCHRATE": "ä¸Šæ¦œå5æ—¥",
            "D10_CLOSE_ADJCHRATE": "ä¸Šæ¦œå10æ—¥",
        }, inplace=True)
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[[
            "åºå·", "ä»£ç ", "åç§°", "ä¸Šæ¦œæ—¥", "è§£è¯»", "æ”¶ç›˜ä»·", "æ¶¨è·Œå¹…",
            "é¾™è™æ¦œå‡€ä¹°é¢", "é¾™è™æ¦œä¹°å…¥é¢", "é¾™è™æ¦œå–å‡ºé¢", "é¾™è™æ¦œæˆäº¤é¢",
            "å¸‚åœºæ€»æˆäº¤é¢", "å‡€ä¹°é¢å æ€»æˆäº¤æ¯”", "æˆäº¤é¢å æ€»æˆäº¤æ¯”", "æ¢æ‰‹ç‡",
            "æµé€šå¸‚å€¼", "ä¸Šæ¦œåŸå› ", "ä¸Šæ¦œå1æ—¥", "ä¸Šæ¦œå2æ—¥", "ä¸Šæ¦œå5æ—¥", "ä¸Šæ¦œå10æ—¥"
        ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self._convert_numeric_columns(df, [
            "æ”¶ç›˜ä»·", "æ¶¨è·Œå¹…", "é¾™è™æ¦œå‡€ä¹°é¢", "é¾™è™æ¦œä¹°å…¥é¢", "é¾™è™æ¦œå–å‡ºé¢",
            "é¾™è™æ¦œæˆäº¤é¢", "å¸‚åœºæ€»æˆäº¤é¢", "å‡€ä¹°é¢å æ€»æˆäº¤æ¯”", "æˆäº¤é¢å æ€»æˆäº¤æ¯”",
            "æ¢æ‰‹ç‡", "æµé€šå¸‚å€¼", "ä¸Šæ¦œå1æ—¥", "ä¸Šæ¦œå2æ—¥", "ä¸Šæ¦œå5æ—¥", "ä¸Šæ¦œå10æ—¥"
        ])
        
        # æ—¥æœŸè½¬æ¢
        df["ä¸Šæ¦œæ—¥"] = pd.to_datetime(df["ä¸Šæ¦œæ—¥"]).dt.date
        
        return df
    
    def _process_stock_statistic_data(self, data: List[Dict]) -> pd.DataFrame:
        """å¤„ç†ä¸ªè‚¡ç»Ÿè®¡æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        df.reset_index(inplace=True)
        df["index"] = df.index + 1
        
        # è®¾ç½®åˆ—å
        df.columns = [
            "åºå·", "-", "ä»£ç ", "æœ€è¿‘ä¸Šæ¦œæ—¥", "åç§°", "è¿‘1ä¸ªæœˆæ¶¨è·Œå¹…", "è¿‘3ä¸ªæœˆæ¶¨è·Œå¹…",
            "è¿‘6ä¸ªæœˆæ¶¨è·Œå¹…", "è¿‘1å¹´æ¶¨è·Œå¹…", "æ¶¨è·Œå¹…", "æ”¶ç›˜ä»·", "-", "é¾™è™æ¦œæ€»æˆäº¤é¢",
            "é¾™è™æ¦œå‡€ä¹°é¢", "-", "-", "æœºæ„ä¹°å…¥å‡€é¢", "ä¸Šæ¦œæ¬¡æ•°", "é¾™è™æ¦œä¹°å…¥é¢",
            "é¾™è™æ¦œå–å‡ºé¢", "æœºæ„ä¹°å…¥æ€»é¢", "æœºæ„å–å‡ºæ€»é¢", "ä¹°æ–¹æœºæ„æ¬¡æ•°", "å–æ–¹æœºæ„æ¬¡æ•°", "-"
        ]
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[[
            "åºå·", "ä»£ç ", "åç§°", "æœ€è¿‘ä¸Šæ¦œæ—¥", "æ”¶ç›˜ä»·", "æ¶¨è·Œå¹…", "ä¸Šæ¦œæ¬¡æ•°",
            "é¾™è™æ¦œå‡€ä¹°é¢", "é¾™è™æ¦œä¹°å…¥é¢", "é¾™è™æ¦œå–å‡ºé¢", "é¾™è™æ¦œæ€»æˆäº¤é¢",
            "ä¹°æ–¹æœºæ„æ¬¡æ•°", "å–æ–¹æœºæ„æ¬¡æ•°", "æœºæ„ä¹°å…¥å‡€é¢", "æœºæ„ä¹°å…¥æ€»é¢", "æœºæ„å–å‡ºæ€»é¢",
            "è¿‘1ä¸ªæœˆæ¶¨è·Œå¹…", "è¿‘3ä¸ªæœˆæ¶¨è·Œå¹…", "è¿‘6ä¸ªæœˆæ¶¨è·Œå¹…", "è¿‘1å¹´æ¶¨è·Œå¹…"
        ]]
        
        # æ—¥æœŸè½¬æ¢
        df["æœ€è¿‘ä¸Šæ¦œæ—¥"] = pd.to_datetime(df["æœ€è¿‘ä¸Šæ¦œæ—¥"]).dt.date
        
        return df
    
    def _process_institution_daily_data(self, data: List[Dict]) -> pd.DataFrame:
        """å¤„ç†æœºæ„æ¯æ—¥ç»Ÿè®¡æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        df.reset_index(inplace=True)
        df["index"] = df.index + 1
        
        # åŠ¨æ€è®¾ç½®åˆ—åï¼Œé€‚åº”ä¸åŒçš„åˆ—æ•°
        expected_cols = [
            "åºå·", "-", "åç§°", "ä»£ç ", "ä¸Šæ¦œæ—¥æœŸ", "æ”¶ç›˜ä»·", "æ¶¨è·Œå¹…", "ä¹°æ–¹æœºæ„æ•°",
            "å–æ–¹æœºæ„æ•°", "æœºæ„ä¹°å…¥æ€»é¢", "æœºæ„å–å‡ºæ€»é¢", "æœºæ„ä¹°å…¥å‡€é¢", "å¸‚åœºæ€»æˆäº¤é¢",
            "æœºæ„å‡€ä¹°é¢å æ€»æˆäº¤é¢æ¯”", "æ¢æ‰‹ç‡", "æµé€šå¸‚å€¼", "ä¸Šæ¦œåŸå› "
        ]
        
        actual_cols = len(df.columns)
        if actual_cols >= len(expected_cols):
            # å¦‚æœå®é™…åˆ—æ•°æ›´å¤šï¼Œæ·»åŠ å ä½ç¬¦
            extra_cols = [f"-{i}" for i in range(actual_cols - len(expected_cols))]
            df.columns = expected_cols + extra_cols
        else:
            # å¦‚æœå®é™…åˆ—æ•°è¾ƒå°‘ï¼Œæˆªå–å¯¹åº”çš„åˆ—å
            df.columns = expected_cols[:actual_cols]
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[[
            "åºå·", "ä»£ç ", "åç§°", "æ”¶ç›˜ä»·", "æ¶¨è·Œå¹…", "ä¹°æ–¹æœºæ„æ•°", "å–æ–¹æœºæ„æ•°",
            "æœºæ„ä¹°å…¥æ€»é¢", "æœºæ„å–å‡ºæ€»é¢", "æœºæ„ä¹°å…¥å‡€é¢", "å¸‚åœºæ€»æˆäº¤é¢",
            "æœºæ„å‡€ä¹°é¢å æ€»æˆäº¤é¢æ¯”", "æ¢æ‰‹ç‡", "æµé€šå¸‚å€¼", "ä¸Šæ¦œåŸå› ", "ä¸Šæ¦œæ—¥æœŸ"
        ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self._convert_numeric_columns(df, [
            "æ”¶ç›˜ä»·", "æ¶¨è·Œå¹…", "ä¹°æ–¹æœºæ„æ•°", "å–æ–¹æœºæ„æ•°", "æœºæ„ä¹°å…¥æ€»é¢",
            "æœºæ„å–å‡ºæ€»é¢", "æœºæ„ä¹°å…¥å‡€é¢", "å¸‚åœºæ€»æˆäº¤é¢", "æœºæ„å‡€ä¹°é¢å æ€»æˆäº¤é¢æ¯”",
            "æ¢æ‰‹ç‡", "æµé€šå¸‚å€¼"
        ])
        
        # æ—¥æœŸè½¬æ¢
        df["ä¸Šæ¦œæ—¥æœŸ"] = pd.to_datetime(df["ä¸Šæ¦œæ—¥æœŸ"]).dt.date
        
        return df
    
    def _process_department_ranking_data(self, data: List[Dict]) -> pd.DataFrame:
        """å¤„ç†è¥ä¸šéƒ¨æ’è¡Œæ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        df.reset_index(inplace=True)
        df["index"] = df.index + 1
        
        # é‡å‘½ååˆ—
        df.rename(columns={
            "index": "åºå·",
            "OPERATEDEPT_NAME": "è¥ä¸šéƒ¨åç§°",
            "TOTAL_BUYER_SALESTIMES_1DAY": "ä¸Šæ¦œå1å¤©-ä¹°å…¥æ¬¡æ•°",
            "AVERAGE_INCREASE_1DAY": "ä¸Šæ¦œå1å¤©-å¹³å‡æ¶¨å¹…",
            "RISE_PROBABILITY_1DAY": "ä¸Šæ¦œå1å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "TOTAL_BUYER_SALESTIMES_2DAY": "ä¸Šæ¦œå2å¤©-ä¹°å…¥æ¬¡æ•°",
            "AVERAGE_INCREASE_2DAY": "ä¸Šæ¦œå2å¤©-å¹³å‡æ¶¨å¹…",
            "RISE_PROBABILITY_2DAY": "ä¸Šæ¦œå2å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "TOTAL_BUYER_SALESTIMES_3DAY": "ä¸Šæ¦œå3å¤©-ä¹°å…¥æ¬¡æ•°",
            "AVERAGE_INCREASE_3DAY": "ä¸Šæ¦œå3å¤©-å¹³å‡æ¶¨å¹…",
            "RISE_PROBABILITY_3DAY": "ä¸Šæ¦œå3å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "TOTAL_BUYER_SALESTIMES_5DAY": "ä¸Šæ¦œå5å¤©-ä¹°å…¥æ¬¡æ•°",
            "AVERAGE_INCREASE_5DAY": "ä¸Šæ¦œå5å¤©-å¹³å‡æ¶¨å¹…",
            "RISE_PROBABILITY_5DAY": "ä¸Šæ¦œå5å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "TOTAL_BUYER_SALESTIMES_10DAY": "ä¸Šæ¦œå10å¤©-ä¹°å…¥æ¬¡æ•°",
            "AVERAGE_INCREASE_10DAY": "ä¸Šæ¦œå10å¤©-å¹³å‡æ¶¨å¹…",
            "RISE_PROBABILITY_10DAY": "ä¸Šæ¦œå10å¤©-ä¸Šæ¶¨æ¦‚ç‡",
        }, inplace=True)
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[[
            "åºå·", "è¥ä¸šéƒ¨åç§°", "ä¸Šæ¦œå1å¤©-ä¹°å…¥æ¬¡æ•°", "ä¸Šæ¦œå1å¤©-å¹³å‡æ¶¨å¹…", "ä¸Šæ¦œå1å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "ä¸Šæ¦œå2å¤©-ä¹°å…¥æ¬¡æ•°", "ä¸Šæ¦œå2å¤©-å¹³å‡æ¶¨å¹…", "ä¸Šæ¦œå2å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "ä¸Šæ¦œå3å¤©-ä¹°å…¥æ¬¡æ•°", "ä¸Šæ¦œå3å¤©-å¹³å‡æ¶¨å¹…", "ä¸Šæ¦œå3å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "ä¸Šæ¦œå5å¤©-ä¹°å…¥æ¬¡æ•°", "ä¸Šæ¦œå5å¤©-å¹³å‡æ¶¨å¹…", "ä¸Šæ¦œå5å¤©-ä¸Šæ¶¨æ¦‚ç‡",
            "ä¸Šæ¦œå10å¤©-ä¹°å…¥æ¬¡æ•°", "ä¸Šæ¦œå10å¤©-å¹³å‡æ¶¨å¹…", "ä¸Šæ¦œå10å¤©-ä¸Šæ¶¨æ¦‚ç‡"
        ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = [col for col in df.columns if col not in ["åºå·", "è¥ä¸šéƒ¨åç§°"]]
        self._convert_numeric_columns(df, numeric_cols)
        
        return df
    
    def _process_stock_detail_data(self, data: List[Dict], flag: str) -> pd.DataFrame:
        """å¤„ç†ä¸ªè‚¡è¯¦æƒ…æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        df.reset_index(inplace=True)
        df["index"] = df.index + 1
        
        # åŠ¨æ€è®¾ç½®åˆ—åï¼Œé€‚åº”ä¸åŒçš„åˆ—æ•°
        expected_cols = [
            "åºå·", "-", "-", "-", "-", "äº¤æ˜“è¥ä¸šéƒ¨åç§°", "ç±»å‹", "-", "-", "-", "-",
            "ä¹°å…¥é‡‘é¢", "å–å‡ºé‡‘é¢", "å‡€é¢", "-", "-", "-", "-",
            "ä¹°å…¥é‡‘é¢-å æ€»æˆäº¤æ¯”ä¾‹", "å–å‡ºé‡‘é¢-å æ€»æˆäº¤æ¯”ä¾‹"
        ]
        
        actual_cols = len(df.columns)
        if actual_cols >= len(expected_cols):
            # å¦‚æœå®é™…åˆ—æ•°æ›´å¤šï¼Œæ·»åŠ å ä½ç¬¦
            extra_cols = [f"-{i}" for i in range(actual_cols - len(expected_cols))]
            df.columns = expected_cols + extra_cols
        else:
            # å¦‚æœå®é™…åˆ—æ•°è¾ƒå°‘ï¼Œæˆªå–å¯¹åº”çš„åˆ—å
            df.columns = expected_cols[:actual_cols]
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[[
            "åºå·", "äº¤æ˜“è¥ä¸šéƒ¨åç§°", "ä¹°å…¥é‡‘é¢", "ä¹°å…¥é‡‘é¢-å æ€»æˆäº¤æ¯”ä¾‹",
            "å–å‡ºé‡‘é¢", "å–å‡ºé‡‘é¢-å æ€»æˆäº¤æ¯”ä¾‹", "å‡€é¢", "ç±»å‹"
        ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self._convert_numeric_columns(df, [
            "ä¹°å…¥é‡‘é¢", "ä¹°å…¥é‡‘é¢-å æ€»æˆäº¤æ¯”ä¾‹", "å–å‡ºé‡‘é¢", "å–å‡ºé‡‘é¢-å æ€»æˆäº¤æ¯”ä¾‹"
        ])
        
        # æŒ‰ç±»å‹æ’åº
        df.sort_values("ç±»å‹", inplace=True)
        df.reset_index(inplace=True, drop=True)
        df["åºå·"] = range(1, len(df) + 1)
        
        return df
    
    def _convert_numeric_columns(self, df: pd.DataFrame, columns: List[str]):
        """è½¬æ¢æ•°å€¼åˆ—çš„æ•°æ®ç±»å‹"""
        for col in columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
    
    def _validate_and_clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®å…³è”æ€§éªŒè¯å’Œå®Œæ•´æ€§æ£€æŸ¥"""
        if df.empty:
            return df
        
        # å»é™¤é‡å¤æ•°æ®
        if "ä»£ç " in df.columns and "ä¸Šæ¦œæ—¥" in df.columns:
            df = df.drop_duplicates(subset=["ä»£ç ", "ä¸Šæ¦œæ—¥"], keep="last")
        
        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        if "é¾™è™æ¦œå‡€ä¹°é¢" in df.columns:
            # æ£€æŸ¥å‡€ä¹°é¢æ˜¯å¦ç­‰äºä¹°å…¥é¢å‡å»å–å‡ºé¢
            if "é¾™è™æ¦œä¹°å…¥é¢" in df.columns and "é¾™è™æ¦œå–å‡ºé¢" in df.columns:
                calculated_net = df["é¾™è™æ¦œä¹°å…¥é¢"] - df["é¾™è™æ¦œå–å‡ºé¢"]
                # å…è®¸å°çš„è¯¯å·®
                mask = abs(df["é¾™è™æ¦œå‡€ä¹°é¢"] - calculated_net) > 1000
                if mask.any():
                    logger.warning(f"å‘ç° {mask.sum()} æ¡æ•°æ®çš„å‡€ä¹°é¢è®¡ç®—ä¸ä¸€è‡´")
        
        return df.reset_index(drop=True)
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """è·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.error_stats['total_requests']
        if total_requests == 0:
            return self.error_stats
        
        return {
            **self.error_stats,
            'success_rate': self.error_stats['successful_requests'] / total_requests,
            'error_rate': (total_requests - self.error_stats['successful_requests']) / total_requests
        }
    
    def reset_error_statistics(self):
        """é‡ç½®é”™è¯¯ç»Ÿè®¡"""
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•è·å–å°‘é‡é¾™è™æ¦œæ•°æ®
            yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
            request = DragonTigerRequest(
                data_type="detail",
                start_date=yesterday,
                end_date=yesterday
            )
            
            response = await self.get_dragon_tiger_detail(request)
            
            return {
                'status': 'healthy' if response.success else 'unhealthy',
                'response_time': response.response_time,
                'error_message': response.error_message,
                'data_available': not response.data.empty,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error_message': str(e),
                'timestamp': datetime.now().isoformat()
            }


# æµ‹è¯•å’Œä½¿ç”¨ç¤ºä¾‹
async def test_dragon_tiger_adapter():
    """æµ‹è¯•é¾™è™æ¦œé€‚é…å™¨"""
    print("ğŸ” æµ‹è¯•é¾™è™æ¦œæ•°æ®é€‚é…å™¨")
    print("=" * 50)
    
    adapter = DragonTigerAdapter()
    
    # æµ‹è¯•é¾™è™æ¦œè¯¦æƒ…
    print("1. æµ‹è¯•é¾™è™æ¦œè¯¦æƒ…...")
    detail_request = DragonTigerRequest(
        data_type="detail",
        start_date="20240101",
        end_date="20240110"
    )
    
    detail_response = await adapter.get_dragon_tiger_detail(detail_request)
    print(f"   æˆåŠŸ: {detail_response.success}")
    print(f"   å“åº”æ—¶é—´: {detail_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(detail_response.data)}")
    
    # æµ‹è¯•ä¸ªè‚¡ç»Ÿè®¡
    print("\n2. æµ‹è¯•ä¸ªè‚¡ç»Ÿè®¡...")
    stock_stat_request = DragonTigerRequest(
        data_type="stock_statistic",
        period="è¿‘ä¸€æœˆ"
    )
    
    stock_stat_response = await adapter.get_stock_statistic(stock_stat_request)
    print(f"   æˆåŠŸ: {stock_stat_response.success}")
    print(f"   å“åº”æ—¶é—´: {stock_stat_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(stock_stat_response.data)}")
    
    # æµ‹è¯•è¥ä¸šéƒ¨æ’è¡Œ
    print("\n3. æµ‹è¯•è¥ä¸šéƒ¨æ’è¡Œ...")
    dept_ranking_request = DragonTigerRequest(
        data_type="department_ranking",
        period="è¿‘ä¸€æœˆ"
    )
    
    dept_ranking_response = await adapter.get_department_ranking(dept_ranking_request)
    print(f"   æˆåŠŸ: {dept_ranking_response.success}")
    print(f"   å“åº”æ—¶é—´: {dept_ranking_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(dept_ranking_response.data)}")
    
    # å¥åº·æ£€æŸ¥
    print("\n4. å¥åº·æ£€æŸ¥...")
    health = await adapter.health_check()
    print(f"   çŠ¶æ€: {health['status']}")
    print(f"   å“åº”æ—¶é—´: {health.get('response_time', 0):.2f}ç§’")
    
    # é”™è¯¯ç»Ÿè®¡
    print("\n5. é”™è¯¯ç»Ÿè®¡...")
    stats = adapter.get_error_statistics()
    print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"   æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}")
    
    print("\nâœ… é¾™è™æ¦œé€‚é…å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(test_dragon_tiger_adapter())
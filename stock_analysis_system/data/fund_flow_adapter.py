"""
èµ„é‡‘æµå‘æ•°æ®é€‚é…å™¨

åŸºäº tmp/core/crawling/stock_fund_em.py åˆ›å»ºçš„èµ„é‡‘æµå‘æ•°æ®é€‚é…å™¨ï¼Œ
æä¾›ä¸ªè‚¡èµ„é‡‘æµå‘å’Œæ¿å—èµ„é‡‘æµå‘æ•°æ®çš„ç»Ÿä¸€æ¥å£ã€‚

Author: Stock Analysis System Team
Date: 2024-01-20
"""

import asyncio
import json
import logging
import math
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
import pandas as pd
import requests
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class FundFlowRequest:
    """èµ„é‡‘æµå‘è¯·æ±‚ç»“æ„"""
    data_type: str = "individual"  # individual, sector
    indicator: str = "5æ—¥"  # ä»Šæ—¥, 3æ—¥, 5æ—¥, 10æ—¥
    sector_type: str = "è¡Œä¸šèµ„é‡‘æµ"  # è¡Œä¸šèµ„é‡‘æµ, æ¦‚å¿µèµ„é‡‘æµ, åœ°åŸŸèµ„é‡‘æµ
    symbols: Optional[List[str]] = None  # æŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—è¡¨


@dataclass
class FundFlowResponse:
    """èµ„é‡‘æµå‘å“åº”ç»“æ„"""
    success: bool
    data: pd.DataFrame
    error_message: str = ""
    response_time: float = 0.0
    data_source: str = "eastmoney_fund_flow"
    timestamp: datetime = None
    data_type: str = ""
    indicator: str = ""


class FundFlowAdapter:
    """èµ„é‡‘æµå‘æ•°æ®é€‚é…å™¨"""
    
    def __init__(self, timeout: int = 15, max_retries: int = 3):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        
        # APIç«¯ç‚¹
        self.base_url = "http://push2.eastmoney.com/api/qt/clist/get"
        
        # ä¸ªè‚¡èµ„é‡‘æµå‘æŒ‡æ ‡æ˜ å°„
        self.individual_indicator_map = {
            "ä»Šæ—¥": [
                "f62",
                "f12,f14,f2,f3,f62,f184,f66,f69,f72,f75,f78,f81,f84,f87,f204,f205,f124",
            ],
            "3æ—¥": [
                "f267",
                "f12,f14,f2,f127,f267,f268,f269,f270,f271,f272,f273,f274,f275,f276,f257,f258,f124",
            ],
            "5æ—¥": [
                "f164",
                "f12,f14,f2,f109,f164,f165,f166,f167,f168,f169,f170,f171,f172,f173,f257,f258,f124",
            ],
            "10æ—¥": [
                "f174",
                "f12,f14,f2,f160,f174,f175,f176,f177,f178,f179,f180,f181,f182,f183,f260,f261,f124",
            ],
        }
        
        # æ¿å—èµ„é‡‘æµå‘æŒ‡æ ‡æ˜ å°„
        self.sector_indicator_map = {
            "ä»Šæ—¥": [
                "f62",
                "1",
                "f12,f14,f2,f3,f62,f184,f66,f69,f72,f75,f78,f81,f84,f87,f204,f205,f124",
            ],
            "5æ—¥": [
                "f164",
                "5",
                "f12,f14,f2,f109,f164,f165,f166,f167,f168,f169,f170,f171,f172,f173,f257,f258,f124",
            ],
            "10æ—¥": [
                "f174",
                "10",
                "f12,f14,f2,f160,f174,f175,f176,f177,f178,f179,f180,f181,f182,f183,f260,f261,f124",
            ],
        }
        
        # æ¿å—ç±»å‹æ˜ å°„
        self.sector_type_map = {
            "è¡Œä¸šèµ„é‡‘æµ": "2",
            "æ¦‚å¿µèµ„é‡‘æµ": "3", 
            "åœ°åŸŸèµ„é‡‘æµ": "1"
        }
        
        # é”™è¯¯ç»Ÿè®¡
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def get_individual_fund_flow(self, request: FundFlowRequest) -> FundFlowResponse:
        """
        è·å–ä¸ªè‚¡èµ„é‡‘æµå‘æ•°æ®
        
        Args:
            request: èµ„é‡‘æµå‘è¯·æ±‚å¯¹è±¡
            
        Returns:
            èµ„é‡‘æµå‘å“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            if request.indicator not in self.individual_indicator_map:
                return FundFlowResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"ä¸æ”¯æŒçš„æŒ‡æ ‡: {request.indicator}",
                    response_time=time.time() - start_time,
                    data_type="individual",
                    indicator=request.indicator
                )
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            indicator_config = self.individual_indicator_map[request.indicator]
            params = {
                "fid": indicator_config[0],
                "po": "1",
                "pz": 5000,  # è·å–æ›´å¤šæ•°æ®
                "pn": 1,
                "np": "1",
                "fltt": "2",
                "invt": "2",
                "ut": "b2884a393a59ad64002292a3e90d46a5",
                "fs": "m:0+t:6+f:!2,m:0+t:13+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:7+f:!2,m:1+t:3+f:!2",
                "fields": indicator_config[1],
            }
            
            # è·å–æ•°æ®
            all_data = await self._fetch_all_pages(params)
            if not all_data:
                return FundFlowResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="individual",
                    indicator=request.indicator
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_individual_fund_flow_data(all_data, request.indicator)
            
            # è¿‡æ»¤æŒ‡å®šè‚¡ç¥¨
            if request.symbols:
                df = df[df['ä»£ç '].isin(request.symbols)]
            
            # æ•°æ®å»é‡å’Œæ—¶é—´åºåˆ—å¤„ç†
            df = self._deduplicate_and_sort(df)
            
            self.error_stats['successful_requests'] += 1
            
            return FundFlowResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="individual",
                indicator=request.indicator
            )
            
        except Exception as e:
            logger.error(f"è·å–ä¸ªè‚¡èµ„é‡‘æµå‘å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return FundFlowResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="individual",
                indicator=request.indicator
            )
    
    async def get_sector_fund_flow(self, request: FundFlowRequest) -> FundFlowResponse:
        """
        è·å–æ¿å—èµ„é‡‘æµå‘æ•°æ®
        
        Args:
            request: èµ„é‡‘æµå‘è¯·æ±‚å¯¹è±¡
            
        Returns:
            èµ„é‡‘æµå‘å“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            if request.indicator not in self.sector_indicator_map:
                return FundFlowResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"ä¸æ”¯æŒçš„æŒ‡æ ‡: {request.indicator}",
                    response_time=time.time() - start_time,
                    data_type="sector",
                    indicator=request.indicator
                )
            
            if request.sector_type not in self.sector_type_map:
                return FundFlowResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"ä¸æ”¯æŒçš„æ¿å—ç±»å‹: {request.sector_type}",
                    response_time=time.time() - start_time,
                    data_type="sector",
                    indicator=request.indicator
                )
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            indicator_config = self.sector_indicator_map[request.indicator]
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            
            params = {
                "pn": 1,
                "pz": 5000,
                "po": "1",
                "np": "1",
                "ut": "b2884a393a59ad64002292a3e90d46a5",
                "fltt": "2",
                "invt": "2",
                "fid0": indicator_config[0],
                "fs": f"m:90 t:{self.sector_type_map[request.sector_type]}",
                "stat": indicator_config[1],
                "fields": indicator_config[2],
                "rt": "52975239",
                "cb": f"jQuery18308357908311220152_{int(time.time() * 1000)}",
                "_": int(time.time() * 1000),
            }
            
            # è·å–æ•°æ®
            all_data = await self._fetch_sector_pages(params, headers)
            if not all_data:
                return FundFlowResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°æ¿å—æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="sector",
                    indicator=request.indicator
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_sector_fund_flow_data(all_data, request.indicator)
            
            # æ•°æ®å»é‡å’Œæ’åº
            df = self._deduplicate_and_sort(df, sort_by='åç§°')
            
            self.error_stats['successful_requests'] += 1
            
            return FundFlowResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="sector",
                indicator=request.indicator
            )
            
        except Exception as e:
            logger.error(f"è·å–æ¿å—èµ„é‡‘æµå‘å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return FundFlowResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="sector",
                indicator=request.indicator
            )
    
    async def get_multi_period_fund_flow(self, symbols: List[str]) -> Dict[str, FundFlowResponse]:
        """
        è·å–å¤šæ—¶é—´å‘¨æœŸèµ„é‡‘æµå‘æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            å¤šæ—¶é—´å‘¨æœŸæ•°æ®å­—å…¸
        """
        results = {}
        periods = ["ä»Šæ—¥", "3æ—¥", "5æ—¥", "10æ—¥"]
        
        for period in periods:
            request = FundFlowRequest(
                data_type="individual",
                indicator=period,
                symbols=symbols
            )
            
            response = await self.get_individual_fund_flow(request)
            results[period] = response
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.5)
        
        return results
    
    async def _fetch_all_pages(self, base_params: Dict) -> List[Dict]:
        """è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®"""
        all_data = []
        page_current = 1
        
        while True:
            params = base_params.copy()
            params["pn"] = page_current
            
            try:
                response = self.session.get(
                    self.base_url, 
                    params=params, 
                    timeout=self.timeout
                )
                response.raise_for_status()
                data_json = response.json()
                
                if not data_json.get("data") or not data_json["data"].get("diff"):
                    break
                
                page_data = data_json["data"]["diff"]
                all_data.extend(page_data)
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
                data_count = data_json["data"].get("total", 0)
                page_size = base_params.get("pz", 50)
                
                if len(all_data) >= data_count:
                    break
                
                page_current += 1
                await asyncio.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                logger.error(f"è·å–ç¬¬{page_current}é¡µæ•°æ®å¤±è´¥: {e}")
                self.error_stats['network_errors'] += 1
                break
        
        return all_data
    
    async def _fetch_sector_pages(self, base_params: Dict, headers: Dict) -> List[Dict]:
        """è·å–æ¿å—æ•°æ®æ‰€æœ‰åˆ†é¡µ"""
        all_data = []
        page_current = 1
        
        while True:
            params = base_params.copy()
            params["pn"] = page_current
            params["_"] = int(time.time() * 1000)
            
            try:
                response = self.session.get(
                    self.base_url,
                    params=params,
                    headers=headers,
                    timeout=self.timeout
                )
                response.raise_for_status()
                
                # å¤„ç†JSONPå“åº”
                text_data = response.text
                if "jQuery" in text_data:
                    json_start = text_data.find("{")
                    json_end = text_data.rfind("}")
                    if json_start != -1 and json_end != -1:
                        json_str = text_data[json_start:json_end + 1]
                        data_json = json.loads(json_str)
                    else:
                        break
                else:
                    data_json = response.json()
                
                if not data_json.get("data") or not data_json["data"].get("diff"):
                    break
                
                page_data = data_json["data"]["diff"]
                all_data.extend(page_data)
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
                data_count = data_json["data"].get("total", 0)
                page_size = base_params.get("pz", 50)
                
                if len(all_data) >= data_count:
                    break
                
                page_current += 1
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"è·å–æ¿å—ç¬¬{page_current}é¡µæ•°æ®å¤±è´¥: {e}")
                self.error_stats['network_errors'] += 1
                break
        
        return all_data
    
    def _process_individual_fund_flow_data(self, data: List[Dict], indicator: str) -> pd.DataFrame:
        """å¤„ç†ä¸ªè‚¡èµ„é‡‘æµå‘æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        
        # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆå¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼‰
        if not df.empty and "f2" in df.columns:
            df = df[~df["f2"].isin(["-"])]
        elif not df.empty and len(df.columns) > 1:
            # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œç¬¬äºŒåˆ—é€šå¸¸æ˜¯ä»·æ ¼ç›¸å…³æ•°æ®
            df = df[~df.iloc[:, 1].isin(["-"])]
        
        # æ ¹æ®æŒ‡æ ‡è®¾ç½®åˆ—å
        if indicator == "ä»Šæ—¥":
            df.columns = [
                "æœ€æ–°ä»·", "ä»Šæ—¥æ¶¨è·Œå¹…", "ä»£ç ", "åç§°", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢",
                "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€é¢",
                "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€å æ¯”", "_", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”", "_", "_", "_"
            ]
            
            df = df[[
                "ä»£ç ", "åç§°", "æœ€æ–°ä»·", "ä»Šæ—¥æ¶¨è·Œå¹…", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€å æ¯”"
            ]]
            
        elif indicator == "3æ—¥":
            df.columns = [
                "æœ€æ–°ä»·", "ä»£ç ", "åç§°", "_", "3æ—¥æ¶¨è·Œå¹…", "_", "_", "_", "3æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢",
                "3æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”", "3æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "3æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "3æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "3æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”", "3æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "3æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”",
                "3æ—¥å°å•å‡€æµå…¥-å‡€é¢", "3æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”"
            ]
            
            df = df[[
                "ä»£ç ", "åç§°", "æœ€æ–°ä»·", "3æ—¥æ¶¨è·Œå¹…", "3æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "3æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "3æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "3æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "3æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "3æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "3æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "3æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "3æ—¥å°å•å‡€æµå…¥-å‡€é¢", "3æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”"
            ]]
            
        elif indicator == "5æ—¥":
            df.columns = [
                "æœ€æ–°ä»·", "ä»£ç ", "åç§°", "5æ—¥æ¶¨è·Œå¹…", "_", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å°å•å‡€æµå…¥-å‡€é¢", "5æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "_", "_", "_"
            ]
            
            df = df[[
                "ä»£ç ", "åç§°", "æœ€æ–°ä»·", "5æ—¥æ¶¨è·Œå¹…", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å°å•å‡€æµå…¥-å‡€é¢", "5æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”"
            ]]
            
        elif indicator == "10æ—¥":
            df.columns = [
                "æœ€æ–°ä»·", "ä»£ç ", "åç§°", "_", "10æ—¥æ¶¨è·Œå¹…", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å°å•å‡€æµå…¥-å‡€é¢", "10æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "_", "_", "_"
            ]
            
            df = df[[
                "ä»£ç ", "åç§°", "æœ€æ–°ä»·", "10æ—¥æ¶¨è·Œå¹…", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å°å•å‡€æµå…¥-å‡€é¢", "10æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”"
            ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self._convert_numeric_columns(df, indicator)
        
        return df
    
    def _process_sector_fund_flow_data(self, data: List[Dict], indicator: str) -> pd.DataFrame:
        """å¤„ç†æ¿å—èµ„é‡‘æµå‘æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        
        # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆå¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼‰
        if not df.empty and "f2" in df.columns:
            df = df[~df["f2"].isin(["-"])]
        elif not df.empty and len(df.columns) > 1:
            # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œç¬¬äºŒåˆ—é€šå¸¸æ˜¯ä»·æ ¼ç›¸å…³æ•°æ®
            df = df[~df.iloc[:, 1].isin(["-"])]
        
        # æ ¹æ®æŒ‡æ ‡è®¾ç½®åˆ—å
        if indicator == "ä»Šæ—¥":
            df.columns = [
                "-", "ä»Šæ—¥æ¶¨è·Œå¹…", "_", "åç§°", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢",
                "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€é¢",
                "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€å æ¯”", "-", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡",
                "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡ä»£ç ", "æ˜¯å¦å‡€æµå…¥"
            ]
            
            df = df[[
                "åç§°", "ä»Šæ—¥æ¶¨è·Œå¹…", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€é¢", "ä»Šæ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡"
            ]]
            
        elif indicator == "5æ—¥":
            df.columns = [
                "-", "_", "åç§°", "5æ—¥æ¶¨è·Œå¹…", "_", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å°å•å‡€æµå…¥-å‡€é¢", "5æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡", "_", "_"
            ]
            
            df = df[[
                "åç§°", "5æ—¥æ¶¨è·Œå¹…", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "5æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "5æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "5æ—¥å°å•å‡€æµå…¥-å‡€é¢", "5æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "5æ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡"
            ]]
            
        elif indicator == "10æ—¥":
            df.columns = [
                "-", "_", "åç§°", "_", "10æ—¥æ¶¨è·Œå¹…", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å°å•å‡€æµå…¥-å‡€é¢", "10æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡", "_", "_"
            ]
            
            df = df[[
                "åç§°", "10æ—¥æ¶¨è·Œå¹…", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å¤§å•å‡€æµå…¥-å‡€é¢", "10æ—¥å¤§å•å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥ä¸­å•å‡€æµå…¥-å‡€é¢", "10æ—¥ä¸­å•å‡€æµå…¥-å‡€å æ¯”", "10æ—¥å°å•å‡€æµå…¥-å‡€é¢", "10æ—¥å°å•å‡€æµå…¥-å‡€å æ¯”",
                "10æ—¥ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡"
            ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self._convert_numeric_columns(df, indicator, is_sector=True)
        
        return df
    
    def _convert_numeric_columns(self, df: pd.DataFrame, indicator: str, is_sector: bool = False):
        """è½¬æ¢æ•°å€¼åˆ—çš„æ•°æ®ç±»å‹"""
        if df.empty:
            return
        
        # åŸºç¡€æ•°å€¼åˆ—
        base_numeric_cols = [
            f"{indicator}ä¸»åŠ›å‡€æµå…¥-å‡€é¢", f"{indicator}ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”",
            f"{indicator}è¶…å¤§å•å‡€æµå…¥-å‡€é¢", f"{indicator}è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”",
            f"{indicator}å¤§å•å‡€æµå…¥-å‡€é¢", f"{indicator}å¤§å•å‡€æµå…¥-å‡€å æ¯”",
            f"{indicator}ä¸­å•å‡€æµå…¥-å‡€é¢", f"{indicator}ä¸­å•å‡€æµå…¥-å‡€å æ¯”",
            f"{indicator}å°å•å‡€æµå…¥-å‡€é¢", f"{indicator}å°å•å‡€æµå…¥-å‡€å æ¯”",
            f"{indicator}æ¶¨è·Œå¹…"
        ]
        
        # ä¸ªè‚¡ç‰¹æœ‰åˆ—
        if not is_sector and "æœ€æ–°ä»·" in df.columns:
            base_numeric_cols.append("æœ€æ–°ä»·")
        
        # è½¬æ¢æ•°å€¼ç±»å‹
        for col in base_numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
    
    def _deduplicate_and_sort(self, df: pd.DataFrame, sort_by: str = "ä»£ç ") -> pd.DataFrame:
        """æ•°æ®å»é‡å’Œæ’åº"""
        if df.empty:
            return df
        
        # å»é‡ï¼ˆä¿ç•™æœ€æ–°æ•°æ®ï¼‰
        if sort_by in df.columns:
            df = df.drop_duplicates(subset=[sort_by], keep='last')
            # æ’åº
            df = df.sort_values(by=sort_by).reset_index(drop=True)
        
        return df
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """è·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.error_stats['total_requests']
        if total_requests == 0:
            return self.error_stats
        
        return {
            **self.error_stats,
            'success_rate': self.error_stats['successful_requests'] / total_requests,
            'error_rate': (total_requests - self.error_stats['successful_requests']) / total_requests
        }
    
    def reset_error_statistics(self):
        """é‡ç½®é”™è¯¯ç»Ÿè®¡"""
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•è·å–å°‘é‡ä¸ªè‚¡èµ„é‡‘æµå‘æ•°æ®
            request = FundFlowRequest(
                data_type="individual",
                indicator="ä»Šæ—¥",
                symbols=["000001"]
            )
            
            response = await self.get_individual_fund_flow(request)
            
            return {
                'status': 'healthy' if response.success else 'unhealthy',
                'response_time': response.response_time,
                'error_message': response.error_message,
                'data_available': not response.data.empty,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error_message': str(e),
                'timestamp': datetime.now().isoformat()
            }


# æµ‹è¯•å’Œä½¿ç”¨ç¤ºä¾‹
async def test_fund_flow_adapter():
    """æµ‹è¯•èµ„é‡‘æµå‘é€‚é…å™¨"""
    print("ğŸ” æµ‹è¯•èµ„é‡‘æµå‘æ•°æ®é€‚é…å™¨")
    print("=" * 50)
    
    adapter = FundFlowAdapter()
    
    # æµ‹è¯•ä¸ªè‚¡èµ„é‡‘æµå‘
    print("1. æµ‹è¯•ä¸ªè‚¡èµ„é‡‘æµå‘...")
    individual_request = FundFlowRequest(
        data_type="individual",
        indicator="5æ—¥",
        symbols=["000001", "000002"]
    )
    
    individual_response = await adapter.get_individual_fund_flow(individual_request)
    print(f"   æˆåŠŸ: {individual_response.success}")
    print(f"   å“åº”æ—¶é—´: {individual_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(individual_response.data)}")
    if not individual_response.data.empty:
        print(f"   æ•°æ®åˆ—: {list(individual_response.data.columns)}")
    
    # æµ‹è¯•æ¿å—èµ„é‡‘æµå‘
    print("\n2. æµ‹è¯•æ¿å—èµ„é‡‘æµå‘...")
    sector_request = FundFlowRequest(
        data_type="sector",
        indicator="ä»Šæ—¥",
        sector_type="è¡Œä¸šèµ„é‡‘æµ"
    )
    
    sector_response = await adapter.get_sector_fund_flow(sector_request)
    print(f"   æˆåŠŸ: {sector_response.success}")
    print(f"   å“åº”æ—¶é—´: {sector_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(sector_response.data)}")
    
    # æµ‹è¯•å¤šæ—¶é—´å‘¨æœŸæ•°æ®
    print("\n3. æµ‹è¯•å¤šæ—¶é—´å‘¨æœŸæ•°æ®...")
    multi_period_data = await adapter.get_multi_period_fund_flow(["000001"])
    for period, response in multi_period_data.items():
        print(f"   {period}: {'âœ…' if response.success else 'âŒ'} ({len(response.data)}è¡Œ)")
    
    # å¥åº·æ£€æŸ¥
    print("\n4. å¥åº·æ£€æŸ¥...")
    health = await adapter.health_check()
    print(f"   çŠ¶æ€: {health['status']}")
    print(f"   å“åº”æ—¶é—´: {health.get('response_time', 0):.2f}ç§’")
    
    # é”™è¯¯ç»Ÿè®¡
    print("\n5. é”™è¯¯ç»Ÿè®¡...")
    stats = adapter.get_error_statistics()
    print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"   æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}")
    
    print("\nâœ… èµ„é‡‘æµå‘é€‚é…å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(test_fund_flow_adapter())
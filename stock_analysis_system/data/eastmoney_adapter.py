"""
ä¸œæ–¹è´¢å¯Œæ•°æ®é€‚é…å™¨

åŸºäº tmp/core/crawling/stock_hist_em.py åˆ›å»ºçš„ç»Ÿä¸€æ•°æ®é€‚é…å™¨ï¼Œ
æä¾›è‚¡ç¥¨å®æ—¶è¡Œæƒ…ã€å†å²æ•°æ®ã€åˆ†æ—¶æ•°æ®çš„ç»Ÿä¸€æ¥å£ã€‚

Author: Stock Analysis System Team
Date: 2024-01-20
"""

import asyncio
import logging
import math
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from functools import lru_cache
import pandas as pd
import requests
from dataclasses import dataclass
import numpy as np

logger = logging.getLogger(__name__)


@dataclass
class DataRequest:
    """æ•°æ®è¯·æ±‚ç»“æ„"""
    symbol: str
    start_date: str = ""
    end_date: str = ""
    period: str = "daily"
    adjust: str = ""
    data_type: str = "stock"


@dataclass
class AdapterResponse:
    """é€‚é…å™¨å“åº”ç»“æ„"""
    success: bool
    data: pd.DataFrame
    error_message: str = ""
    response_time: float = 0.0
    data_source: str = "eastmoney"
    timestamp: datetime = None


class EastMoneyAdapter:
    """ä¸œæ–¹è´¢å¯Œæ•°æ®é€‚é…å™¨"""
    
    def __init__(self, timeout: int = 15, max_retries: int = 3):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        
        # APIç«¯ç‚¹é…ç½®
        self.endpoints = {
            'realtime': "http://82.push2.eastmoney.com/api/qt/clist/get",
            'history': "http://push2his.eastmoney.com/api/qt/stock/kline/get",
            'intraday': "https://push2his.eastmoney.com/api/qt/stock/trends2/get",
            'code_map': "http://80.push2.eastmoney.com/api/qt/clist/get"
        }
        
        # å‚æ•°æ˜ å°„
        self.adjust_dict = {"qfq": "1", "hfq": "2", "": "0"}
        self.period_dict = {"daily": "101", "weekly": "102", "monthly": "103"}
        
        # ç¼“å­˜ä»£ç æ˜ å°„
        self._code_id_cache = None
        self._cache_timestamp = None
        self._cache_ttl = 3600  # ç¼“å­˜1å°æ—¶
        
        # é”™è¯¯ç»Ÿè®¡
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def get_realtime_data(self, symbols: Optional[List[str]] = None) -> AdapterResponse:
        """
        è·å–å®æ—¶è¡Œæƒ…æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºç©ºæ—¶è·å–å…¨å¸‚åœºæ•°æ®
            
        Returns:
            é€‚é…å™¨å“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            url = self.endpoints['realtime']
            page_size = 5000 if symbols is None else min(len(symbols), 5000)
            
            params = {
                "pn": 1,
                "pz": page_size,
                "po": "1",
                "np": "1",
                "ut": "bd1d9ddb04089700cf9c27f6f7426281",
                "fltt": "2",
                "invt": "2",
                "fid": "f12",
                "fs": "m:0 t:6,m:0 t:80,m:1 t:2,m:1 t:23,m:0 t:81 s:2048",
                "fields": "f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f14,f15,f16,f17,f18,f20,f21,f22,f23,f24,f25",
                "_": str(int(time.time() * 1000)),
            }
            
            # æ‰§è¡Œè¯·æ±‚
            response_data = await self._make_request(url, params)
            if not response_data:
                return AdapterResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="Failed to get response data",
                    response_time=time.time() - start_time
                )
            
            # è§£ææ•°æ®
            data = response_data.get("data", {}).get("diff", [])
            if not data:
                return AdapterResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="No data returned from API",
                    response_time=time.time() - start_time
                )
            
            # å¤„ç†åˆ†é¡µæ•°æ®
            if response_data["data"].get("total", 0) > page_size:
                data = await self._fetch_all_pages(url, params, response_data)
            
            # è½¬æ¢ä¸ºDataFrame
            df = self._process_realtime_data(data)
            
            # è¿‡æ»¤æŒ‡å®šè‚¡ç¥¨
            if symbols:
                df = df[df['ä»£ç '].isin(symbols)]
            
            self.error_stats['successful_requests'] += 1
            
            return AdapterResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"è·å–å®æ—¶æ•°æ®å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return AdapterResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time
            )
    
    async def get_history_data(self, request: DataRequest) -> AdapterResponse:
        """
        è·å–å†å²æ•°æ®
        
        Args:
            request: æ•°æ®è¯·æ±‚å¯¹è±¡
            
        Returns:
            é€‚é…å™¨å“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            # è·å–ä»£ç æ˜ å°„
            code_id_map = await self._get_code_id_map()
            if request.symbol not in code_id_map:
                return AdapterResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"Symbol {request.symbol} not found in code map",
                    response_time=time.time() - start_time
                )
            
            url = self.endpoints['history']
            params = {
                "fields1": "f1,f2,f3,f4,f5,f6",
                "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61,f116",
                "ut": "7eea3edcaed734bea9cbfc24409ed989",
                "klt": self.period_dict.get(request.period, "101"),
                "fqt": self.adjust_dict.get(request.adjust, "0"),
                "secid": f"{code_id_map[request.symbol]}.{request.symbol}",
                "beg": request.start_date or "19700101",
                "end": request.end_date or "20500101",
                "_": str(int(time.time() * 1000)),
            }
            
            response_data = await self._make_request(url, params)
            if not response_data:
                return AdapterResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="Failed to get response data",
                    response_time=time.time() - start_time
                )
            
            # æ£€æŸ¥æ•°æ®
            if not (response_data.get("data") and response_data["data"].get("klines")):
                return AdapterResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="No kline data returned",
                    response_time=time.time() - start_time
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_history_data(response_data["data"]["klines"])
            
            self.error_stats['successful_requests'] += 1
            
            return AdapterResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return AdapterResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time
            )
    
    async def get_intraday_data(self, request: DataRequest) -> AdapterResponse:
        """
        è·å–åˆ†æ—¶æ•°æ®
        
        Args:
            request: æ•°æ®è¯·æ±‚å¯¹è±¡ï¼Œperiodæ”¯æŒ '1', '5', '15', '30', '60'
            
        Returns:
            é€‚é…å™¨å“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            # è·å–ä»£ç æ˜ å°„
            code_id_map = await self._get_code_id_map()
            if request.symbol not in code_id_map:
                return AdapterResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"Symbol {request.symbol} not found in code map",
                    response_time=time.time() - start_time
                )
            
            if request.period == "1":
                # 1åˆ†é’Ÿæ•°æ®ä½¿ç”¨ä¸åŒçš„API
                url = self.endpoints['intraday']
                params = {
                    "fields1": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13",
                    "fields2": "f51,f52,f53,f54,f55,f56,f57,f58",
                    "ut": "7eea3edcaed734bea9cbfc24409ed989",
                    "ndays": "5",
                    "iscr": "0",
                    "secid": f"{code_id_map[request.symbol]}.{request.symbol}",
                    "_": str(int(time.time() * 1000)),
                }
                
                response_data = await self._make_request(url, params)
                if not response_data or not response_data.get("data", {}).get("trends"):
                    return AdapterResponse(
                        success=False,
                        data=pd.DataFrame(),
                        error_message="No trends data returned",
                        response_time=time.time() - start_time
                    )
                
                df = self._process_intraday_1min_data(response_data["data"]["trends"])
                
            else:
                # å…¶ä»–å‘¨æœŸä½¿ç”¨Kçº¿API
                url = self.endpoints['history']
                params = {
                    "fields1": "f1,f2,f3,f4,f5,f6",
                    "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61",
                    "ut": "7eea3edcaed734bea9cbfc24409ed989",
                    "klt": request.period,
                    "fqt": self.adjust_dict.get(request.adjust, "0"),
                    "secid": f"{code_id_map[request.symbol]}.{request.symbol}",
                    "beg": "0",
                    "end": "20500000",
                    "_": str(int(time.time() * 1000)),
                }
                
                response_data = await self._make_request(url, params)
                if not response_data or not response_data.get("data", {}).get("klines"):
                    return AdapterResponse(
                        success=False,
                        data=pd.DataFrame(),
                        error_message="No klines data returned",
                        response_time=time.time() - start_time
                    )
                
                df = self._process_intraday_kline_data(response_data["data"]["klines"])
            
            # åº”ç”¨æ—¶é—´è¿‡æ»¤
            if request.start_date or request.end_date:
                df = self._filter_by_date_range(df, request.start_date, request.end_date)
            
            self.error_stats['successful_requests'] += 1
            
            return AdapterResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"è·å–åˆ†æ—¶æ•°æ®å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return AdapterResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time
            )
    
    async def _get_code_id_map(self) -> Dict[str, int]:
        """è·å–è‚¡ç¥¨ä»£ç å’Œå¸‚åœºIDæ˜ å°„ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        if (self._code_id_cache is not None and 
            self._cache_timestamp is not None and 
            current_time - self._cache_timestamp < self._cache_ttl):
            return self._code_id_cache
        
        try:
            code_id_dict = {}
            
            # è·å–ä¸Šæµ·Aè‚¡
            sh_codes = await self._fetch_market_codes("m:1 t:2,m:1 t:23")
            code_id_dict.update({code: 1 for code in sh_codes})
            
            # è·å–æ·±åœ³Aè‚¡
            sz_codes = await self._fetch_market_codes("m:0 t:6,m:0 t:80")
            code_id_dict.update({code: 0 for code in sz_codes})
            
            # è·å–åŒ—äº¬Aè‚¡
            bj_codes = await self._fetch_market_codes("m:0 t:81 s:2048")
            code_id_dict.update({code: 0 for code in bj_codes})
            
            # æ›´æ–°ç¼“å­˜
            self._code_id_cache = code_id_dict
            self._cache_timestamp = current_time
            
            logger.info(f"æ›´æ–°ä»£ç æ˜ å°„ç¼“å­˜ï¼Œå…± {len(code_id_dict)} ä¸ªè‚¡ç¥¨")
            return code_id_dict
            
        except Exception as e:
            logger.error(f"è·å–ä»£ç æ˜ å°„å¤±è´¥: {e}")
            return self._code_id_cache or {}
    
    async def _fetch_market_codes(self, market_filter: str) -> List[str]:
        """è·å–ç‰¹å®šå¸‚åœºçš„è‚¡ç¥¨ä»£ç """
        codes = []
        url = self.endpoints['code_map']
        page_size = 50
        page_current = 1
        
        params = {
            "pn": page_current,
            "pz": page_size,
            "po": "1",
            "np": "1",
            "ut": "bd1d9ddb04089700cf9c27f6f7426281",
            "fltt": "2",
            "invt": "2",
            "fid": "f12",
            "fs": market_filter,
            "fields": "f12",
            "_": str(int(time.time() * 1000)),
        }
        
        try:
            response_data = await self._make_request(url, params)
            if not response_data:
                return codes
            
            data = response_data.get("data", {}).get("diff", [])
            if not data:
                return codes
            
            # è·å–ç¬¬ä¸€é¡µæ•°æ®
            for item in data:
                codes.append(item["f12"])
            
            # è·å–å…¶ä»–é¡µé¢
            data_count = response_data["data"].get("total", 0)
            page_count = math.ceil(data_count / page_size)
            
            for page in range(2, page_count + 1):
                params["pn"] = page
                response_data = await self._make_request(url, params)
                if response_data:
                    page_data = response_data.get("data", {}).get("diff", [])
                    for item in page_data:
                        codes.append(item["f12"])
                        
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºä»£ç å¤±è´¥ {market_filter}: {e}")
            
        return codes
    
    async def _make_request(self, url: str, params: Dict) -> Optional[Dict]:
        """å‘é€HTTPè¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        for attempt in range(self.max_retries):
            try:
                response = self.session.get(url, params=params, timeout=self.timeout)
                response.raise_for_status()
                return response.json()
                
            except requests.exceptions.Timeout:
                self.error_stats['network_errors'] += 1
                logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{self.max_retries}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
            except requests.exceptions.RequestException as e:
                self.error_stats['network_errors'] += 1
                logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                    
            except ValueError as e:
                self.error_stats['data_format_errors'] += 1
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                break
                
        return None
    
    async def _fetch_all_pages(self, url: str, base_params: Dict, first_response: Dict) -> List[Dict]:
        """è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®"""
        all_data = first_response["data"]["diff"]
        data_count = first_response["data"]["total"]
        page_size = base_params["pz"]
        page_count = math.ceil(data_count / page_size)
        
        for page in range(2, page_count + 1):
            params = base_params.copy()
            params["pn"] = page
            
            response_data = await self._make_request(url, params)
            if response_data and response_data.get("data", {}).get("diff"):
                all_data.extend(response_data["data"]["diff"])
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.1)
        
        return all_data
    
    def _process_realtime_data(self, data: List[Dict]) -> pd.DataFrame:
        """å¤„ç†å®æ—¶æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        
        # æ ¹æ®å­—æ®µæ˜ å°„é‡å‘½ååˆ—
        field_mapping = {
            'f2': 'æœ€æ–°ä»·', 'f3': 'æ¶¨è·Œå¹…', 'f4': 'æ¶¨è·Œé¢', 'f5': 'æˆäº¤é‡', 'f6': 'æˆäº¤é¢',
            'f7': 'æŒ¯å¹…', 'f8': 'æ¢æ‰‹ç‡', 'f9': 'å¸‚ç›ˆç‡åŠ¨', 'f10': 'é‡æ¯”', 'f11': '5åˆ†é’Ÿæ¶¨è·Œ',
            'f12': 'ä»£ç ', 'f14': 'åç§°', 'f15': 'æœ€é«˜', 'f16': 'æœ€ä½', 'f17': 'ä»Šå¼€',
            'f18': 'æ˜¨æ”¶', 'f20': 'æ€»å¸‚å€¼', 'f21': 'æµé€šå¸‚å€¼', 'f22': 'æ¶¨é€Ÿ', 'f23': 'å¸‚å‡€ç‡',
            'f24': '60æ—¥æ¶¨è·Œå¹…', 'f25': 'å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…'
        }
        
        # é‡å‘½åå­˜åœ¨çš„åˆ—
        existing_mapping = {k: v for k, v in field_mapping.items() if k in df.columns}
        df = df.rename(columns=existing_mapping)
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = ["æœ€æ–°ä»·", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æˆäº¤é‡", "æˆäº¤é¢", "æŒ¯å¹…", 
                       "æ¢æ‰‹ç‡", "å¸‚ç›ˆç‡åŠ¨", "é‡æ¯”", "æœ€é«˜", "æœ€ä½", "ä»Šå¼€", "æ˜¨æ”¶"]
        
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        return df
    
    def _process_history_data(self, klines: List[str]) -> pd.DataFrame:
        """å¤„ç†å†å²æ•°æ®"""
        if not klines:
            return pd.DataFrame()
        
        df = pd.DataFrame([item.split(",") for item in klines])
        df.columns = [
            "æ—¥æœŸ", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", 
            "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"
        ]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = ["å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", 
                       "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"]
        
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        
        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
        df.set_index("æ—¥æœŸ", inplace=True)
        
        return df
    
    def _process_intraday_1min_data(self, trends: List[str]) -> pd.DataFrame:
        """å¤„ç†1åˆ†é’Ÿåˆ†æ—¶æ•°æ®"""
        if not trends:
            return pd.DataFrame()
        
        df = pd.DataFrame([item.split(",") for item in trends])
        df.columns = [
            "æ—¶é—´", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", "æœ€æ–°ä»·"
        ]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = ["å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", "æœ€æ–°ä»·"]
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"])
        df.set_index("æ—¶é—´", inplace=True)
        
        return df
    
    def _process_intraday_kline_data(self, klines: List[str]) -> pd.DataFrame:
        """å¤„ç†åˆ†æ—¶Kçº¿æ•°æ®"""
        if not klines:
            return pd.DataFrame()
        
        df = pd.DataFrame([item.split(",") for item in klines])
        df.columns = [
            "æ—¶é—´", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢",
            "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"
        ]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = ["å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢",
                       "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"]
        
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"])
        df.set_index("æ—¶é—´", inplace=True)
        
        return df
    
    def _filter_by_date_range(self, df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:
        """æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤æ•°æ®"""
        if df.empty:
            return df
        
        try:
            if start_date:
                start_dt = pd.to_datetime(start_date)
                df = df[df.index >= start_dt]
            
            if end_date:
                end_dt = pd.to_datetime(end_date)
                df = df[df.index <= end_dt]
                
        except Exception as e:
            logger.warning(f"æ—¥æœŸè¿‡æ»¤å¤±è´¥: {e}")
        
        return df
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """è·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.error_stats['total_requests']
        if total_requests == 0:
            return self.error_stats
        
        return {
            **self.error_stats,
            'success_rate': self.error_stats['successful_requests'] / total_requests,
            'error_rate': (total_requests - self.error_stats['successful_requests']) / total_requests
        }
    
    def reset_error_statistics(self):
        """é‡ç½®é”™è¯¯ç»Ÿè®¡"""
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•è·å–å°‘é‡å®æ—¶æ•°æ®
            response = await self.get_realtime_data(['000001'])
            
            return {
                'status': 'healthy' if response.success else 'unhealthy',
                'response_time': response.response_time,
                'error_message': response.error_message,
                'data_available': not response.data.empty,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error_message': str(e),
                'timestamp': datetime.now().isoformat()
            }


# æµ‹è¯•å’Œä½¿ç”¨ç¤ºä¾‹
async def test_eastmoney_adapter():
    """æµ‹è¯•ä¸œæ–¹è´¢å¯Œé€‚é…å™¨"""
    print("ğŸ” æµ‹è¯•ä¸œæ–¹è´¢å¯Œæ•°æ®é€‚é…å™¨")
    print("=" * 50)
    
    adapter = EastMoneyAdapter()
    
    # æµ‹è¯•å®æ—¶æ•°æ®
    print("1. æµ‹è¯•å®æ—¶æ•°æ®...")
    realtime_response = await adapter.get_realtime_data(['000001', '000002'])
    print(f"   æˆåŠŸ: {realtime_response.success}")
    print(f"   å“åº”æ—¶é—´: {realtime_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(realtime_response.data)}")
    if not realtime_response.data.empty:
        print(f"   æ•°æ®åˆ—: {list(realtime_response.data.columns)}")
    
    # æµ‹è¯•å†å²æ•°æ®
    print("\n2. æµ‹è¯•å†å²æ•°æ®...")
    history_request = DataRequest(
        symbol="000001",
        start_date="20240101",
        end_date="20241231",
        period="daily"
    )
    history_response = await adapter.get_history_data(history_request)
    print(f"   æˆåŠŸ: {history_response.success}")
    print(f"   å“åº”æ—¶é—´: {history_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(history_response.data)}")
    
    # æµ‹è¯•åˆ†æ—¶æ•°æ®
    print("\n3. æµ‹è¯•åˆ†æ—¶æ•°æ®...")
    intraday_request = DataRequest(
        symbol="000001",
        period="5"
    )
    intraday_response = await adapter.get_intraday_data(intraday_request)
    print(f"   æˆåŠŸ: {intraday_response.success}")
    print(f"   å“åº”æ—¶é—´: {intraday_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(intraday_response.data)}")
    
    # å¥åº·æ£€æŸ¥
    print("\n4. å¥åº·æ£€æŸ¥...")
    health = await adapter.health_check()
    print(f"   çŠ¶æ€: {health['status']}")
    print(f"   å“åº”æ—¶é—´: {health.get('response_time', 0):.2f}ç§’")
    
    # é”™è¯¯ç»Ÿè®¡
    print("\n5. é”™è¯¯ç»Ÿè®¡...")
    stats = adapter.get_error_statistics()
    print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"   æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}")
    
    print("\nâœ… ä¸œæ–¹è´¢å¯Œé€‚é…å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(test_eastmoney_adapter())
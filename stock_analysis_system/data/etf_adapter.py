"""
ETFæ•°æ®é€‚é…å™¨

åŸºäº tmp/core/crawling/fund_etf_em.py åˆ›å»ºçš„ETFæ•°æ®é€‚é…å™¨ï¼Œ
æä¾›ETFå®æ—¶è¡Œæƒ…å’Œå†å²æ•°æ®è·å–çš„ç»Ÿä¸€æ¥å£ã€‚

Author: Stock Analysis System Team
Date: 2024-01-20
"""

import asyncio
import logging
import math
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from functools import lru_cache
import pandas as pd
import requests
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class ETFRequest:
    """ETFè¯·æ±‚ç»“æ„"""
    symbol: str = ""  # ETFä»£ç 
    data_type: str = "realtime"  # realtime, history, intraday
    period: str = "daily"  # daily, weekly, monthly (for history) or 1,5,15,30,60 (for intraday)
    start_date: str = ""
    end_date: str = ""
    adjust: str = ""  # "", "qfq", "hfq"


@dataclass
class ETFResponse:
    """ETFå“åº”ç»“æ„"""
    success: bool
    data: pd.DataFrame
    error_message: str = ""
    response_time: float = 0.0
    data_source: str = "eastmoney_etf"
    timestamp: datetime = None
    data_type: str = ""
    symbol: str = ""


class ETFAdapter:
    """ETFæ•°æ®é€‚é…å™¨"""
    
    def __init__(self, timeout: int = 15, max_retries: int = 3):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        
        # APIç«¯ç‚¹
        self.endpoints = {
            'realtime': "http://88.push2.eastmoney.com/api/qt/clist/get",
            'history': "http://push2his.eastmoney.com/api/qt/stock/kline/get",
            'intraday_1min': "https://push2his.eastmoney.com/api/qt/stock/trends2/get",
            'code_map': "http://88.push2.eastmoney.com/api/qt/clist/get"
        }
        
        # å‚æ•°æ˜ å°„
        self.adjust_dict = {"qfq": "1", "hfq": "2", "": "0"}
        self.period_dict = {"daily": "101", "weekly": "102", "monthly": "103"}
        
        # ç¼“å­˜ETFä»£ç æ˜ å°„
        self._etf_code_cache = None
        self._cache_timestamp = None
        self._cache_ttl = 3600  # ç¼“å­˜1å°æ—¶ 
       
        # é”™è¯¯ç»Ÿè®¡
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def get_etf_realtime_data(self, symbols: Optional[List[str]] = None) -> ETFResponse:
        """
        è·å–ETFå®æ—¶è¡Œæƒ…æ•°æ®
        
        Args:
            symbols: ETFä»£ç åˆ—è¡¨ï¼Œä¸ºç©ºæ—¶è·å–å…¨å¸‚åœºETFæ•°æ®
            
        Returns:
            ETFå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            url = self.endpoints['realtime']
            page_size = 5000 if symbols is None else min(len(symbols), 5000)
            
            params = {
                "pn": 1,
                "pz": page_size,
                "po": "1",
                "np": "1",
                "ut": "bd1d9ddb04089700cf9c27f6f7426281",
                "fltt": "2",
                "invt": "2",
                "wbp2u": "|0|0|0|web",
                "fid": "f12",
                "fs": "b:MK0021,b:MK0022,b:MK0023,b:MK0024",
                "fields": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152",
                "_": str(int(time.time() * 1000)),
            }
            
            # è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®
            all_data = await self._fetch_all_pages(url, params)
            if not all_data:
                return ETFResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°ETFå®æ—¶æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="realtime"
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_realtime_data(all_data)
            
            # è¿‡æ»¤æŒ‡å®šETF
            if symbols:
                df = df[df['ä»£ç '].isin(symbols)]
            
            self.error_stats['successful_requests'] += 1
            
            return ETFResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="realtime"
            )
            
        except Exception as e:
            logger.error(f"è·å–ETFå®æ—¶æ•°æ®å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return ETFResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="realtime"
            )   
 
    async def get_etf_history_data(self, request: ETFRequest) -> ETFResponse:
        """
        è·å–ETFå†å²æ•°æ®
        
        Args:
            request: ETFè¯·æ±‚å¯¹è±¡
            
        Returns:
            ETFå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            # è·å–ETFä»£ç æ˜ å°„
            code_id_map = await self._get_etf_code_id_map()
            if request.symbol not in code_id_map:
                return ETFResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"ETFä»£ç  {request.symbol} æœªæ‰¾åˆ°",
                    response_time=time.time() - start_time,
                    data_type="history",
                    symbol=request.symbol
                )
            
            url = self.endpoints['history']
            params = {
                "fields1": "f1,f2,f3,f4,f5,f6",
                "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61,f116",
                "ut": "7eea3edcaed734bea9cbfc24409ed989",
                "klt": self.period_dict.get(request.period, "101"),
                "fqt": self.adjust_dict.get(request.adjust, "0"),
                "secid": f"{code_id_map[request.symbol]}.{request.symbol}",
                "beg": request.start_date or "19700101",
                "end": request.end_date or "20500101",
                "_": str(int(time.time() * 1000)),
            }
            
            response_data = await self._make_request(url, params)
            if not response_data:
                return ETFResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°å“åº”æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="history",
                    symbol=request.symbol
                )
            
            # æ£€æŸ¥æ•°æ®
            if not (response_data.get("data") and response_data["data"].get("klines")):
                return ETFResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message="æœªè·å–åˆ°Kçº¿æ•°æ®",
                    response_time=time.time() - start_time,
                    data_type="history",
                    symbol=request.symbol
                )
            
            # å¤„ç†æ•°æ®
            df = self._process_history_data(response_data["data"]["klines"])
            
            self.error_stats['successful_requests'] += 1
            
            return ETFResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="history",
                symbol=request.symbol
            )
            
        except Exception as e:
            logger.error(f"è·å–ETFå†å²æ•°æ®å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return ETFResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="history",
                symbol=request.symbol
            ) 
   
    async def get_etf_intraday_data(self, request: ETFRequest) -> ETFResponse:
        """
        è·å–ETFåˆ†æ—¶æ•°æ®
        
        Args:
            request: ETFè¯·æ±‚å¯¹è±¡ï¼Œperiodæ”¯æŒ '1', '5', '15', '30', '60'
            
        Returns:
            ETFå“åº”å¯¹è±¡
        """
        start_time = time.time()
        self.error_stats['total_requests'] += 1
        
        try:
            # è·å–ETFä»£ç æ˜ å°„
            code_id_map = await self._get_etf_code_id_map()
            if request.symbol not in code_id_map:
                return ETFResponse(
                    success=False,
                    data=pd.DataFrame(),
                    error_message=f"ETFä»£ç  {request.symbol} æœªæ‰¾åˆ°",
                    response_time=time.time() - start_time,
                    data_type="intraday",
                    symbol=request.symbol
                )
            
            if request.period == "1":
                # 1åˆ†é’Ÿæ•°æ®ä½¿ç”¨ä¸åŒçš„API
                url = self.endpoints['intraday_1min']
                params = {
                    "fields1": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13",
                    "fields2": "f51,f52,f53,f54,f55,f56,f57,f58",
                    "ut": "7eea3edcaed734bea9cbfc24409ed989",
                    "ndays": "5",
                    "iscr": "0",
                    "secid": f"{code_id_map[request.symbol]}.{request.symbol}",
                    "_": str(int(time.time() * 1000)),
                }
                
                response_data = await self._make_request(url, params)
                if not response_data or not response_data.get("data", {}).get("trends"):
                    return ETFResponse(
                        success=False,
                        data=pd.DataFrame(),
                        error_message="æœªè·å–åˆ°åˆ†æ—¶æ•°æ®",
                        response_time=time.time() - start_time,
                        data_type="intraday",
                        symbol=request.symbol
                    )
                
                df = self._process_intraday_1min_data(response_data["data"]["trends"])
                
            else:
                # å…¶ä»–å‘¨æœŸä½¿ç”¨Kçº¿API
                url = self.endpoints['history']
                params = {
                    "fields1": "f1,f2,f3,f4,f5,f6",
                    "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61",
                    "ut": "7eea3edcaed734bea9cbfc24409ed989",
                    "klt": request.period,
                    "fqt": self.adjust_dict.get(request.adjust, "0"),
                    "secid": f"{code_id_map[request.symbol]}.{request.symbol}",
                    "beg": "0",
                    "end": "20500000",
                    "_": str(int(time.time() * 1000)),
                }
                
                response_data = await self._make_request(url, params)
                if not response_data or not response_data.get("data", {}).get("klines"):
                    return ETFResponse(
                        success=False,
                        data=pd.DataFrame(),
                        error_message="æœªè·å–åˆ°Kçº¿æ•°æ®",
                        response_time=time.time() - start_time,
                        data_type="intraday",
                        symbol=request.symbol
                    )
                
                df = self._process_intraday_kline_data(response_data["data"]["klines"])
            
            # åº”ç”¨æ—¶é—´è¿‡æ»¤
            if request.start_date or request.end_date:
                df = self._filter_by_date_range(df, request.start_date, request.end_date)
            
            self.error_stats['successful_requests'] += 1
            
            return ETFResponse(
                success=True,
                data=df,
                response_time=time.time() - start_time,
                timestamp=datetime.now(),
                data_type="intraday",
                symbol=request.symbol
            )
            
        except Exception as e:
            logger.error(f"è·å–ETFåˆ†æ—¶æ•°æ®å¤±è´¥: {e}")
            self.error_stats['api_errors'] += 1
            return ETFResponse(
                success=False,
                data=pd.DataFrame(),
                error_message=str(e),
                response_time=time.time() - start_time,
                data_type="intraday",
                symbol=request.symbol
            )  
  
    async def _get_etf_code_id_map(self) -> Dict[str, str]:
        """è·å–ETFä»£ç å’Œå¸‚åœºIDæ˜ å°„ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        if (self._etf_code_cache is not None and 
            self._cache_timestamp is not None and 
            current_time - self._cache_timestamp < self._cache_ttl):
            return self._etf_code_cache
        
        try:
            url = self.endpoints['code_map']
            params = {
                "pn": "1",
                "pz": "5000",
                "po": "1",
                "np": "1",
                "ut": "bd1d9ddb04089700cf9c27f6f7426281",
                "fltt": "2",
                "invt": "2",
                "wbp2u": "|0|0|0|web",
                "fid": "f3",
                "fs": "b:MK0021,b:MK0022,b:MK0023,b:MK0024",
                "fields": "f12,f13",
                "_": str(int(time.time() * 1000)),
            }
            
            response_data = await self._make_request(url, params)
            if not response_data or not response_data.get("data", {}).get("diff"):
                return self._etf_code_cache or {}
            
            data = response_data["data"]["diff"]
            code_id_dict = {item["f12"]: item["f13"] for item in data}
            
            # æ›´æ–°ç¼“å­˜
            self._etf_code_cache = code_id_dict
            self._cache_timestamp = current_time
            
            logger.info(f"æ›´æ–°ETFä»£ç æ˜ å°„ç¼“å­˜ï¼Œå…± {len(code_id_dict)} ä¸ªETF")
            return code_id_dict
            
        except Exception as e:
            logger.error(f"è·å–ETFä»£ç æ˜ å°„å¤±è´¥: {e}")
            return self._etf_code_cache or {}
    
    async def _make_request(self, url: str, params: Dict) -> Optional[Dict]:
        """å‘é€HTTPè¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        for attempt in range(self.max_retries):
            try:
                response = self.session.get(url, params=params, timeout=self.timeout)
                response.raise_for_status()
                return response.json()
                
            except requests.exceptions.Timeout:
                self.error_stats['network_errors'] += 1
                logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{self.max_retries}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                    
            except requests.exceptions.RequestException as e:
                self.error_stats['network_errors'] += 1
                logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                    
            except ValueError as e:
                self.error_stats['data_format_errors'] += 1
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                break
                
        return None
    
    async def _fetch_all_pages(self, url: str, base_params: Dict) -> List[Dict]:
        """è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®"""
        all_data = []
        
        # è·å–ç¬¬ä¸€é¡µæ•°æ®
        response_data = await self._make_request(url, base_params)
        if not response_data or not response_data.get("data", {}).get("diff"):
            return all_data
        
        first_page_data = response_data["data"]["diff"]
        all_data.extend(first_page_data)
        
        # è·å–æ€»æ•°æ®é‡å’Œé¡µæ•°
        data_count = response_data["data"].get("total", 0)
        page_size = base_params.get("pz", 50)
        page_count = math.ceil(data_count / page_size)
        
        # è·å–å…¶ä»–é¡µé¢æ•°æ®
        for page in range(2, page_count + 1):
            params = base_params.copy()
            params["pn"] = page
            
            response_data = await self._make_request(url, params)
            if response_data and response_data.get("data", {}).get("diff"):
                all_data.extend(response_data["data"]["diff"])
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.1)
        
        return all_data 
   
    def _process_realtime_data(self, data: List[Dict]) -> pd.DataFrame:
        """å¤„ç†ETFå®æ—¶æ•°æ®"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        
        # é‡å‘½ååˆ—
        df.rename(columns={
            "f12": "ä»£ç ",
            "f14": "åç§°",
            "f2": "æœ€æ–°ä»·",
            "f3": "æ¶¨è·Œå¹…",
            "f4": "æ¶¨è·Œé¢",
            "f5": "æˆäº¤é‡",
            "f6": "æˆäº¤é¢",
            "f17": "å¼€ç›˜ä»·",
            "f15": "æœ€é«˜ä»·",
            "f16": "æœ€ä½ä»·",
            "f18": "æ˜¨æ”¶",
            "f8": "æ¢æ‰‹ç‡",
            "f21": "æµé€šå¸‚å€¼",
            "f20": "æ€»å¸‚å€¼",
        }, inplace=True)
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        df = df[[
            "ä»£ç ", "åç§°", "æœ€æ–°ä»·", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æˆäº¤é‡", "æˆäº¤é¢",
            "å¼€ç›˜ä»·", "æœ€é«˜ä»·", "æœ€ä½ä»·", "æ˜¨æ”¶", "æ¢æ‰‹ç‡", "æµé€šå¸‚å€¼", "æ€»å¸‚å€¼"
        ]]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = [
            "æœ€æ–°ä»·", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æˆäº¤é‡", "æˆäº¤é¢", "å¼€ç›˜ä»·",
            "æœ€é«˜ä»·", "æœ€ä½ä»·", "æ˜¨æ”¶", "æ¢æ‰‹ç‡", "æµé€šå¸‚å€¼", "æ€»å¸‚å€¼"
        ]
        
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")
        
        return df
    
    def _process_history_data(self, klines: List[str]) -> pd.DataFrame:
        """å¤„ç†ETFå†å²æ•°æ®"""
        if not klines:
            return pd.DataFrame()
        
        df = pd.DataFrame([item.split(",") for item in klines])
        df.columns = [
            "æ—¥æœŸ", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢",
            "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"
        ]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = [
            "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢",
            "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"
        ]
        
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        
        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
        df.set_index("æ—¥æœŸ", inplace=True)
        
        return df
    
    def _process_intraday_1min_data(self, trends: List[str]) -> pd.DataFrame:
        """å¤„ç†ETF 1åˆ†é’Ÿåˆ†æ—¶æ•°æ®"""
        if not trends:
            return pd.DataFrame()
        
        df = pd.DataFrame([item.split(",") for item in trends])
        df.columns = [
            "æ—¶é—´", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", "æœ€æ–°ä»·"
        ]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = ["å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢", "æœ€æ–°ä»·"]
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"])
        df.set_index("æ—¶é—´", inplace=True)
        
        return df
    
    def _process_intraday_kline_data(self, klines: List[str]) -> pd.DataFrame:
        """å¤„ç†ETFåˆ†æ—¶Kçº¿æ•°æ®"""
        if not klines:
            return pd.DataFrame()
        
        df = pd.DataFrame([item.split(",") for item in klines])
        df.columns = [
            "æ—¶é—´", "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢",
            "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"
        ]
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = [
            "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æˆäº¤é‡", "æˆäº¤é¢",
            "æŒ¯å¹…", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢", "æ¢æ‰‹ç‡"
        ]
        
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        
        df["æ—¶é—´"] = pd.to_datetime(df["æ—¶é—´"])
        df.set_index("æ—¶é—´", inplace=True)
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        df = df[[
            "å¼€ç›˜", "æ”¶ç›˜", "æœ€é«˜", "æœ€ä½", "æ¶¨è·Œå¹…", "æ¶¨è·Œé¢",
            "æˆäº¤é‡", "æˆäº¤é¢", "æŒ¯å¹…", "æ¢æ‰‹ç‡"
        ]]
        
        return df 
   
    def _filter_by_date_range(self, df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:
        """æŒ‰æ—¥æœŸèŒƒå›´è¿‡æ»¤æ•°æ®"""
        if df.empty:
            return df
        
        try:
            if start_date:
                start_dt = pd.to_datetime(start_date)
                df = df[df.index >= start_dt]
            
            if end_date:
                end_dt = pd.to_datetime(end_date)
                df = df[df.index <= end_dt]
                
        except Exception as e:
            logger.warning(f"æ—¥æœŸè¿‡æ»¤å¤±è´¥: {e}")
        
        return df
    
    def get_etf_special_indicators(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è®¡ç®—ETFç‰¹æœ‰æŒ‡æ ‡"""
        if df.empty:
            return {}
        
        indicators = {}
        
        # åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
        if "æ¶¨è·Œå¹…" in df.columns:
            indicators["å¹³å‡æ¶¨è·Œå¹…"] = df["æ¶¨è·Œå¹…"].mean()
            indicators["æ¶¨è·Œå¹…æ ‡å‡†å·®"] = df["æ¶¨è·Œå¹…"].std()
            indicators["æœ€å¤§æ¶¨å¹…"] = df["æ¶¨è·Œå¹…"].max()
            indicators["æœ€å¤§è·Œå¹…"] = df["æ¶¨è·Œå¹…"].min()
        
        if "æˆäº¤é¢" in df.columns:
            indicators["å¹³å‡æˆäº¤é¢"] = df["æˆäº¤é¢"].mean()
            indicators["æˆäº¤é¢æ ‡å‡†å·®"] = df["æˆäº¤é¢"].std()
        
        if "æ¢æ‰‹ç‡" in df.columns:
            indicators["å¹³å‡æ¢æ‰‹ç‡"] = df["æ¢æ‰‹ç‡"].mean()
        
        # ETFç‰¹æœ‰æŒ‡æ ‡
        if "æœ€æ–°ä»·" in df.columns and len(df) > 1:
            # ä»·æ ¼æ³¢åŠ¨ç‡
            price_returns = df["æœ€æ–°ä»·"].pct_change().dropna()
            if not price_returns.empty:
                indicators["ä»·æ ¼æ³¢åŠ¨ç‡"] = price_returns.std() * (252 ** 0.5)  # å¹´åŒ–æ³¢åŠ¨ç‡
        
        # æµåŠ¨æ€§æŒ‡æ ‡
        if "æˆäº¤é¢" in df.columns and "æµé€šå¸‚å€¼" in df.columns:
            # æµåŠ¨æ€§æ¯”ç‡
            liquidity_ratio = df["æˆäº¤é¢"] / df["æµé€šå¸‚å€¼"]
            indicators["å¹³å‡æµåŠ¨æ€§æ¯”ç‡"] = liquidity_ratio.mean()
        
        return indicators
    
    def get_error_statistics(self) -> Dict[str, Any]:
        """è·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.error_stats['total_requests']
        if total_requests == 0:
            return self.error_stats
        
        return {
            **self.error_stats,
            'success_rate': self.error_stats['successful_requests'] / total_requests,
            'error_rate': (total_requests - self.error_stats['successful_requests']) / total_requests
        }
    
    def reset_error_statistics(self):
        """é‡ç½®é”™è¯¯ç»Ÿè®¡"""
        self.error_stats = {
            'network_errors': 0,
            'data_format_errors': 0,
            'api_errors': 0,
            'total_requests': 0,
            'successful_requests': 0
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æµ‹è¯•è·å–å°‘é‡ETFå®æ—¶æ•°æ®
            response = await self.get_etf_realtime_data(['159707'])  # ä¸­è¯500ETF
            
            return {
                'status': 'healthy' if response.success else 'unhealthy',
                'response_time': response.response_time,
                'error_message': response.error_message,
                'data_available': not response.data.empty,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error_message': str(e),
                'timestamp': datetime.now().isoformat()
            }


# æµ‹è¯•å’Œä½¿ç”¨ç¤ºä¾‹
async def test_etf_adapter():
    """æµ‹è¯•ETFé€‚é…å™¨"""
    print("ğŸ” æµ‹è¯•ETFæ•°æ®é€‚é…å™¨")
    print("=" * 50)
    
    adapter = ETFAdapter()
    
    # æµ‹è¯•ETFå®æ—¶æ•°æ®
    print("1. æµ‹è¯•ETFå®æ—¶æ•°æ®...")
    realtime_response = await adapter.get_etf_realtime_data(['159707', '513500'])
    print(f"   æˆåŠŸ: {realtime_response.success}")
    print(f"   å“åº”æ—¶é—´: {realtime_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(realtime_response.data)}")
    if not realtime_response.data.empty:
        print(f"   æ•°æ®åˆ—: {list(realtime_response.data.columns)}")
    
    # æµ‹è¯•ETFå†å²æ•°æ®
    print("\n2. æµ‹è¯•ETFå†å²æ•°æ®...")
    history_request = ETFRequest(
        symbol="159707",
        data_type="history",
        period="daily",
        start_date="20240101",
        end_date="20241231"
    )
    history_response = await adapter.get_etf_history_data(history_request)
    print(f"   æˆåŠŸ: {history_response.success}")
    print(f"   å“åº”æ—¶é—´: {history_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(history_response.data)}")
    
    # æµ‹è¯•ETFåˆ†æ—¶æ•°æ®
    print("\n3. æµ‹è¯•ETFåˆ†æ—¶æ•°æ®...")
    intraday_request = ETFRequest(
        symbol="159707",
        data_type="intraday",
        period="5"
    )
    intraday_response = await adapter.get_etf_intraday_data(intraday_request)
    print(f"   æˆåŠŸ: {intraday_response.success}")
    print(f"   å“åº”æ—¶é—´: {intraday_response.response_time:.2f}ç§’")
    print(f"   æ•°æ®è¡Œæ•°: {len(intraday_response.data)}")
    
    # æµ‹è¯•ETFç‰¹æœ‰æŒ‡æ ‡
    if not realtime_response.data.empty:
        print("\n4. æµ‹è¯•ETFç‰¹æœ‰æŒ‡æ ‡...")
        indicators = adapter.get_etf_special_indicators(realtime_response.data)
        print(f"   è®¡ç®—å‡º {len(indicators)} ä¸ªæŒ‡æ ‡")
        for key, value in list(indicators.items())[:3]:
            print(f"   {key}: {value:.4f}" if isinstance(value, float) else f"   {key}: {value}")
    
    # å¥åº·æ£€æŸ¥
    print("\n5. å¥åº·æ£€æŸ¥...")
    health = await adapter.health_check()
    print(f"   çŠ¶æ€: {health['status']}")
    print(f"   å“åº”æ—¶é—´: {health.get('response_time', 0):.2f}ç§’")
    
    # é”™è¯¯ç»Ÿè®¡
    print("\n6. é”™è¯¯ç»Ÿè®¡...")
    stats = adapter.get_error_statistics()
    print(f"   æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"   æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}")
    
    print("\nâœ… ETFé€‚é…å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(test_etf_adapter())